<!DOCTYPE html>
<html lang="zh-cn"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>性能建议 · Julia中文文档</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-89508993-1', 'auto');
ga('send', 'pageview');
</script><link rel="canonical" href="https://juliacn.github.io/JuliaZH.jl/latest/manual/performance-tips/index.html"/><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/julia-manual.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../index.html"><img class="logo" src="../../assets/logo.png" alt="Julia中文文档 logo"/></a><h1>Julia中文文档</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">主页</a></li><li><span class="toctext">手册</span><ul><li><a class="toctext" href="../getting-started/">入门</a></li><li><a class="toctext" href="../variables/">变量</a></li><li><a class="toctext" href="../integers-and-floating-point-numbers/">整数和浮点数</a></li><li><a class="toctext" href="../mathematical-operations/">数学运算和初等函数</a></li><li><a class="toctext" href="../complex-and-rational-numbers/">复数和分数</a></li><li><a class="toctext" href="../strings/">字符串</a></li><li><a class="toctext" href="../functions/">函数</a></li><li><a class="toctext" href="../control-flow/">流程控制</a></li><li><a class="toctext" href="../variables-and-scoping/">变量作用域</a></li><li><a class="toctext" href="../types/">类型</a></li><li><a class="toctext" href="../methods/">方法</a></li><li><a class="toctext" href="../constructors/">构造函数</a></li><li><a class="toctext" href="../conversion-and-promotion/">类型转换和类型提升</a></li><li><a class="toctext" href="../interfaces/">接口</a></li><li><a class="toctext" href="../modules/">模块</a></li><li><a class="toctext" href="../documentation/">文档</a></li><li><a class="toctext" href="../metaprogramming/">元编程</a></li><li><a class="toctext" href="../arrays/">多维数组</a></li><li><a class="toctext" href="../missing/">缺失值</a></li><li><a class="toctext" href="../networking-and-streams/">网络和流</a></li><li><a class="toctext" href="../parallel-computing/">并行计算</a></li><li><a class="toctext" href="../running-external-programs/">运行外部程序</a></li><li><a class="toctext" href="../calling-c-and-fortran-code/">调用 C 和 Fortran 代码</a></li><li><a class="toctext" href="../handling-operating-system-variation/">处理操作系统差异</a></li><li><a class="toctext" href="../environment-variables/">环境变量</a></li><li><a class="toctext" href="../embedding/">嵌入 Julia</a></li><li><a class="toctext" href="../code-loading/">代码加载</a></li><li><a class="toctext" href="../profile/">性能分析</a></li><li><a class="toctext" href="../stacktraces/">栈跟踪</a></li><li class="current"><a class="toctext" href>性能建议</a><ul class="internal"><li><a class="toctext" href="#避免全局变量-1">避免全局变量</a></li><li><a class="toctext" href="#使用-[@time](@ref)评估性能以及注意内存分配-1">使用 <code>@time</code>评估性能以及注意内存分配</a></li><li><a class="toctext" href="#tools-1">工具</a></li><li><a class="toctext" href="#避免拥有抽象类型参数的容器-1">避免拥有抽象类型参数的容器</a></li><li><a class="toctext" href="#类型声明-1">类型声明</a></li><li><a class="toctext" href="#Break-functions-into-multiple-definitions-1">Break functions into multiple definitions</a></li><li><a class="toctext" href="#编写「类型稳定的」函数-1">编写「类型稳定的」函数</a></li><li><a class="toctext" href="#避免更改变量类型-1">避免更改变量类型</a></li><li><a class="toctext" href="#kernal-functions-1">Separate kernel functions (aka, function barriers)</a></li><li><a class="toctext" href="#Types-with-values-as-parameters-1">Types with values-as-parameters</a></li><li><a class="toctext" href="#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)-1">The dangers of abusing multiple dispatch (aka, more on types with values-as-parameters)</a></li><li><a class="toctext" href="#Access-arrays-in-memory-order,-along-columns-1">Access arrays in memory order, along columns</a></li><li><a class="toctext" href="#Pre-allocating-outputs-1">Pre-allocating outputs</a></li><li><a class="toctext" href="#More-dots:-Fuse-vectorized-operations-1">More dots: Fuse vectorized operations</a></li><li><a class="toctext" href="#Consider-using-views-for-slices-1">Consider using views for slices</a></li><li><a class="toctext" href="#Copying-data-is-not-always-bad-1">Copying data is not always bad</a></li><li><a class="toctext" href="#Avoid-string-interpolation-for-I/O-1">Avoid string interpolation for I/O</a></li><li><a class="toctext" href="#Optimize-network-I/O-during-parallel-execution-1">Optimize network I/O during parallel execution</a></li><li><a class="toctext" href="#Fix-deprecation-warnings-1">Fix deprecation warnings</a></li><li><a class="toctext" href="#Tweaks-1">Tweaks</a></li><li><a class="toctext" href="#man-performance-annotations-1">Performance Annotations</a></li><li><a class="toctext" href="#Treat-Subnormal-Numbers-as-Zeros-1">Treat Subnormal Numbers as Zeros</a></li><li><a class="toctext" href="#man-code-warntype-1"><code>@code_warntype</code></a></li><li><a class="toctext" href="#man-performance-captured-1">被捕获变量的性能</a></li></ul></li><li><a class="toctext" href="../workflow-tips/">工作流程建议</a></li><li><a class="toctext" href="../style-guide/">代码风格指南</a></li><li><a class="toctext" href="../faq/">常见问题</a></li><li><a class="toctext" href="../noteworthy-differences/">与其他语言的显著差异</a></li><li><a class="toctext" href="../unicode-input/">Unicode 输入表</a></li></ul></li><li><span class="toctext">Base</span><ul><li><a class="toctext" href="../../base/base/">基本功能</a></li><li><a class="toctext" href="../../base/collections/">集合和数据结构</a></li><li><a class="toctext" href="../../base/math/">数学相关</a></li><li><a class="toctext" href="../../base/numbers/">Numbers</a></li><li><a class="toctext" href="../../base/strings/">字符串</a></li><li><a class="toctext" href="../../base/arrays/">Arrays</a></li><li><a class="toctext" href="../../base/parallel/">Tasks</a></li><li><a class="toctext" href="../../base/multi-threading/">多线程</a></li><li><a class="toctext" href="../../base/constants/">常量</a></li><li><a class="toctext" href="../../base/file/">文件系统</a></li><li><a class="toctext" href="../../base/io-network/">I/O 与网络</a></li><li><a class="toctext" href="../../base/punctuation/">标点符号</a></li><li><a class="toctext" href="../../base/sort/">排序及相关函数</a></li><li><a class="toctext" href="../../base/iterators/">迭代相关</a></li><li><a class="toctext" href="../../base/c/">C 接口</a></li><li><a class="toctext" href="../../base/libc/">C 标准库</a></li><li><a class="toctext" href="../../base/stacktraces/">StackTraces</a></li><li><a class="toctext" href="../../base/simd-types/">SIMD 支持</a></li></ul></li><li><span class="toctext">Standard Library</span><ul><li><a class="toctext" href="../../stdlib/Base64/">Base64</a></li><li><a class="toctext" href="../../stdlib/CRC32c/">CRC32c</a></li><li><a class="toctext" href="../../stdlib/Dates/">Dates</a></li><li><a class="toctext" href="../../stdlib/DelimitedFiles/">Delimited Files</a></li><li><a class="toctext" href="../../stdlib/Distributed/">Distributed Computing</a></li><li><a class="toctext" href="../../stdlib/FileWatching/">File Events</a></li><li><a class="toctext" href="../../stdlib/InteractiveUtils/">Interactive Utilities</a></li><li><a class="toctext" href="../../stdlib/LibGit2/">LibGit2</a></li><li><a class="toctext" href="../../stdlib/Libdl/">动态链接器</a></li><li><a class="toctext" href="../../stdlib/LinearAlgebra/">线性代数</a></li><li><a class="toctext" href="../../stdlib/Logging/">Logging</a></li><li><a class="toctext" href="../../stdlib/Markdown/">Markdown</a></li><li><a class="toctext" href="../../stdlib/Mmap/">Memory-mapped I/O</a></li><li><a class="toctext" href="../../stdlib/Pkg/">Pkg</a></li><li><a class="toctext" href="../../stdlib/Printf/">Printf</a></li><li><a class="toctext" href="../../stdlib/Profile/">Profiling</a></li><li><a class="toctext" href="../../stdlib/REPL/">Julia REPL</a></li><li><a class="toctext" href="../../stdlib/Random/">Random Numbers</a></li><li><a class="toctext" href="../../stdlib/SHA/">SHA</a></li><li><a class="toctext" href="../../stdlib/Serialization/">Serialization</a></li><li><a class="toctext" href="../../stdlib/SharedArrays/">Shared Arrays</a></li><li><a class="toctext" href="../../stdlib/Sockets/">Sockets</a></li><li><a class="toctext" href="../../stdlib/SparseArrays/">Sparse Arrays</a></li><li><a class="toctext" href="../../stdlib/Statistics/">Statistics</a></li><li><a class="toctext" href="../../stdlib/Test/">Unit Testing</a></li><li><a class="toctext" href="../../stdlib/UUIDs/">UUIDs</a></li><li><a class="toctext" href="../../stdlib/Unicode/">Unicode</a></li></ul></li><li><span class="toctext">Developer Documentation</span><ul><li><a class="toctext" href="../../devdocs/reflection/">反射 与 自我检查</a></li><li><span class="toctext">Documentation of Julia&#39;s Internals</span><ul><li><a class="toctext" href="../../devdocs/init/">Julia 运行时的初始化</a></li><li><a class="toctext" href="../../devdocs/ast/">Julia 的 AST</a></li><li><a class="toctext" href="../../devdocs/types/">More about types</a></li><li><a class="toctext" href="../../devdocs/object/">Memory layout of Julia Objects</a></li><li><a class="toctext" href="../../devdocs/eval/">Julia 代码的 eval</a></li><li><a class="toctext" href="../../devdocs/callconv/">Calling Conventions</a></li><li><a class="toctext" href="../../devdocs/compiler/">High-level Overview of the Native-Code Generation Process</a></li><li><a class="toctext" href="../../devdocs/functions/">Julia的相关函数</a></li><li><a class="toctext" href="../../devdocs/cartesian/">Base.Cartesian</a></li><li><a class="toctext" href="../../devdocs/meta/">Talking to the compiler (the <code>:meta</code> mechanism)</a></li><li><a class="toctext" href="../../devdocs/subarrays/">SubArrays</a></li><li><a class="toctext" href="../../devdocs/isbitsunionarrays/">isbits Union Optimizations</a></li><li><a class="toctext" href="../../devdocs/sysimg/">System Image Building</a></li><li><a class="toctext" href="../../devdocs/llvm/">Working with LLVM</a></li><li><a class="toctext" href="../../devdocs/stdio/">printf() and stdio in the Julia runtime</a></li><li><a class="toctext" href="../../devdocs/boundscheck/">边界检查</a></li><li><a class="toctext" href="../../devdocs/locks/">Proper maintenance and care of multi-threading locks</a></li><li><a class="toctext" href="../../devdocs/offset-arrays/">Arrays with custom indices</a></li><li><a class="toctext" href="../../devdocs/require/">Module loading</a></li><li><a class="toctext" href="../../devdocs/inference/">Inference</a></li></ul></li><li><span class="toctext">Developing/debugging Julia&#39;s C code</span><ul><li><a class="toctext" href="../../devdocs/backtraces/">Reporting and analyzing crashes (segfaults)</a></li><li><a class="toctext" href="../../devdocs/debuggingtips/">gdb 调试提示</a></li><li><a class="toctext" href="../../devdocs/valgrind/">Using Valgrind with Julia</a></li><li><a class="toctext" href="../../devdocs/sanitizers/">Sanitizer support</a></li></ul></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>手册</li><li><a href>性能建议</a></li></ul><a class="edit-page" href="https://www.transifex.com/juliacn/manual-zh_cn/translate/#zh_CN/performance-tipsmd"><span class="fa"></span> 完善 Transifex 上的翻译</a></nav><hr/><div id="topbar"><span>性能建议</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="man-performance-tips-1" href="#man-performance-tips-1">性能建议</a></h1><p>下面几节简要地介绍了一些使 Julia 代码运行得尽可能快的技巧。</p><h2><a class="nav-anchor" id="避免全局变量-1" href="#避免全局变量-1">避免全局变量</a></h2><p>全局变量的值和类型随时都会发生变化。 这使编译器难以优化使用全局变量的代码。 变量应该是局部的，或者尽可能作为参数传递给函数。</p><p>任何注重性能或者需要测试性能的代码都应该被放置在函数之中。</p><p>我们发现全局变量经常是常量，将它们声明为常量可以巨大的提升性能。</p><pre><code class="language-julia">const DEFAULT_VAL = 0</code></pre><p>对于非常量的全局变量可以通过在使用的地方标注它们的类型来优化效率。</p><pre><code class="language-julia">global x = rand(1000)

function loop_over_global()
    s = 0.0
    for i in x::Vector{Float64}
        s += i
    end
    return s
end</code></pre><p>一个更好的编程风格是将变量作为参数传给函数。这样可以使得代码更易复用，以及清晰的展示函数的输入和输出。</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>所有的REPL中的代码都是在全局作用域中求值的，因此在顶层的变量的定义与赋值都会成为一个<strong>全局</strong>变量。在模块的顶层作用域定义的变量也是全局变量。</p></div></div><p>在下面的REPL会话中：</p><pre><code class="language-julia-repl">julia&gt; x = 1.0</code></pre><p>等价于</p><pre><code class="language-julia-repl">julia&gt; global x = 1.0</code></pre><p>因此，所有上文关于性能问题的讨论都适用于它们。</p><h2><a class="nav-anchor" id="使用-[@time](@ref)评估性能以及注意内存分配-1" href="#使用-[@time](@ref)评估性能以及注意内存分配-1">使用 <a href="../../base/base/#Base.@time"><code>@time</code></a>评估性能以及注意内存分配</a></h2><p><a href="../../base/base/#Base.@time"><code>@time</code></a> 宏是一个有用的性能评估工具。这里我们将重复上面全局变量的例子，但是这次移除类型声明：</p><pre><code class="language-julia-repl">julia&gt; x = rand(1000);

julia&gt; function sum_global()
           s = 0.0
           for i in x
               s += i
           end
           return s
       end;

julia&gt; @time sum_global()
  0.017705 seconds (15.28 k allocations: 694.484 KiB)
496.84883432553846

julia&gt; @time sum_global()
  0.000140 seconds (3.49 k allocations: 70.313 KiB)
496.84883432553846</code></pre><p>在第一次调用函数(<code>@time sum_global()</code>)的时候，它会被编译。（如果你这次会话中还没有使用过<a href="../../base/base/#Base.@time"><code>@time</code></a>，这时也会编译计时需要的相关函数。）你不必认真对待这次运行的结果。接下来看第二次运行，除了运行的耗时以外，它还表明了分配了大量的内存。我们这里仅仅是计算了一个64比特浮点向量元素和，因此这里应该没有申请内存的必要的（至少不用在<code>@time</code>报告的堆上申请内存）。</p><p>未被预料的内存分配往往说明你的代码中存在一些问题，这些问题常常是由于类型的稳定性或者创建了太多临时的小数组。因此，除了分配内存本身，这也很可能说明你所写的函数没有生成最佳的代码。认真对待这些现象，遵循接下来的建议。</p><p>如果你换成将<code>x</code>作为参数传给函数，就可以避免内存的分配（这里报告的内存分配是由于在全局作用域中运行<code>@time</code>导致的），而且在第一次运行之后运行速度也会得到显著的提高。</p><pre><code class="language-julia-repl">julia&gt; x = rand(1000);

julia&gt; function sum_arg(x)
           s = 0.0
           for i in x
               s += i
           end
           return s
       end;

julia&gt; @time sum_arg(x)
  0.007701 seconds (821 allocations: 43.059 KiB)
496.84883432553846

julia&gt; @time sum_arg(x)
  0.000006 seconds (5 allocations: 176 bytes)
496.84883432553846</code></pre><p>这里出现的5个内存分配是由于在全局作用域中运行<code>@time</code>宏导致的。如果我们在函数中运行时间测试，我们将发现事实上并没有发生任何内存分配。</p><pre><code class="language-julia-repl">julia&gt; time_sum(x) = @time sum_arg(x);

julia&gt; time_sum(x)
  0.000001 seconds
496.84883432553846</code></pre><p>在一些情况下，你的函数需要分配新的内存，作为运算的一部分，这就会复杂化上面提到的简单的图像。在这样的情况下，考虑一下使用下面的<a href="#tools-1">工具</a>之一来诊断问题，或者为函数写一个算法和内存分配分离的版本（参见<a href="#Pre-allocating-outputs-1">Pre-allocating outputs</a>）。</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"></div></div><p>对于更加正经的性能测试，考虑一下<a href="https://github.com/JuliaCI/BenchmarkTools.jl">BenchmarkTools.jl</a>包，这个包除了其他方面之外会多次评估函数的性能以降低噪声。</p><h2><a class="nav-anchor" id="tools-1" href="#tools-1">工具</a></h2><p>Julia和其包生态圈包含了能帮助你诊断问题和提高你的代码的性能表现的工具：</p><ul><li><p><a href="../profile/#性能分析-1">性能分析</a>允许你测量你运行的代码的性能表现并找出是性能瓶颈的代码。对于复杂的工程，<a href="https://github.com/timholy/ProfileView.jl">ProfileView</a>能帮你将性能分析结果可视化。</p></li><li><p><a href="https://github.com/MikeInnes/Traceur.jl">Traceur</a>包能帮你找到你代码中的常见性能问题。</p></li><li><p>没有预想到的巨大的内存申请 – 像<a href="../../base/base/#Base.@time"><code>@time</code></a>，<a href="../../base/base/#Base.@allocated"><code>@allocated</code></a> 或者性能分析器（通过对于垃圾回收进程的调用）告诉你的一样 – 提示着你的代码会有问题。 如果没有见到有关内存申请的其他原因，你需要怀疑这是一个类型问题。你也可以通过<code>-track-allocation=user</code>选项开启Julia并检查生成的<code>*.mem</code>文件来检查有关内存申请发生位置的信息。参见<a href="../profile/#内存分配分析-1">内存分配分析</a>。</p></li></ul><p>*<code>@code_warntype</code>生成你的代码的一个表示，对于找到会造成类型不确定的表达式有用。参见下面的<a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a>。</p><h2><a class="nav-anchor" id="避免拥有抽象类型参数的容器-1" href="#避免拥有抽象类型参数的容器-1">避免拥有抽象类型参数的容器</a></h2><p>当处理参数化类型，包括数组，时，最好尽可能避免通过抽象类型进行参数化。</p><p>考虑一下下面的代码：</p><pre><code class="language-julia-repl">julia&gt; a = Real[]
0-element Array{Real,1}

julia&gt; push!(a, 1); push!(a, 2.0); push!(a, π)
3-element Array{Real,1}:
 1
 2.0
 π = 3.1415926535897...</code></pre><p>因为<code>a</code>是一个抽象类型<a href="../../base/numbers/#Core.Real"><code>Real</code></a>的数组，它必须能容纳任何一个<code>Real</code>值。因为<code>Real</code>对象可以有任意的大小和结构，<code>a</code>必须用指针的数组来表示，以便能独立地为<code>Real</code>对象进行内存分配。但是如果我们只允许同样类型的数，比如<a href="../../base/numbers/#Core.Float64"><code>Float64</code></a>，才能存在<code>a</code>中，它们就能被更有效率地存储：</p><pre><code class="language-julia-repl">julia&gt; a = Float64[]
0-element Array{Float64,1}

julia&gt; push!(a, 1); push!(a, 2.0); push!(a,  π)
3-element Array{Float64,1}:
 1.0
 2.0
 3.141592653589793</code></pre><p>把数字赋值给<code>a</code>会即时将数字转换成<code>Float64</code>并且<code>a</code>会按照64位浮点数值的连续的块来储存，这就能高效地处理。</p><p>也请参见在<a href="../types/#参数类型-1">参数类型</a>下的讨论。</p><h2><a class="nav-anchor" id="类型声明-1" href="#类型声明-1">类型声明</a></h2><p>在有可选类型声明的语言中，添加声明是使代码运行更快的原则性方法。在Julia中<em>并不是</em>这种情况。在Julia中，编译器都知道所有的函数参数，局部变量和表达式的类型。但是，有一些特殊的情况下声明是有帮助的。</p><h3><a class="nav-anchor" id="避免有抽象类型的域-1" href="#避免有抽象类型的域-1">避免有抽象类型的域</a></h3><p>类型能在不指定其域的类型的情况下被声明：</p><pre><code class="language-julia-repl">julia&gt; struct MyAmbiguousType
           a
       end</code></pre><p>这就允许<code>a</code>可以是任意类型。这经常很有用，但是有个缺点：对于类型<code>MyAmbiguousType</code>的对象，编译器不能够生成高性能的代码。原因是编译器使用对象的类型，而非值，来确定如何构建代码。不幸的是，几乎没有信息可以从类型<code>MyAmbiguousType</code>的对象中推导出来：</p><pre><code class="language-julia-repl">julia&gt; b = MyAmbiguousType(&quot;Hello&quot;)
MyAmbiguousType(&quot;Hello&quot;)

julia&gt; c = MyAmbiguousType(17)
MyAmbiguousType(17)

julia&gt; typeof(b)
MyAmbiguousType

julia&gt; typeof(c)
MyAmbiguousType</code></pre><p>The values of <code>b</code> and <code>c</code> have the same type, yet their underlying representation of data in memory is very different. Even if you stored just numeric values in field <code>a</code>, the fact that the memory representation of a <a href="../../base/numbers/#Core.UInt8"><code>UInt8</code></a> differs from a <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a> also means that the CPU needs to handle them using two different kinds of instructions. Since the required information is not available in the type, such decisions have to be made at run-time. This slows performance.</p><p>通过声明 <code>a</code> 的类型，你能够做得更好。这里我们关注 <code>a</code> 可能是几种类型中任意一种的情况，在这种情况下，自然的一个解决方法是使用参数。例如：</p><pre><code class="language-julia-repl">julia&gt; mutable struct MyType{T&lt;:AbstractFloat}
           a::T
       end</code></pre><p>比下面这种更好</p><pre><code class="language-julia-repl">julia&gt; mutable struct MyStillAmbiguousType
           a::AbstractFloat
       end</code></pre><p>因为第一种通过包装对象的类型指定了 <code>a</code> 的类型。 例如：</p><pre><code class="language-julia-repl">julia&gt; m = MyType(3.2)
MyType{Float64}(3.2)

julia&gt; t = MyStillAmbiguousType(3.2)
MyStillAmbiguousType(3.2)

julia&gt; typeof(m)
MyType{Float64}

julia&gt; typeof(t)
MyStillAmbiguousType
域 `a` 的类型可以很容易地通过 `m` 的类型确定，而不是通过 `t` 的类型确定。事实上，在 `t` 中是可以改变域 `a` 的类型的：
</code></pre><p>jldoctest myambig2 julia&gt; typeof(t.a) Float64</p><p>julia&gt; t.a = 4.5f0 4.5f0</p><p>julia&gt; typeof(t.a) Float32</p><pre><code class="language-none">
反之，一旦 `m` 被构建出来，`m.a` 的类型就不能够更改了。
</code></pre><p>jldoctest myambig2 julia&gt; m.a = 4.5f0 4.5f0</p><p>julia&gt; typeof(m.a) Float64 <code>m.a</code> 的类型是通过 <code>m</code> 的类型得知这一事实加上它的类型不能改变在函数中改变这一事实，这两者使得对于像 <code>m</code> 这样的对象编译器可以生成高度优化后的代码，但是对 <code>t</code> 这样的对象却不可以。 当然，如果我们将 <code>m</code> 构造成一个具体类型，那么这两者都可以。我们可以通过明确地使用一个抽象类型去构建它来破坏这一点：</p><pre><code class="language-julia-repl">julia&gt; m = MyType{AbstractFloat}(3.2)
MyType{AbstractFloat}(3.2)

julia&gt; typeof(m.a)
Float64

julia&gt; m.a = 4.5f0
4.5f0

julia&gt; typeof(m.a)
Float32</code></pre><p>对于一个实际的目的来说，这样的对象表现起来和那些 <code>MyStillAmbiguousType</code> 的对象一模一样。</p><p>比较为一个简单函数生成的代码的绝对数量是十分有指导意义的，</p><pre><code class="language-julia">func(m::MyType) = m.a+1</code></pre><p>使用</p><pre><code class="language-julia">code_llvm(func, Tuple{MyType{Float64}})
code_llvm(func, Tuple{MyType{AbstractFloat}})</code></pre><p>由于长度的原因，代码的结果没有在这里显示出来，但是你可能会希望自己去验证这一点。因为在第一种情况中，类型被完全指定了，在运行时，编译器不需要生成任何代码来决定类型。这就带来了更短和更快的代码。</p><h3><a class="nav-anchor" id="避免有抽象容器的域-1" href="#避免有抽象容器的域-1">避免有抽象容器的域</a></h3><p>上面的做法同样也适用于容器的类型：</p><pre><code class="language-julia-repl">julia&gt; struct MySimpleContainer{A&lt;:AbstractVector}
           a::A
       end

julia&gt; struct MyAmbiguousContainer{T}
           a::AbstractVector{T}
       end</code></pre><p>例如:</p><pre><code class="language-julia-repl">julia&gt; c = MySimpleContainer(1:3);

julia&gt; typeof(c)
MySimpleContainer{UnitRange{Int64}}

julia&gt; c = MySimpleContainer([1:3;]);

julia&gt; typeof(c)
MySimpleContainer{Array{Int64,1}}

julia&gt; b = MyAmbiguousContainer(1:3);

julia&gt; typeof(b)
MyAmbiguousContainer{Int64}

julia&gt; b = MyAmbiguousContainer([1:3;]);

julia&gt; typeof(b)
MyAmbiguousContainer{Int64}</code></pre><p>对于 <code>MySimpleContainer</code> 来说，它被它的类型和参数完全确定了，因此编译器能够生成优化过的代码。在大多数实例中，这点能够实现。</p><p>尽管编译器现在可以将它的工作做得非常好，但是还是有<strong>你</strong>可能希望你的代码能够能够根据 <code>a</code> 的<strong>元素类型</strong>做不同的事情的时候。通常达成这个目的最好的方式是将你的具体操作 (here, <code>foo</code>) 打包到一个独立的函数中。</p><pre><code class="language-julia-repl">julia&gt; function sumfoo(c::MySimpleContainer)
           s = 0
           for x in c.a
               s += foo(x)
           end
           s
       end
sumfoo (generic function with 1 method)

julia&gt; foo(x::Integer) = x
foo (generic function with 1 method)

julia&gt; foo(x::AbstractFloat) = round(x)
foo (generic function with 2 methods)</code></pre><p>This keeps things simple, while allowing the compiler to generate optimized code in all cases.</p><p>However, there are cases where you may need to declare different versions of the outer function for different element types or types of the <code>AbstractVector</code> of the field <code>a</code> in <code>MySimpleContainer</code>. You could do it like this:</p><pre><code class="language-julia-repl">julia&gt; function myfunc(c::MySimpleContainer{&lt;:AbstractArray{&lt;:Integer}})
           return c.a[1]+1
       end
myfunc (generic function with 1 method)

julia&gt; function myfunc(c::MySimpleContainer{&lt;:AbstractArray{&lt;:AbstractFloat}})
           return c.a[1]+2
       end
myfunc (generic function with 2 methods)

julia&gt; function myfunc(c::MySimpleContainer{Vector{T}}) where T &lt;: Integer
           return c.a[1]+3
       end
myfunc (generic function with 3 methods)</code></pre><pre><code class="language-julia-repl">julia&gt; myfunc(MySimpleContainer(1:3))
2

julia&gt; myfunc(MySimpleContainer(1.0:3))
3.0

julia&gt; myfunc(MySimpleContainer([1:3;]))
4</code></pre><h3><a class="nav-anchor" id="Annotate-values-taken-from-untyped-locations-1" href="#Annotate-values-taken-from-untyped-locations-1">Annotate values taken from untyped locations</a></h3><p>It is often convenient to work with data structures that may contain values of any type (arrays of type <code>Array{Any}</code>). But, if you&#39;re using one of these structures and happen to know the type of an element, it helps to share this knowledge with the compiler:</p><pre><code class="language-julia">function foo(a::Array{Any,1})
    x = a[1]::Int32
    b = x+1
    ...
end</code></pre><p>Here, we happened to know that the first element of <code>a</code> would be an <a href="../../base/numbers/#Core.Int32"><code>Int32</code></a>. Making an annotation like this has the added benefit that it will raise a run-time error if the value is not of the expected type, potentially catching certain bugs earlier.</p><p>In the case that the type of <code>a[1]</code> is not known precisely, <code>x</code> can be declared via <code>x = convert(Int32, a[1])::Int32</code>. The use of the <a href="../../base/base/#Base.convert"><code>convert</code></a> function allows <code>a[1]</code> to be any object convertible to an <code>Int32</code> (such as <code>UInt8</code>), thus increasing the genericity of the code by loosening the type requirement. Notice that <code>convert</code> itself needs a type annotation in this context in order to achieve type stability. This is because the compiler cannot deduce the type of the return value of a function, even <code>convert</code>, unless the types of all the function&#39;s arguments are known.</p><p>Type annotation will not enhance (and can actually hinder) performance if the type is constructed at run-time. This is because the compiler cannot use the annotation to specialize the subsequent code, and the type-check itself takes time. For example, in the code:</p><pre><code class="language-julia">function nr(a, prec)
    ctype = prec == 32 ? Float32 : Float64
    b = Complex{ctype}(a)
    c = (b + 1.0f0)::Complex{ctype}
    abs(c)
end</code></pre><p>the annotation of <code>c</code> harms performance. To write performant code involving types constructed at run-time, use the <a href="#kernal-functions-1">function-barrier technique</a> discussed below, and ensure that the constructed type appears among the argument types of the kernel function so that the kernel operations are properly specialized by the compiler. For example, in the above snippet, as soon as <code>b</code> is constructed, it can be passed to another function <code>k</code>, the kernel. If, for example, function <code>k</code> declares <code>b</code> as an argument of type <code>Complex{T}</code>, where <code>T</code> is a type parameter, then a type annotation appearing in an assignment statement within <code>k</code> of the form:</p><pre><code class="language-julia">c = (b + 1.0f0)::Complex{T}</code></pre><p>does not hinder performance (but does not help either) since the compiler can determine the type of <code>c</code> at the time <code>k</code> is compiled.</p><h3><a class="nav-anchor" id="声明关键参数的类型-1" href="#声明关键参数的类型-1">声明关键参数的类型</a></h3><p>关键参数可以声明类型：</p><pre><code class="language-julia">function with_keyword(x; name::Int = 1)
    ...
end</code></pre><p>Functions are specialized on the types of keyword arguments, so these declarations will not affect performance of code inside the function. However, they will reduce the overhead of calls to the function that include keyword arguments.</p><p>Functions with keyword arguments have near-zero overhead for call sites that pass only positional arguments.</p><p>在性能敏感的代码中应当避免传递像 <code>f(x; keywords...)</code> 的动态列表参数。</p><h2><a class="nav-anchor" id="Break-functions-into-multiple-definitions-1" href="#Break-functions-into-multiple-definitions-1">Break functions into multiple definitions</a></h2><p>将一个函数写成许多小的定义能让编译器直接调用最适合的代码，甚至能够直接将它内联。</p><p>这是一个真的该被写成许多小的定义的<strong>复合函数</strong>的例子：</p><pre><code class="language-julia">using LinearAlgebra

function mynorm(A)
    if isa(A, Vector)
        return sqrt(real(dot(A,A)))
    elseif isa(A, Matrix)
        return maximum(svdvals(A))
    else
        error(&quot;mynorm: invalid argument&quot;)
    end
end</code></pre><p>这可以更简洁有效地写成：</p><pre><code class="language-julia">norm(x::Vector) = sqrt(real(dot(x, x)))
norm(A::Matrix) = maximum(svdvals(A))</code></pre><p>It should however be noted that the compiler is quite efficient at optimizing away the dead branches in code written as the <code>mynorm</code> example.</p><h2><a class="nav-anchor" id="编写「类型稳定的」函数-1" href="#编写「类型稳定的」函数-1">编写「类型稳定的」函数</a></h2><p>如果可能，确保函数总是返回相同类型的值是有好处的。考虑以下定义：</p><pre><code class="language-julia">pos(x) = x &lt; 0 ? 0 : x</code></pre><p>虽然这看起来挺合法的，但问题是 <code>0</code> 是一个（<code>Int</code> 类型的）整数而 <code>x</code> 可能是任何类型。于是，根据 <code>x</code> 的值，此函数可能返回两种类型中任何一种的值。这种行为是允许的，并且在某些情况下可能是合乎需要的。但它可以很容易地以如下方式修复：</p><pre><code class="language-julia">pos(x) = x &lt; 0 ? zero(x) : x</code></pre><p>还有 <a href="../../base/numbers/#Base.oneunit"><code>oneunit</code></a> 函数，以及更通用的 <a href="../../base/base/#Base.oftype"><code>oftype(x, y)</code></a> 函数，它返回被转换为 <code>x</code> 的类型的 <code>y</code>。</p><h2><a class="nav-anchor" id="避免更改变量类型-1" href="#避免更改变量类型-1">避免更改变量类型</a></h2><p>类似的「类型稳定性」问题存在于在函数内重复使用的变量：</p><pre><code class="language-julia">function foo()
    x = 1
    for i = 1:10
        x /= rand()
    end
    return x
end</code></pre><p>局部变量 <code>x</code> 一开始是整数，在一次循环迭代后变为浮点数（<a href="../../base/math/#Base.:/"><code>/</code></a> 运算符的结果）。这使得编译器更难优化循环体。有几种可能的解决方法：</p><ul><li>使用 <code>x = 1.0</code> 初始化 <code>x</code></li><li>声明 <code>x</code> 的类型：<code>x::Float64 = 1</code></li><li>使用显式的类型转换：<code>x = oneunit(Float64)</code></li><li>使用第一个循环迭代初始化，即 <code>x = 1 / rand()</code>，接着循环 <code>for i = 2:10</code></li></ul><h2><a class="nav-anchor" id="kernal-functions-1" href="#kernal-functions-1">Separate kernel functions (aka, function barriers)</a></h2><p>Many functions follow a pattern of performing some set-up work, and then running many iterations to perform a core computation. Where possible, it is a good idea to put these core computations in separate functions. For example, the following contrived function returns an array of a randomly-chosen type:</p><pre><code class="language-julia-repl">julia&gt; function strange_twos(n)
           a = Vector{rand(Bool) ? Int64 : Float64}(undef, n)
           for i = 1:n
               a[i] = 2
           end
           return a
       end;

julia&gt; strange_twos(3)
3-element Array{Float64,1}:
 2.0
 2.0
 2.0</code></pre><p>这应该写作：</p><pre><code class="language-julia-repl">julia&gt; function fill_twos!(a)
           for i = eachindex(a)
               a[i] = 2
           end
       end;

julia&gt; function strange_twos(n)
           a = Vector{rand(Bool) ? Int64 : Float64}(undef, n)
           fill_twos!(a)
           return a
       end;

julia&gt; strange_twos(3)
3-element Array{Float64,1}:
 2.0
 2.0
 2.0</code></pre><p>Julia&#39;s compiler specializes code for argument types at function boundaries, so in the original implementation it does not know the type of <code>a</code> during the loop (since it is chosen randomly). Therefore the second version is generally faster since the inner loop can be recompiled as part of <code>fill_twos!</code> for different types of <code>a</code>.</p><p>第二种形式通常是更好的风格，并且可以带来更多的代码的重复利用。</p><p>This pattern is used in several places in Julia Base. For example, see <code>vcat</code> and <code>hcat</code> in <a href="https://github.com/JuliaLang/julia/blob/40fe264f4ffaa29b749bcf42239a89abdcbba846/base/abstractarray.jl#L1205-L1206"><code>abstractarray.jl</code></a>, or the <a href="../../base/arrays/#Base.fill!"><code>fill!</code></a> function, which we could have used instead of writing our own <code>fill_twos!</code>.</p><p>Functions like <code>strange_twos</code> occur when dealing with data of uncertain type, for example data loaded from an input file that might contain either integers, floats, strings, or something else.</p><h2><a class="nav-anchor" id="Types-with-values-as-parameters-1" href="#Types-with-values-as-parameters-1">Types with values-as-parameters</a></h2><p>比方说你想创建一个每个维度大小都是3的 <code>N</code> 维数组。这种数组可以这样创建：</p><pre><code class="language-julia-repl">julia&gt; A = fill(5.0, (3, 3))
3×3 Array{Float64,2}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>这个方法工作得很好：编译器可以识别出来 <code>A</code> 是一个 <code>Array{Float64,2}</code> 因为它知道填充值 (<code>5.0::Float64</code>) 的类型和维度 (<code>(3, 3)::NTuple{2,Int}</code>).</p><p>但是现在打比方说你想写一个函数，在任何一个维度下，它都创建一个 3×3×... 的数组；你可能会心动地写下一个函数</p><pre><code class="language-julia-repl">julia&gt; function array3(fillval, N)
           fill(fillval, ntuple(d-&gt;3, N))
       end
array3 (generic function with 1 method)

julia&gt; array3(5.0, 2)
3×3 Array{Float64,2}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>这确实有用，但是（你可以自己使用 <code>@code_warntype array3(5.0, 2)</code> 来验证）问题是输出地类型不能被推断出来：参数 <code>N</code> 是一个 <code>Int</code> 类型的<strong>值</strong>，而且类型推断不会（也不能）提前预测它的值。这意味着使用这个函数的结果的代码在每次获取 <code>A</code> 时都不得不保守地检查其类型；这样的代码将会是非常缓慢的。</p><p>Now, one very good way to solve such problems is by using the <a href="#kernal-functions-1">function-barrier technique</a>. However, in some cases you might want to eliminate the type-instability altogether. In such cases, one approach is to pass the dimensionality as a parameter, for example through <code>Val{T}()</code> (see <a href="manual/@ref">&quot;Value types&quot;</a>):</p><pre><code class="language-julia-repl">julia&gt; function array3(fillval, ::Val{N}) where N
           fill(fillval, ntuple(d-&gt;3, Val(N)))
       end
array3 (generic function with 1 method)

julia&gt; array3(5.0, Val(2))
3×3 Array{Float64,2}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>Julia has a specialized version of <code>ntuple</code> that accepts a <code>Val{::Int}</code> instance as the second parameter; by passing <code>N</code> as a type-parameter, you make its &quot;value&quot; known to the compiler. Consequently, this version of <code>array3</code> allows the compiler to predict the return type.</p><p>However, making use of such techniques can be surprisingly subtle. For example, it would be of no help if you called <code>array3</code> from a function like this:</p><pre><code class="language-julia">function call_array3(fillval, n)
    A = array3(fillval, Val(n))
end</code></pre><p>Here, you&#39;ve created the same problem all over again: the compiler can&#39;t guess what <code>n</code> is, so it doesn&#39;t know the <em>type</em> of <code>Val(n)</code>. Attempting to use <code>Val</code>, but doing so incorrectly, can easily make performance <em>worse</em> in many situations. (Only in situations where you&#39;re effectively combining <code>Val</code> with the function-barrier trick, to make the kernel function more efficient, should code like the above be used.)</p><p>一个正确使用 <code>Val</code> 的例子是这样的：</p><pre><code class="language-julia">function filter3(A::AbstractArray{T,N}) where {T,N}
    kernel = array3(1, Val(N))
    filter(A, kernel)
end</code></pre><p>In this example, <code>N</code> is passed as a parameter, so its &quot;value&quot; is known to the compiler. Essentially, <code>Val(T)</code> works only when <code>T</code> is either hard-coded/literal (<code>Val(3)</code>) or already specified in the type-domain.</p><h2><a class="nav-anchor" id="The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)-1" href="#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)-1">The dangers of abusing multiple dispatch (aka, more on types with values-as-parameters)</a></h2><p>Once one learns to appreciate multiple dispatch, there&#39;s an understandable tendency to go crazy and try to use it for everything. For example, you might imagine using it to store information, e.g.</p><pre><code class="language-none">struct Car{Make, Model}
    year::Int
    ...more fields...
end</code></pre><p>and then dispatch on objects like <code>Car{:Honda,:Accord}(year, args...)</code>.</p><p>This might be worthwhile when either of the following are true:</p><ul><li>You require CPU-intensive processing on each <code>Car</code>, and it becomes vastly more efficient if you know the <code>Make</code> and <code>Model</code> at compile time and the total number of different <code>Make</code> or <code>Model</code> that will be used is not too large.</li><li>You have homogenous lists of the same type of <code>Car</code> to process, so that you can store them all in an <code>Array{Car{:Honda,:Accord},N}</code>.</li></ul><p>When the latter holds, a function processing such a homogenous array can be productively specialized: Julia knows the type of each element in advance (all objects in the container have the same concrete type), so Julia can &quot;look up&quot; the correct method calls when the function is being compiled (obviating the need to check at run-time) and thereby emit efficient code for processing the whole list.</p><p>When these do not hold, then it&#39;s likely that you&#39;ll get no benefit; worse, the resulting &quot;combinatorial explosion of types&quot; will be counterproductive. If <code>items[i+1]</code> has a different type than <code>item[i]</code>, Julia has to look up the type at run-time, search for the appropriate method in method tables, decide (via type intersection) which one matches, determine whether it has been JIT-compiled yet (and do so if not), and then make the call. In essence, you&#39;re asking the full type- system and JIT-compilation machinery to basically execute the equivalent of a switch statement or dictionary lookup in your own code.</p><p>Some run-time benchmarks comparing (1) type dispatch, (2) dictionary lookup, and (3) a &quot;switch&quot; statement can be found <a href="https://groups.google.com/forum/#!msg/julia-users/jUMu9A3QKQQ/qjgVWr7vAwAJ">on the mailing list</a>.</p><p>Perhaps even worse than the run-time impact is the compile-time impact: Julia will compile specialized functions for each different <code>Car{Make, Model}</code>; if you have hundreds or thousands of such types, then every function that accepts such an object as a parameter (from a custom <code>get_year</code> function you might write yourself, to the generic <code>push!</code> function in Julia Base) will have hundreds or thousands of variants compiled for it. Each of these increases the size of the cache of compiled code, the length of internal lists of methods, etc. Excess enthusiasm for values-as-parameters can easily waste enormous resources.</p><h2><a class="nav-anchor" id="Access-arrays-in-memory-order,-along-columns-1" href="#Access-arrays-in-memory-order,-along-columns-1">Access arrays in memory order, along columns</a></h2><p>Multidimensional arrays in Julia are stored in column-major order. This means that arrays are stacked one column at a time. This can be verified using the <code>vec</code> function or the syntax <code>[:]</code> as shown below (notice that the array is ordered <code>[1 3 2 4]</code>, not <code>[1 2 3 4]</code>):</p><pre><code class="language-julia-repl">julia&gt; x = [1 2; 3 4]
2×2 Array{Int64,2}:
 1  2
 3  4

julia&gt; x[:]
4-element Array{Int64,1}:
 1
 3
 2
 4</code></pre><p>This convention for ordering arrays is common in many languages like Fortran, Matlab, and R (to name a few). The alternative to column-major ordering is row-major ordering, which is the convention adopted by C and Python (<code>numpy</code>) among other languages. Remembering the ordering of arrays can have significant performance effects when looping over arrays. A rule of thumb to keep in mind is that with column-major arrays, the first index changes most rapidly. Essentially this means that looping will be faster if the inner-most loop index is the first to appear in a slice expression.</p><p>Consider the following contrived example. Imagine we wanted to write a function that accepts a <a href="../../base/arrays/#Base.Vector"><code>Vector</code></a> and returns a square <a href="../../base/arrays/#Base.Matrix"><code>Matrix</code></a> with either the rows or the columns filled with copies of the input vector. Assume that it is not important whether rows or columns are filled with these copies (perhaps the rest of the code can be easily adapted accordingly). We could conceivably do this in at least four ways (in addition to the recommended call to the built-in <a href="../../base/arrays/#Base.repeat"><code>repeat</code></a>):</p><pre><code class="language-julia">function copy_cols(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for i = inds
        out[:, i] = x
    end
    return out
end

function copy_rows(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for i = inds
        out[i, :] = x
    end
    return out
end

function copy_col_row(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for col = inds, row = inds
        out[row, col] = x[row]
    end
    return out
end

function copy_row_col(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for row = inds, col = inds
        out[row, col] = x[col]
    end
    return out
end</code></pre><p>Now we will time each of these functions using the same random <code>10000</code> by <code>1</code> input vector:</p><pre><code class="language-julia-repl">julia&gt; x = randn(10000);

julia&gt; fmt(f) = println(rpad(string(f)*&quot;: &quot;, 14, &#39; &#39;), @elapsed f(x))

julia&gt; map(fmt, Any[copy_cols, copy_rows, copy_col_row, copy_row_col]);
copy_cols:    0.331706323
copy_rows:    1.799009911
copy_col_row: 0.415630047
copy_row_col: 1.721531501</code></pre><p>Notice that <code>copy_cols</code> is much faster than <code>copy_rows</code>. This is expected because <code>copy_cols</code> respects the column-based memory layout of the <code>Matrix</code> and fills it one column at a time. Additionally, <code>copy_col_row</code> is much faster than <code>copy_row_col</code> because it follows our rule of thumb that the first element to appear in a slice expression should be coupled with the inner-most loop.</p><h2><a class="nav-anchor" id="Pre-allocating-outputs-1" href="#Pre-allocating-outputs-1">Pre-allocating outputs</a></h2><p>If your function returns an <code>Array</code> or some other complex type, it may have to allocate memory. Unfortunately, oftentimes allocation and its converse, garbage collection, are substantial bottlenecks.</p><p>Sometimes you can circumvent the need to allocate memory on each function call by preallocating the output. As a trivial example, compare</p><pre><code class="language-julia-repl">julia&gt; function xinc(x)
           return [x, x+1, x+2]
       end;

julia&gt; function loopinc()
           y = 0
           for i = 1:10^7
               ret = xinc(i)
               y += ret[2]
           end
           return y
       end;</code></pre><p>with</p><pre><code class="language-julia-repl">julia&gt; function xinc!(ret::AbstractVector{T}, x::T) where T
           ret[1] = x
           ret[2] = x+1
           ret[3] = x+2
           nothing
       end;

julia&gt; function loopinc_prealloc()
           ret = Vector{Int}(undef, 3)
           y = 0
           for i = 1:10^7
               xinc!(ret, i)
               y += ret[2]
           end
           return y
       end;</code></pre><p>Timing results:</p><pre><code class="language-julia-repl">julia&gt; @time loopinc()
  0.529894 seconds (40.00 M allocations: 1.490 GiB, 12.14% gc time)
50000015000000

julia&gt; @time loopinc_prealloc()
  0.030850 seconds (6 allocations: 288 bytes)
50000015000000</code></pre><p>Preallocation has other advantages, for example by allowing the caller to control the &quot;output&quot; type from an algorithm. In the example above, we could have passed a <code>SubArray</code> rather than an <a href="../../base/arrays/#Core.Array"><code>Array</code></a>, had we so desired.</p><p>Taken to its extreme, pre-allocation can make your code uglier, so performance measurements and some judgment may be required. However, for &quot;vectorized&quot; (element-wise) functions, the convenient syntax <code>x .= f.(y)</code> can be used for in-place operations with fused loops and no temporary arrays (see the <a href="../functions/#man-vectorized-1">dot syntax for vectorizing functions</a>).</p><h2><a class="nav-anchor" id="More-dots:-Fuse-vectorized-operations-1" href="#More-dots:-Fuse-vectorized-operations-1">More dots: Fuse vectorized operations</a></h2><p>Julia has a special <a href="../functions/#man-vectorized-1">dot syntax</a> that converts any scalar function into a &quot;vectorized&quot; function call, and any operator into a &quot;vectorized&quot; operator, with the special property that nested &quot;dot calls&quot; are <em>fusing</em>: they are combined at the syntax level into a single loop, without allocating temporary arrays. If you use <code>.=</code> and similar assignment operators, the result can also be stored in-place in a pre-allocated array (see above).</p><p>In a linear-algebra context, this means that even though operations like <code>vector + vector</code> and <code>vector * scalar</code> are defined, it can be advantageous to instead use <code>vector .+ vector</code> and <code>vector .* scalar</code> because the resulting loops can be fused with surrounding computations. For example, consider the two functions:</p><pre><code class="language-julia-repl">julia&gt; f(x) = 3x.^2 + 4x + 7x.^3;

julia&gt; fdot(x) = @. 3x^2 + 4x + 7x^3 # equivalent to 3 .* x.^2 .+ 4 .* x .+ 7 .* x.^3;</code></pre><p>Both <code>f</code> and <code>fdot</code> compute the same thing. However, <code>fdot</code> (defined with the help of the <a href="../../base/arrays/#Base.Broadcast.@__dot__"><code>@.</code></a> macro) is significantly faster when applied to an array:</p><pre><code class="language-julia-repl">julia&gt; x = rand(10^6);

julia&gt; @time f(x);
  0.019049 seconds (16 allocations: 45.777 MiB, 18.59% gc time)

julia&gt; @time fdot(x);
  0.002790 seconds (6 allocations: 7.630 MiB)

julia&gt; @time f.(x);
  0.002626 seconds (8 allocations: 7.630 MiB)</code></pre><p>That is, <code>fdot(x)</code> is ten times faster and allocates 1/6 the memory of <code>f(x)</code>, because each <code>*</code> and <code>+</code> operation in <code>f(x)</code> allocates a new temporary array and executes in a separate loop. (Of course, if you just do <code>f.(x)</code> then it is as fast as <code>fdot(x)</code> in this example, but in many contexts it is more convenient to just sprinkle some dots in your expressions rather than defining a separate function for each vectorized operation.)</p><h2><a class="nav-anchor" id="Consider-using-views-for-slices-1" href="#Consider-using-views-for-slices-1">Consider using views for slices</a></h2><p>In Julia, an array &quot;slice&quot; expression like <code>array[1:5, :]</code> creates a copy of that data (except on the left-hand side of an assignment, where <code>array[1:5, :] = ...</code> assigns in-place to that portion of <code>array</code>). If you are doing many operations on the slice, this can be good for performance because it is more efficient to work with a smaller contiguous copy than it would be to index into the original array. On the other hand, if you are just doing a few simple operations on the slice, the cost of the allocation and copy operations can be substantial.</p><p>An alternative is to create a &quot;view&quot; of the array, which is an array object (a <code>SubArray</code>) that actually references the data of the original array in-place, without making a copy. (If you write to a view, it modifies the original array&#39;s data as well.) This can be done for individual slices by calling <a href="../../base/arrays/#Base.view"><code>view</code></a>, or more simply for a whole expression or block of code by putting <a href="../../base/arrays/#Base.@views"><code>@views</code></a> in front of that expression. For example:</p><pre><code class="language-julia-repl">julia&gt; fcopy(x) = sum(x[2:end-1]);

julia&gt; @views fview(x) = sum(x[2:end-1]);

julia&gt; x = rand(10^6);

julia&gt; @time fcopy(x);
  0.003051 seconds (7 allocations: 7.630 MB)

julia&gt; @time fview(x);
  0.001020 seconds (6 allocations: 224 bytes)</code></pre><p>Notice both the 3× speedup and the decreased memory allocation of the <code>fview</code> version of the function.</p><h2><a class="nav-anchor" id="Copying-data-is-not-always-bad-1" href="#Copying-data-is-not-always-bad-1">Copying data is not always bad</a></h2><p>Arrays are stored contiguously in memory, lending themselves to CPU vectorization and fewer memory accesses due to caching. These are the same reasons that it is recommended to access arrays in column-major order (see above). Irregular access patterns and non-contiguous views can drastically slow down computations on arrays because of non-sequential memory access.</p><p>Copying irregularly-accessed data into a contiguous array before operating on it can result in a large speedup, such as in the example below. Here, a matrix and a vector are being accessed at 800,000 of their randomly-shuffled indices before being multiplied. Copying the views into plain arrays speeds up the multiplication even with the cost of the copying operation.</p><pre><code class="language-julia-repl">julia&gt; using Random

julia&gt; x = randn(1_000_000);

julia&gt; inds = shuffle(1:1_000_000)[1:800000];

julia&gt; A = randn(50, 1_000_000);

julia&gt; xtmp = zeros(800_000);

julia&gt; Atmp = zeros(50, 800_000);

julia&gt; @time sum(view(A, :, inds) * view(x, inds))
  0.412156 seconds (14 allocations: 960 bytes)
-4256.759568345458

julia&gt; @time begin
           copyto!(xtmp, view(x, inds))
           copyto!(Atmp, view(A, :, inds))
           sum(Atmp * xtmp)
       end
  0.285923 seconds (14 allocations: 960 bytes)
-4256.759568345134</code></pre><p>Provided there is enough memory for the copies, the cost of copying the view to an array is far outweighed by the speed boost from doing the matrix multiplication on a contiguous array.</p><h2><a class="nav-anchor" id="Avoid-string-interpolation-for-I/O-1" href="#Avoid-string-interpolation-for-I/O-1">Avoid string interpolation for I/O</a></h2><p>When writing data to a file (or other I/O device), forming extra intermediate strings is a source of overhead. Instead of:</p><pre><code class="language-julia">println(file, &quot;$a $b&quot;)</code></pre><p>请写成这样：</p><pre><code class="language-julia">println(file, a, &quot; &quot;, b)</code></pre><p>The first version of the code forms a string, then writes it to the file, while the second version writes values directly to the file. Also notice that in some cases string interpolation can be harder to read. Consider:</p><pre><code class="language-julia">println(file, &quot;$(f(a))$(f(b))&quot;)</code></pre><p>versus:</p><pre><code class="language-julia">println(file, f(a), f(b))</code></pre><h2><a class="nav-anchor" id="Optimize-network-I/O-during-parallel-execution-1" href="#Optimize-network-I/O-during-parallel-execution-1">Optimize network I/O during parallel execution</a></h2><p>When executing a remote function in parallel:</p><pre><code class="language-julia">using Distributed

responses = Vector{Any}(undef, nworkers())
@sync begin
    for (idx, pid) in enumerate(workers())
        @async responses[idx] = remotecall_fetch(pid, foo, args...)
    end
end</code></pre><p>is faster than:</p><pre><code class="language-julia">using Distributed

refs = Vector{Any}(undef, nworkers())
for (idx, pid) in enumerate(workers())
    refs[idx] = @spawnat pid foo(args...)
end
responses = [fetch(r) for r in refs]</code></pre><p>The former results in a single network round-trip to every worker, while the latter results in two network calls - first by the <a href="../../stdlib/Distributed/#Distributed.@spawnat"><code>@spawnat</code></a> and the second due to the <a href="../../base/parallel/#Base.fetch-Tuple{Channel}"><code>fetch</code></a> (or even a <a href="../../stdlib/Distributed/#Base.wait"><code>wait</code></a>). The <a href="../../base/parallel/#Base.fetch-Tuple{Channel}"><code>fetch</code></a>/<a href="../../stdlib/Distributed/#Base.wait"><code>wait</code></a> is also being executed serially resulting in an overall poorer performance.</p><h2><a class="nav-anchor" id="Fix-deprecation-warnings-1" href="#Fix-deprecation-warnings-1">Fix deprecation warnings</a></h2><p>A deprecated function internally performs a lookup in order to print a relevant warning only once. This extra lookup can cause a significant slowdown, so all uses of deprecated functions should be modified as suggested by the warnings.</p><h2><a class="nav-anchor" id="Tweaks-1" href="#Tweaks-1">Tweaks</a></h2><p>These are some minor points that might help in tight inner loops.</p><ul><li>Avoid unnecessary arrays. For example, instead of <a href="../../base/collections/#Base.sum"><code>sum([x,y,z])</code></a> use <code>x+y+z</code>.</li><li>Use <a href="../../base/math/#Base.abs2"><code>abs2(z)</code></a> instead of <a href="../../base/strings/#Base.:^-Tuple{AbstractString,Integer}"><code>abs(z)^2</code></a> for complex <code>z</code>. In general, try to rewrite code to use <a href="../../base/math/#Base.abs2"><code>abs2</code></a> instead of <a href="../../base/math/#Base.abs"><code>abs</code></a> for complex arguments.</li><li>Use <a href="../../base/math/#Base.div"><code>div(x,y)</code></a> for truncating division of integers instead of <a href="../../stdlib/Dates/#Base.trunc-Tuple{TimeType,Type{Period}}"><code>trunc(x/y)</code></a>, <a href="../../base/math/#Base.fld"><code>fld(x,y)</code></a> instead of <a href="../../stdlib/Dates/#Base.floor-Tuple{TimeType,Period}"><code>floor(x/y)</code></a>, and <a href="../../base/math/#Base.cld"><code>cld(x,y)</code></a> instead of <a href="../../stdlib/Dates/#Base.ceil-Tuple{TimeType,Period}"><code>ceil(x/y)</code></a>.</li></ul><h2><a class="nav-anchor" id="man-performance-annotations-1" href="#man-performance-annotations-1">Performance Annotations</a></h2><p>Sometimes you can enable better optimization by promising certain program properties.</p><ul><li>Use <a href="../../base/base/#Base.@inbounds"><code>@inbounds</code></a> to eliminate array bounds checking within expressions. Be certain before doing 如果下标越界，会发生崩溃或潜在的故障</li><li>Use <a href="../../base/math/#Base.FastMath.@fastmath"><code>@fastmath</code></a> to allow floating point optimizations that are correct for real numbers, but lead to differences for IEEE numbers. Be careful when doing this, as this may change numerical results. This corresponds to the <code>-ffast-math</code> option of clang.</li><li>Write <a href="../../base/base/#Base.SimdLoop.@simd"><code>@simd</code></a> in front of <code>for</code> loops to promise that the iterations are independent and may be reordered.  Note that in many cases, Julia can automatically vectorize code without the <code>@simd</code> macro; it is only beneficial in cases where such a transformation would otherwise be illegal, including cases like allowing floating-point re-associativity and ignoring dependent memory accesses (<code>@simd ivdep</code>). Again, be very careful when asserting <code>@simd</code> as erroneously annotating a loop with dependent iterations may result in unexpected results. In particular, note that <code>setindex!</code> on some <code>AbstractArray</code> subtypes is inherently dependent upon iteration order. <strong>This feature is experimental</strong> and could change or disappear in future versions of Julia.</li></ul><p>The common idiom of using 1:n to index into an AbstractArray is not safe if the Array uses unconventional indexing, and may cause a segmentation fault if bounds checking is turned off. Use <code>LinearIndices(x)</code> or <code>eachindex(x)</code> instead (see also <a href="https://docs.julialang.org/en/latest/devdocs/offset-arrays">offset-arrays</a>).</p><p>!!!note     While <code>@simd</code> needs to be placed directly in front of an innermost <code>for</code> loop, both <code>@inbounds</code> and <code>@fastmath</code>     can be applied to either single expressions or all the expressions that appear within nested blocks of code, e.g.,     using <code>@inbounds begin</code> or <code>@inbounds for ...</code>.</p><p>Here is an example with both <code>@inbounds</code> and <code>@simd</code> markup (we here use <code>@noinline</code> to prevent the optimizer from trying to be too clever and defeat our benchmark):</p><pre><code class="language-julia">@noinline function inner(x, y)
    s = zero(eltype(x))
    for i=eachindex(x)
        @inbounds s += x[i]*y[i]
    end
    return s
end

@noinline function innersimd(x, y)
    s = zero(eltype(x))
    @simd for i = eachindex(x)
        @inbounds s += x[i] * y[i]
    end
    return s
end

function timeit(n, reps)
    x = rand(Float32, n)
    y = rand(Float32, n)
    s = zero(Float64)
    time = @elapsed for j in 1:reps
        s += inner(x, y)
    end
    println(&quot;GFlop/sec        = &quot;, 2n*reps / time*1E-9)
    time = @elapsed for j in 1:reps
        s += innersimd(x, y)
    end
    println(&quot;GFlop/sec (SIMD) = &quot;, 2n*reps / time*1E-9)
end

timeit(1000, 1000)</code></pre><p>On a computer with a 2.4GHz Intel Core i5 processor, this produces:</p><pre><code class="language-none">GFlop/sec        = 1.9467069505224963
GFlop/sec (SIMD) = 17.578554163920018</code></pre><p>(<code>GFlop/sec</code> measures the performance, and larger numbers are better.)</p><p>Here is an example with all three kinds of markup. This program first calculates the finite difference of a one-dimensional array, and then evaluates the L2-norm of the result:</p><pre><code class="language-julia">function init!(u::Vector)
    n = length(u)
    dx = 1.0 / (n-1)
    @fastmath @inbounds @simd for i in 1:n #by asserting that `u` is a `Vector` we can assume it has 1-based indexing
        u[i] = sin(2pi*dx*i)
    end
end

function deriv!(u::Vector, du)
    n = length(u)
    dx = 1.0 / (n-1)
    @fastmath @inbounds du[1] = (u[2] - u[1]) / dx
    @fastmath @inbounds @simd for i in 2:n-1
        du[i] = (u[i+1] - u[i-1]) / (2*dx)
    end
    @fastmath @inbounds du[n] = (u[n] - u[n-1]) / dx
end

function mynorm(u::Vector)
    n = length(u)
    T = eltype(u)
    s = zero(T)
    @fastmath @inbounds @simd for i in 1:n
        s += u[i]^2
    end
    @fastmath @inbounds return sqrt(s/n)
end

function main()
    n = 2000
    u = Vector{Float64}(undef, n)
    init!(u)
    du = similar(u)

    deriv!(u, du)
    nu = mynorm(du)

    @time for i in 1:10^6
        deriv!(u, du)
        nu = mynorm(du)
    end

    println(nu)
end

main()</code></pre><p>On a computer with a 2.7 GHz Intel Core i7 processor, this produces:</p><pre><code class="language-none">$ julia wave.jl;
  1.207814709 seconds
4.443986180758249

$ julia --math-mode=ieee wave.jl;
  4.487083643 seconds
4.443986180758249</code></pre><p>Here, the option <code>--math-mode=ieee</code> disables the <code>@fastmath</code> macro, so that we can compare results.</p><p>In this case, the speedup due to <code>@fastmath</code> is a factor of about 3.7. This is unusually large – in general, the speedup will be smaller. (In this particular example, the working set of the benchmark is small enough to fit into the L1 cache of the processor, so that memory access latency does not play a role, and computing time is dominated by CPU usage. In many real world programs this is not the case.) Also, in this case this optimization does not change the result – in general, the result will be slightly different. In some cases, especially for numerically unstable algorithms, the result can be very different.</p><p>The annotation <code>@fastmath</code> re-arranges floating point expressions, e.g. changing the order of evaluation, or assuming that certain special cases (inf, nan) cannot occur. In this case (and on this particular computer), the main difference is that the expression <code>1 / (2*dx)</code> in the function <code>deriv</code> is hoisted out of the loop (i.e. calculated outside the loop), as if one had written <code>idx = 1 / (2*dx)</code>. In the loop, the expression <code>... / (2*dx)</code> then becomes <code>... * idx</code>, which is much faster to evaluate. Of course, both the actual optimization that is applied by the compiler as well as the resulting speedup depend very much on the hardware. You can examine the change in generated code by using Julia&#39;s <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.code_native"><code>code_native</code></a> function.</p><p>Note that <code>@fastmath</code> also assumes that <code>NaN</code>s will not occur during the computation, which can lead to surprising behavior:</p><pre><code class="language-julia-repl">julia&gt; f(x) = isnan(x);

julia&gt; f(NaN)
true

julia&gt; f_fast(x) = @fastmath isnan(x);

julia&gt; f_fast(NaN)
false</code></pre><h2><a class="nav-anchor" id="Treat-Subnormal-Numbers-as-Zeros-1" href="#Treat-Subnormal-Numbers-as-Zeros-1">Treat Subnormal Numbers as Zeros</a></h2><p>Subnormal numbers, formerly called <a href="https://en.wikipedia.org/wiki/Denormal_number">denormal numbers</a>, are useful in many contexts, but incur a performance penalty on some hardware. A call <a href="../../base/numbers/#Base.Rounding.set_zero_subnormals"><code>set_zero_subnormals(true)</code></a> grants permission for floating-point operations to treat subnormal inputs or outputs as zeros, which may improve performance on some hardware. A call <a href="../../base/numbers/#Base.Rounding.set_zero_subnormals"><code>set_zero_subnormals(false)</code></a> enforces strict IEEE behavior for subnormal numbers.</p><p>Below is an example where subnormals noticeably impact performance on some hardware:</p><pre><code class="language-julia">function timestep(b::Vector{T}, a::Vector{T}, Δt::T) where T
    @assert length(a)==length(b)
    n = length(b)
    b[1] = 1                            # Boundary condition
    for i=2:n-1
        b[i] = a[i] + (a[i-1] - T(2)*a[i] + a[i+1]) * Δt
    end
    b[n] = 0                            # Boundary condition
end

function heatflow(a::Vector{T}, nstep::Integer) where T
    b = similar(a)
    for t=1:div(nstep,2)                # Assume nstep is even
        timestep(b,a,T(0.1))
        timestep(a,b,T(0.1))
    end
end

heatflow(zeros(Float32,10),2)           # Force compilation
for trial=1:6
    a = zeros(Float32,1000)
    set_zero_subnormals(iseven(trial))  # Odd trials use strict IEEE arithmetic
    @time heatflow(a,1000)
end</code></pre><p>This gives an output similar to</p><pre><code class="language-none">  0.002202 seconds (1 allocation: 4.063 KiB)
  0.001502 seconds (1 allocation: 4.063 KiB)
  0.002139 seconds (1 allocation: 4.063 KiB)
  0.001454 seconds (1 allocation: 4.063 KiB)
  0.002115 seconds (1 allocation: 4.063 KiB)
  0.001455 seconds (1 allocation: 4.063 KiB)</code></pre><p>Note how each even iteration is significantly faster.</p><p>This example generates many subnormal numbers because the values in <code>a</code> become an exponentially decreasing curve, which slowly flattens out over time.</p><p>Treating subnormals as zeros should be used with caution, because doing so breaks some identities, such as <code>x-y == 0</code> implies <code>x == y</code>:</p><pre><code class="language-julia-repl">julia&gt; x = 3f-38; y = 2f-38;

julia&gt; set_zero_subnormals(true); (x - y, x == y)
(0.0f0, false)

julia&gt; set_zero_subnormals(false); (x - y, x == y)
(1.0000001f-38, false)</code></pre><p>In some applications, an alternative to zeroing subnormal numbers is to inject a tiny bit of noise.  For example, instead of initializing <code>a</code> with zeros, initialize it with:</p><pre><code class="language-julia">a = rand(Float32,1000) * 1.f-9</code></pre><h2><a class="nav-anchor" id="man-code-warntype-1" href="#man-code-warntype-1"><a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a></a></h2><p>The macro <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a> (or its function variant <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.code_warntype"><code>code_warntype</code></a>) can sometimes be helpful in diagnosing type-related problems. Here&#39;s an example:</p><pre><code class="language-julia-repl">julia&gt; @noinline pos(x) = x &lt; 0 ? 0 : x;

julia&gt; function f(x)
           y = pos(x)
           sin(y*x + 1)
       end;

julia&gt; @code_warntype f(3.2)
Body::Float64
2 1 ─ %1  = invoke Main.pos(%%x::Float64)::UNION{FLOAT64, INT64}
3 │   %2  = isa(%1, Float64)::Bool
  └──       goto 3 if not %2
  2 ─ %4  = π (%1, Float64)
  │   %5  = Base.mul_float(%4, %%x)::Float64
  └──       goto 6
  3 ─ %7  = isa(%1, Int64)::Bool
  └──       goto 5 if not %7
  4 ─ %9  = π (%1, Int64)
  │   %10 = Base.sitofp(Float64, %9)::Float64
  │   %11 = Base.mul_float(%10, %%x)::Float64
  └──       goto 6
  5 ─       Base.error(&quot;fatal error in type inference (type bound)&quot;)
  └──       unreachable
  6 ┄ %15 = φ (2 =&gt; %5, 4 =&gt; %11)::Float64
  │   %16 = Base.add_float(%15, 1.0)::Float64
  │   %17 = invoke Main.sin(%16::Float64)::Float64
  └──       return %17</code></pre><p>Interpreting the output of <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a>, like that of its cousins <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_lowered"><code>@code_lowered</code></a>, <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_typed"><code>@code_typed</code></a>, <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_llvm"><code>@code_llvm</code></a>, and <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_native"><code>@code_native</code></a>, takes a little practice. Your code is being presented in form that has been heavily digested on its way to generating compiled machine code. Most of the expressions are annotated by a type, indicated by the <code>::T</code> (where <code>T</code> might be <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a>, for example). The most important characteristic of <a href="../../stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a> is that non-concrete types are displayed in red; in the above example, such output is shown in uppercase.</p><p>At the top, the inferred return type of the function is shown as <code>Body::Float64</code>. The next lines represent the body of <code>f</code> in Julia&#39;s SSA IR form. The numbered boxes are labels and represent targets for jumps (via <code>goto</code>) in your code. Looking at the body, you can see that the first thing that happens is that <code>pos</code> is called and the return value has been inferred as the <code>Union</code> type <code>UNION{FLOAT64, INT64}</code> shown in uppercase since it is a non-concrete type. This means that we cannot know the exact return type of <code>pos</code> based on the input types. However, the result of <code>y*x</code>is a <code>Float64</code> no matter if <code>y</code> is a <code>Float64</code> or <code>Int64</code> The net result is that <code>f(x::Float64)</code> will not be type-unstable in its output, even if some of the intermediate computations are type-unstable.</p><p>How you use this information is up to you. Obviously, it would be far and away best to fix <code>pos</code> to be type-stable: if you did so, all of the variables in <code>f</code> would be concrete, and its performance would be optimal. However, there are circumstances where this kind of <em>ephemeral</em> type instability might not matter too much: for example, if <code>pos</code> is never used in isolation, the fact that <code>f</code>&#39;s output is type-stable (for <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a> inputs) will shield later code from the propagating effects of type instability. This is particularly relevant in cases where fixing the type instability is difficult or impossible. In such cases, the tips above (e.g., adding type annotations and/or breaking up functions) are your best tools to contain the &quot;damage&quot; from type instability. Also, note that even Julia Base has functions that are type unstable. For example, the function <a href="../../base/strings/#Base.findfirst-Tuple{AbstractString,AbstractString}"><code>findfirst</code></a> returns the index into an array where a key is found, or <code>nothing</code> if it is not found, a clear type instability. In order to make it easier to find the type instabilities that are likely to be important, <code>Union</code>s containing either <code>missing</code> or <code>nothing</code> are color highlighted in yellow, instead of red.</p><p>The following examples may help you interpret expressions marked as containing non-leaf types:</p><ul><li><p>Function body starting with <code>Body::UNION{T1,T2})</code></p><ul><li>Interpretation: function with unstable return type</li><li>Suggestion: make the return value type-stable, even if you have to annotate it</li></ul></li><li><p><code>invoke Main.g(%%x::Int64)::UNION{FLOAT64, INT64}</code></p><ul><li>Interpretation: call to a type-unstable function <code>g</code>.</li><li>Suggestion: fix the function, or if necessary annotate the return value</li></ul></li><li><p><code>invoke Base.getindex(%%x::Array{Any,1}, 1::Int64)::ANY</code></p><ul><li>Interpretation: accessing elements of poorly-typed arrays</li><li>Suggestion: use arrays with better-defined types, or if necessary annotate the type of individual element accesses</li></ul></li><li><p><code>Base.getfield(%%x, :(:data))::ARRAY{FLOAT64,N} WHERE N</code></p><ul><li>Interpretation: getting a field that is of non-leaf type. In this case, <code>ArrayContainer</code> had a field <code>data::Array{T}</code>. But <code>Array</code> needs the dimension <code>N</code>, too, to be a concrete type.</li><li>Suggestion: use concrete types like <code>Array{T,3}</code> or <code>Array{T,N}</code>, where <code>N</code> is now a parameter of <code>ArrayContainer</code></li></ul></li></ul><h2><a class="nav-anchor" id="man-performance-captured-1" href="#man-performance-captured-1">被捕获变量的性能</a></h2><p>请考虑以下定义内部函数的示例：</p><pre><code class="language-julia">function abmult(r::Int)
    if r &lt; 0
        r = -r
    end
    f = x -&gt; x * r
    return f
end</code></pre><p>函数 <code>abmult</code> 返回一个函数 <code>f</code>，它将其参数乘以 <code>r</code> 的绝对值。赋值给 <code>f</code> 的函数称为「闭包」。内部函数还被语言用于 <code>do</code> 代码块和生成器表达式。</p><p>这种代码风格为语言带来了性能挑战。解析器在将其转换为较低级别的指令时，基本上通过将内部函数提取到单独的代码块来重新组织上述代码。「被捕获的」变量，比如 <code>r</code>，被内部函数共享，且包含它们的作用域会被提取到内部函数和外部函数皆可访问的堆分配「box」中，这是因为语言指定内部作用域中的 <code>r</code> 必须与外部作用域中的 <code>r</code> 相同，就算在外部作用域（或另一个内部函数）修改 <code>r</code> 后也需如此。</p><p>前一段的讨论中提到了「解析器」，也就是，包含 <code>abmult</code> 的模块被首次加载时发生的编译前期，而不是首次调用它的编译后期。解析器不「知道」<code>Int</code> 是固定类型，也不知道语句 <code>r = -r</code> 将一个 <code>Int</code> 转换为另一个 <code>Int</code>。类型推断的魔力在编译后期生效。</p><p>因此，解析器不知道 <code>r</code> 具有固定类型（<code>Int</code>）。一旦内部函数被创建，<code>r</code> 的值也不会改变（因此也不需要 box）。因此，解析器向包含具有抽象类型（比如 <code>Any</code>）的对象的 box 发出代码，这对于每次出现的 <code>r</code> 都需要运行时类型分派。这可以通过在上述函数中使用 <code>@code_warntype</code> 来验证。装箱和运行时的类型分派都有可能导致性能损失。</p><p>如果捕获的变量用于代码的性能关键部分，那么以下提示有助于确保它们的使用具有高效性。首先，如果已经知道被捕获的变量不会改变类型，则可以使用类型注释来显式声明类型（在变量上，而不是在右侧）：</p><pre><code class="language-julia">function abmult2(r0::Int)
    r::Int = r0
    if r &lt; 0
        r = -r
    end
    f = x -&gt; x * r
    return f
end</code></pre><p>类型注释部分恢复由于捕获而导致的丢失性能，因为解析器可以将具体类型与 box 中的对象相关联。更进一步，如果被捕获的变量不再需要 box（因为它不会在闭包创建后被重新分配），就可以用 <code>let</code> 代码块表示，如下所示。</p><pre><code class="language-julia">function abmult3(r::Int)
    if r &lt; 0
        r = -r
    end
    f = let r = r
            x -&gt; x * r
    end
    return f
end</code></pre><p><code>let</code> 代码块创建了一个新的变量 <code>r</code>，它的作用域只是内部函数。第二种技术在捕获变量存在时完全恢复了语言性能。请注意，这是编译器的一个快速发展的方面，未来的版本可能不需要依靠这种程度的程序员注释来获得性能。与此同时，一些用户提供的包（如 <a href="https://github.com/c42f/FastClosures.jl">FastClosures</a>）会自动插入像在 <code>abmult3</code> 中那样的 <code>let</code> 语句。</p><footer><hr/><a class="previous" href="../stacktraces/"><span class="direction">上一篇</span><span class="title">栈跟踪</span></a><a class="next" href="../workflow-tips/"><span class="direction">下一篇</span><span class="title">工作流程建议</span></a></footer></article></body></html>
