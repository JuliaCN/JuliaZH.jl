<!DOCTYPE html>
<html lang="zh-cn"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>线性代数 · Julia中文文档</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-28835595-9', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link rel="canonical" href="https://juliacn.github.io/JuliaZH.jl/latest/stdlib/LinearAlgebra/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/julia-manual.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Julia中文文档 logo"/></a><div class="docs-package-name"><span class="docs-autofit">Julia中文文档</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">主页</a></li><li><span class="tocitem">手册</span><ul><li><a class="tocitem" href="../../manual/getting-started/">入门</a></li><li><a class="tocitem" href="../../manual/variables/">变量</a></li><li><a class="tocitem" href="../../manual/integers-and-floating-point-numbers/">整数和浮点数</a></li><li><a class="tocitem" href="../../manual/mathematical-operations/">数学运算和初等函数</a></li><li><a class="tocitem" href="../../manual/complex-and-rational-numbers/">复数和有理数</a></li><li><a class="tocitem" href="../../manual/strings/">字符串</a></li><li><a class="tocitem" href="../../manual/functions/">函数</a></li><li><a class="tocitem" href="../../manual/control-flow/">流程控制</a></li><li><a class="tocitem" href="../../manual/variables-and-scoping/">变量作用域</a></li><li><a class="tocitem" href="../../manual/types/">类型</a></li><li><a class="tocitem" href="../../manual/methods/">方法</a></li><li><a class="tocitem" href="../../manual/constructors/">构造函数</a></li><li><a class="tocitem" href="../../manual/conversion-and-promotion/">类型转换和类型提升</a></li><li><a class="tocitem" href="../../manual/interfaces/">接口</a></li><li><a class="tocitem" href="../../manual/modules/">模块</a></li><li><a class="tocitem" href="../../manual/documentation/">文档</a></li><li><a class="tocitem" href="../../manual/metaprogramming/">元编程</a></li><li><a class="tocitem" href="../../manual/arrays/">多维数组</a></li><li><a class="tocitem" href="../../manual/missing/">缺失值</a></li><li><a class="tocitem" href="../../manual/networking-and-streams/">网络和流</a></li><li><a class="tocitem" href="../../manual/parallel-computing/">并行计算</a></li><li><a class="tocitem" href="../../manual/running-external-programs/">运行外部程序</a></li><li><a class="tocitem" href="../../manual/calling-c-and-fortran-code/">调用 C 和 Fortran 代码</a></li><li><a class="tocitem" href="../../manual/handling-operating-system-variation/">处理操作系统差异</a></li><li><a class="tocitem" href="../../manual/environment-variables/">环境变量</a></li><li><a class="tocitem" href="../../manual/embedding/">嵌入 Julia</a></li><li><a class="tocitem" href="../../manual/code-loading/">代码加载</a></li><li><a class="tocitem" href="../../manual/profile/">性能分析</a></li><li><a class="tocitem" href="../../manual/stacktraces/">栈跟踪</a></li><li><a class="tocitem" href="../../manual/performance-tips/">性能建议</a></li><li><a class="tocitem" href="../../manual/workflow-tips/">工作流程建议</a></li><li><a class="tocitem" href="../../manual/style-guide/">代码风格指南</a></li><li><a class="tocitem" href="../../manual/faq/">常见问题</a></li><li><a class="tocitem" href="../../manual/noteworthy-differences/">与其他语言的显著差异</a></li><li><a class="tocitem" href="../../manual/unicode-input/">Unicode 输入表</a></li></ul></li><li><span class="tocitem">Base</span><ul><li><a class="tocitem" href="../../base/base/">基本功能</a></li><li><a class="tocitem" href="../../base/collections/">集合和数据结构</a></li><li><a class="tocitem" href="../../base/math/">数学相关</a></li><li><a class="tocitem" href="../../base/numbers/">Numbers</a></li><li><a class="tocitem" href="../../base/strings/">字符串</a></li><li><a class="tocitem" href="../../base/arrays/">数组</a></li><li><a class="tocitem" href="../../base/parallel/">Tasks</a></li><li><a class="tocitem" href="../../base/multi-threading/">Multi-Threading</a></li><li><a class="tocitem" href="../../base/constants/">常量</a></li><li><a class="tocitem" href="../../base/file/">文件系统</a></li><li><a class="tocitem" href="../../base/io-network/">I/O 与网络</a></li><li><a class="tocitem" href="../../base/punctuation/">运算符与记号</a></li><li><a class="tocitem" href="../../base/sort/">排序及相关函数</a></li><li><a class="tocitem" href="../../base/iterators/">迭代相关</a></li><li><a class="tocitem" href="../../base/c/">C 接口</a></li><li><a class="tocitem" href="../../base/libc/">C 标准库</a></li><li><a class="tocitem" href="../../base/stacktraces/">堆栈跟踪</a></li><li><a class="tocitem" href="../../base/simd-types/">SIMD 支持</a></li></ul></li><li><span class="tocitem">Standard Library</span><ul><li><a class="tocitem" href="../Base64/">Base64</a></li><li><a class="tocitem" href="../CRC32c/">CRC32c</a></li><li><a class="tocitem" href="../Dates/">日期</a></li><li><a class="tocitem" href="../DelimitedFiles/">分隔符文件</a></li><li><a class="tocitem" href="../Distributed/">分布式计算</a></li><li><a class="tocitem" href="../FileWatching/">文件相关事件</a></li><li><a class="tocitem" href="../InteractiveUtils/">交互式组件</a></li><li><a class="tocitem" href="../LibGit2/">LibGit2</a></li><li><a class="tocitem" href="../Libdl/">动态链接器</a></li><li class="is-active"><a class="tocitem" href>线性代数</a><ul class="internal"><li><a class="tocitem" href="#特殊矩阵"><span>特殊矩阵</span></a></li><li><a class="tocitem" href="#man-linalg-factorizations"><span>Matrix factorizations</span></a></li><li><a class="tocitem" href="#Standard-functions"><span>Standard functions</span></a></li><li><a class="tocitem" href="#Low-level-matrix-operations"><span>Low-level matrix operations</span></a></li><li><a class="tocitem" href="#BLAS-functions"><span>BLAS functions</span></a></li><li><a class="tocitem" href="#LAPACK-functions"><span>LAPACK functions</span></a></li></ul></li><li><a class="tocitem" href="../Logging/">日志记录</a></li><li><a class="tocitem" href="../Markdown/">Markdown</a></li><li><a class="tocitem" href="../Mmap/">内存映射 I/O</a></li><li><a class="tocitem" href="../Pkg/">Pkg</a></li><li><a class="tocitem" href="../Printf/">Printf</a></li><li><a class="tocitem" href="../Profile/">性能分析</a></li><li><a class="tocitem" href="../REPL/">Julia REPL</a></li><li><a class="tocitem" href="../Random/">随机数</a></li><li><a class="tocitem" href="../SHA/">SHA</a></li><li><a class="tocitem" href="../Serialization/">序列化</a></li><li><a class="tocitem" href="../SharedArrays/">共享数组</a></li><li><a class="tocitem" href="../Sockets/">套接字</a></li><li><a class="tocitem" href="../SparseArrays/">稀疏数组</a></li><li><a class="tocitem" href="../Statistics/">统计</a></li><li><a class="tocitem" href="../Test/">单元测试</a></li><li><a class="tocitem" href="../UUIDs/">UUIDs</a></li><li><a class="tocitem" href="../Unicode/">Unicode</a></li></ul></li><li><span class="tocitem">Developer Documentation</span><ul><li><a class="tocitem" href="../../devdocs/reflection/">反射 与 自我检查</a></li><li><input class="collapse-toggle" id="menuitem-5-2" type="checkbox"/><label class="tocitem" for="menuitem-5-2"><span class="docs-label">Documentation of Julia&#39;s Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../devdocs/init/">Julia 运行时的初始化</a></li><li><a class="tocitem" href="../../devdocs/ast/">Julia 的 AST</a></li><li><a class="tocitem" href="../../devdocs/types/">More about types</a></li><li><a class="tocitem" href="../../devdocs/object/">Memory layout of Julia Objects</a></li><li><a class="tocitem" href="../../devdocs/eval/">Julia 代码的 eval</a></li><li><a class="tocitem" href="../../devdocs/callconv/">Calling Conventions</a></li><li><a class="tocitem" href="../../devdocs/compiler/">High-level Overview of the Native-Code Generation Process</a></li><li><a class="tocitem" href="../../devdocs/functions/">Julia 函数</a></li><li><a class="tocitem" href="../../devdocs/cartesian/">笛卡尔</a></li><li><a class="tocitem" href="../../devdocs/meta/">Talking to the compiler (the <code>:meta</code> mechanism)</a></li><li><a class="tocitem" href="../../devdocs/subarrays/">子数组</a></li><li><a class="tocitem" href="../../devdocs/isbitsunionarrays/">isbits Union Optimizations</a></li><li><a class="tocitem" href="../../devdocs/sysimg/">System Image Building</a></li><li><a class="tocitem" href="../../devdocs/llvm/">Working with LLVM</a></li><li><a class="tocitem" href="../../devdocs/stdio/">printf() and stdio in the Julia runtime</a></li><li><a class="tocitem" href="../../devdocs/boundscheck/">边界检查</a></li><li><a class="tocitem" href="../../devdocs/locks/">Proper maintenance and care of multi-threading locks</a></li><li><a class="tocitem" href="../../devdocs/offset-arrays/">Arrays with custom indices</a></li><li><a class="tocitem" href="../../devdocs/require/">Module loading</a></li><li><a class="tocitem" href="../../devdocs/inference/">类型推导</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Developing/debugging Julia&#39;s C code</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../devdocs/backtraces/">报告和分析崩溃（段错误）</a></li><li><a class="tocitem" href="../../devdocs/debuggingtips/">gdb 调试提示</a></li><li><a class="tocitem" href="../../devdocs/valgrind/">在Julia中使用Valgrind</a></li><li><a class="tocitem" href="../../devdocs/sanitizers/">Sanitizer support</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Standard Library</a></li><li class="is-active"><a href>线性代数</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>线性代数</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://www.transifex.com/juliacn/stdlib-zh_cn/translate/#zh_CN/LinearAlgebramd" title=" 完善 Transifex 上的翻译"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch"> 完善 Transifex 上的翻译</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="设置"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="线性代数"><a class="docs-heading-anchor" href="#线性代数">线性代数</a><a id="线性代数-1"></a><a class="docs-heading-anchor-permalink" href="#线性代数" title="Permalink"></a></h1><p>In addition to (and as part of) its support for multi-dimensional arrays, Julia provides native implementations of many common and useful linear algebra operations which can be loaded with <code>using LinearAlgebra</code>. Basic operations, such as <a href="#LinearAlgebra.tr"><code>tr</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, and <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a> are all supported:</p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3; 4 1 6; 7 8 1]
3×3 Array{Int64,2}:
 1  2  3
 4  1  6
 7  8  1

julia&gt; tr(A)
3

julia&gt; det(A)
104.0

julia&gt; inv(A)
3×3 Array{Float64,2}:
 -0.451923   0.211538    0.0865385
  0.365385  -0.192308    0.0576923
  0.240385   0.0576923  -0.0673077</code></pre><p>还有其它实用的运算，比如寻找特征值或特征向量：</p><pre><code class="language-julia-repl">julia&gt; A = [-4. -17.; 2. 2.]
2×2 Array{Float64,2}:
 -4.0  -17.0
  2.0    2.0

julia&gt; eigvals(A)
2-element Array{Complex{Float64},1}:
 -1.0 - 5.0im
 -1.0 + 5.0im

julia&gt; eigvecs(A)
2×2 Array{Complex{Float64},2}:
  0.945905-0.0im        0.945905+0.0im
 -0.166924+0.278207im  -0.166924-0.278207im</code></pre><p>此外，Julia 提供了多种<a href="#man-linalg-factorizations">矩阵分解</a>，它们可用于加快问题的求解，比如线性求解或矩阵或矩阵求幂，这通过将矩阵预先分解成更适合问题的形式（出于性能或内存上的原因）。有关的更多信息，请参阅文档 <a href="#LinearAlgebra.factorize"><code>factorize</code></a>。举个例子：</p><pre><code class="language-julia-repl">julia&gt; A = [1.5 2 -4; 3 -1 -6; -10 2.3 4]
3×3 Array{Float64,2}:
   1.5   2.0  -4.0
   3.0  -1.0  -6.0
 -10.0   2.3   4.0

julia&gt; factorize(A)
LU{Float64,Array{Float64,2}}
L factor:
3×3 Array{Float64,2}:
  1.0    0.0       0.0
 -0.15   1.0       0.0
 -0.3   -0.132196  1.0
U factor:
3×3 Array{Float64,2}:
 -10.0  2.3     4.0
   0.0  2.345  -3.4
   0.0  0.0    -5.24947</code></pre><p>因为 <code>A</code> 不是埃尔米特、对称、三角、三对角或双对角矩阵，LU 分解也许是我们能做的最好分解。与之相比：</p><pre><code class="language-julia-repl">julia&gt; B = [1.5 2 -4; 2 -1 -3; -4 -3 5]
3×3 Array{Float64,2}:
  1.5   2.0  -4.0
  2.0  -1.0  -3.0
 -4.0  -3.0   5.0

julia&gt; factorize(B)
BunchKaufman{Float64,Array{Float64,2}}
D factor:
3×3 Tridiagonal{Float64,Array{Float64,1}}:
 -1.64286   0.0   ⋅
  0.0      -2.8  0.0
   ⋅        0.0  5.0
U factor:
3×3 UnitUpperTriangular{Float64,Array{Float64,2}}:
 1.0  0.142857  -0.8
  ⋅   1.0       -0.6
  ⋅    ⋅         1.0
permutation:
3-element Array{Int64,1}:
 1
 2
 3</code></pre><p>在这里，Julia 能够发现 <code>B</code> 确实是对称矩阵，并且使用一种更适当的分解。针对一个具有某些属性的矩阵，比如一个对称或三对角矩阵，往往有可能写出更高效的代码。Julia 提供了一些特殊的类型好让你可以根据矩阵所具有的属性「标记」它们。例如：</p><pre><code class="language-julia-repl">julia&gt; B = [1.5 2 -4; 2 -1 -3; -4 -3 5]
3×3 Array{Float64,2}:
  1.5   2.0  -4.0
  2.0  -1.0  -3.0
 -4.0  -3.0   5.0

julia&gt; sB = Symmetric(B)
3×3 Symmetric{Float64,Array{Float64,2}}:
  1.5   2.0  -4.0
  2.0  -1.0  -3.0
 -4.0  -3.0   5.0</code></pre><p><code>sB</code> 已经被标记成（实）对称矩阵，所以对于之后可能在它上面执行的操作，例如特征因子化或矩阵-向量乘积，只引用矩阵的一半可以提高效率。举个例子：</p><pre><code class="language-julia-repl">julia&gt; B = [1.5 2 -4; 2 -1 -3; -4 -3 5]
3×3 Array{Float64,2}:
  1.5   2.0  -4.0
  2.0  -1.0  -3.0
 -4.0  -3.0   5.0

julia&gt; sB = Symmetric(B)
3×3 Symmetric{Float64,Array{Float64,2}}:
  1.5   2.0  -4.0
  2.0  -1.0  -3.0
 -4.0  -3.0   5.0

julia&gt; x = [1; 2; 3]
3-element Array{Int64,1}:
 1
 2
 3

julia&gt; sB\x
3-element Array{Float64,1}:
 -1.7391304347826084
 -1.1086956521739126
 -1.4565217391304346</code></pre><p><code>\</code> 运算在这里执行线性求解。左除运算符相当强大，很容易写出紧凑、可读的代码，它足够灵活，可以求解各种线性方程组。</p><h2 id="特殊矩阵"><a class="docs-heading-anchor" href="#特殊矩阵">特殊矩阵</a><a id="特殊矩阵-1"></a><a class="docs-heading-anchor-permalink" href="#特殊矩阵" title="Permalink"></a></h2><p><a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=3274">具有特殊对称性和结构的矩阵</a>经常在线性代数中出现并且与各种矩阵分解相关。Julia 具有丰富的特殊矩阵类型，可以快速计算专门为特定矩阵类型开发的专用例程。</p><p>下表总结了在 Julia 中已经实现的特殊矩阵类型，以及为它们提供各种优化方法的钩子在 LAPACK 中是否可用。</p><table><tr><th style="text-align: left">类型</th><th style="text-align: left">描述</th></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Symmetric_matrix">对称矩阵</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Hermitian_matrix">埃尔米特矩阵</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UpperTriangular"><code>UpperTriangular</code></a></td><td style="text-align: left">上<a href="https://en.wikipedia.org/wiki/Triangular_matrix">三角矩阵</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitUpperTriangular"><code>UnitUpperTriangular</code></a></td><td style="text-align: left">Upper <a href="https://en.wikipedia.org/wiki/Triangular_matrix">triangular matrix</a> with unit diagonal</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.LowerTriangular"><code>LowerTriangular</code></a></td><td style="text-align: left">Lower <a href="https://en.wikipedia.org/wiki/Triangular_matrix">triangular matrix</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitLowerTriangular"><code>UnitLowerTriangular</code></a></td><td style="text-align: left">Lower <a href="https://en.wikipedia.org/wiki/Triangular_matrix">triangular matrix</a> with unit diagonal</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UpperHessenberg"><code>UpperHessenberg</code></a></td><td style="text-align: left">Upper <a href="https://en.wikipedia.org/wiki/Hessenberg_matrix">Hessenberg matrix</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Tridiagonal"><code>Tridiagonal</code></a></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Tridiagonal_matrix">Tridiagonal matrix</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a></td><td style="text-align: left">Symmetric tridiagonal matrix</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Bidiagonal"><code>Bidiagonal</code></a></td><td style="text-align: left">Upper/lower <a href="https://en.wikipedia.org/wiki/Bidiagonal_matrix">bidiagonal matrix</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Diagonal_matrix">Diagonal matrix</a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UniformScaling"><code>UniformScaling</code></a></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Uniform_scaling">Uniform scaling operator</a></td></tr></table><h3 id="Elementary-operations"><a class="docs-heading-anchor" href="#Elementary-operations">Elementary operations</a><a id="Elementary-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Elementary-operations" title="Permalink"></a></h3><table><tr><th style="text-align: left">Matrix type</th><th style="text-align: left"><code>+</code></th><th style="text-align: left"><code>-</code></th><th style="text-align: left"><code>*</code></th><th style="text-align: left"><code>\</code></th><th style="text-align: left">Other functions with optimized methods</th></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="../../base/math/#Base.sqrt-Tuple{Real}"><code>sqrt</code></a>, <a href="../../base/math/#Base.exp-Tuple{Float64}"><code>exp</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="../../base/math/#Base.sqrt-Tuple{Real}"><code>sqrt</code></a>, <a href="../../base/math/#Base.exp-Tuple{Float64}"><code>exp</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UpperTriangular"><code>UpperTriangular</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitUpperTriangular"><code>UnitUpperTriangular</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.LowerTriangular"><code>LowerTriangular</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitLowerTriangular"><code>UnitLowerTriangular</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MV</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UpperHessenberg"><code>UpperHessenberg</code></a></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">MM</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a></td><td style="text-align: left">M</td><td style="text-align: left">M</td><td style="text-align: left">MS</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="#LinearAlgebra.eigmax"><code>eigmax</code></a>, <a href="#LinearAlgebra.eigmin"><code>eigmin</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Tridiagonal"><code>Tridiagonal</code></a></td><td style="text-align: left">M</td><td style="text-align: left">M</td><td style="text-align: left">MS</td><td style="text-align: left">MV</td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Bidiagonal"><code>Bidiagonal</code></a></td><td style="text-align: left">M</td><td style="text-align: left">M</td><td style="text-align: left">MS</td><td style="text-align: left">MV</td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a></td><td style="text-align: left">M</td><td style="text-align: left">M</td><td style="text-align: left">MV</td><td style="text-align: left">MV</td><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, <a href="#LinearAlgebra.logdet"><code>logdet</code></a>, <a href="../../base/math/#Base.:/"><code>/</code></a></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UniformScaling"><code>UniformScaling</code></a></td><td style="text-align: left">M</td><td style="text-align: left">M</td><td style="text-align: left">MVS</td><td style="text-align: left">MVS</td><td style="text-align: left"><a href="../../base/math/#Base.:/"><code>/</code></a></td></tr></table><p>Legend:</p><table><tr><th style="text-align: left">Key</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left">M (matrix)</td><td style="text-align: left">An optimized method for matrix-matrix operations is available</td></tr><tr><td style="text-align: left">V (vector)</td><td style="text-align: left">An optimized method for matrix-vector operations is available</td></tr><tr><td style="text-align: left">S (scalar)</td><td style="text-align: left">An optimized method for matrix-scalar operations is available</td></tr></table><h3 id="Matrix-factorizations"><a class="docs-heading-anchor" href="#Matrix-factorizations">Matrix factorizations</a><a id="Matrix-factorizations-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-factorizations" title="Permalink"></a></h3><table><tr><th style="text-align: left">Matrix type</th><th style="text-align: left">LAPACK</th><th style="text-align: left"><a href="#LinearAlgebra.eigen"><code>eigen</code></a></th><th style="text-align: left"><a href="#LinearAlgebra.eigvals"><code>eigvals</code></a></th><th style="text-align: left"><a href="#LinearAlgebra.eigvecs"><code>eigvecs</code></a></th><th style="text-align: left"><a href="#LinearAlgebra.svd"><code>svd</code></a></th><th style="text-align: left"><a href="#LinearAlgebra.svdvals"><code>svdvals</code></a></th></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a></td><td style="text-align: left">SY</td><td style="text-align: left"></td><td style="text-align: left">ARI</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a></td><td style="text-align: left">HE</td><td style="text-align: left"></td><td style="text-align: left">ARI</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UpperTriangular"><code>UpperTriangular</code></a></td><td style="text-align: left">TR</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitUpperTriangular"><code>UnitUpperTriangular</code></a></td><td style="text-align: left">TR</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.LowerTriangular"><code>LowerTriangular</code></a></td><td style="text-align: left">TR</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.UnitLowerTriangular"><code>UnitLowerTriangular</code></a></td><td style="text-align: left">TR</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left">A</td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a></td><td style="text-align: left">ST</td><td style="text-align: left">A</td><td style="text-align: left">ARI</td><td style="text-align: left">AV</td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Tridiagonal"><code>Tridiagonal</code></a></td><td style="text-align: left">GT</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Bidiagonal"><code>Bidiagonal</code></a></td><td style="text-align: left">BD</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">A</td><td style="text-align: left">A</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a></td><td style="text-align: left">DI</td><td style="text-align: left"></td><td style="text-align: left">A</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr></table><p>Legend:</p><table><tr><th style="text-align: left">Key</th><th style="text-align: left">Description</th><th style="text-align: left">Example</th></tr><tr><td style="text-align: left">A (all)</td><td style="text-align: left">An optimized method to find all the characteristic values and/or vectors is available</td><td style="text-align: left">e.g. <code>eigvals(M)</code></td></tr><tr><td style="text-align: left">R (range)</td><td style="text-align: left">An optimized method to find the <code>il</code>th through the <code>ih</code>th characteristic values are available</td><td style="text-align: left"><code>eigvals(M, il, ih)</code></td></tr><tr><td style="text-align: left">I (interval)</td><td style="text-align: left">An optimized method to find the characteristic values in the interval [<code>vl</code>, <code>vh</code>] is available</td><td style="text-align: left"><code>eigvals(M, vl, vh)</code></td></tr><tr><td style="text-align: left">V (vectors)</td><td style="text-align: left">An optimized method to find the characteristic vectors corresponding to the characteristic values <code>x=[x1, x2,...]</code> is available</td><td style="text-align: left"><code>eigvecs(M, x)</code></td></tr></table><h3 id="The-uniform-scaling-operator"><a class="docs-heading-anchor" href="#The-uniform-scaling-operator">The uniform scaling operator</a><a id="The-uniform-scaling-operator-1"></a><a class="docs-heading-anchor-permalink" href="#The-uniform-scaling-operator" title="Permalink"></a></h3><p>A <a href="#LinearAlgebra.UniformScaling"><code>UniformScaling</code></a> operator represents a scalar times the identity operator, <code>λ*I</code>. The identity operator <code>I</code> is defined as a constant and is an instance of <code>UniformScaling</code>. The size of these operators are generic and match the other matrix in the binary operations <a href="../../base/math/#Base.:+"><code>+</code></a>, <a href="../../base/math/#Base.:--Tuple{Any}"><code>-</code></a>, <a href="../../base/math/#Base.:*-Tuple{Any, Vararg{Any, N} where N}"><code>*</code></a> and <a href="../../base/math/#Base.:\\-Tuple{Any, Any}"><code>\</code></a>. For <code>A+I</code> and <code>A-I</code> this means that <code>A</code> must be square. Multiplication with the identity operator <code>I</code> is a noop (except for checking that the scaling factor is one) and therefore almost without overhead.</p><p>To see the <code>UniformScaling</code> operator in action:</p><pre><code class="language-julia-repl">julia&gt; U = UniformScaling(2);

julia&gt; a = [1 2; 3 4]
2×2 Array{Int64,2}:
 1  2
 3  4

julia&gt; a + U
2×2 Array{Int64,2}:
 3  2
 3  6

julia&gt; a * U
2×2 Array{Int64,2}:
 2  4
 6  8

julia&gt; [a U]
2×4 Array{Int64,2}:
 1  2  2  0
 3  4  0  2

julia&gt; b = [1 2 3; 4 5 6]
2×3 Array{Int64,2}:
 1  2  3
 4  5  6

julia&gt; b - U
ERROR: DimensionMismatch(&quot;matrix is not square: dimensions are (2, 3)&quot;)
Stacktrace:
[...]</code></pre><p>If you need to solve many systems of the form <code>(A+μI)x = b</code> for the same <code>A</code> and different <code>μ</code>, it might be beneficial to first compute the Hessenberg factorization <code>F</code> of <code>A</code> via the <a href="#LinearAlgebra.hessenberg"><code>hessenberg</code></a> function. Given <code>F</code>, Julia employs an efficient algorithm for <code>(F+μ*I) \ b</code> (equivalent to <code>(A+μ*I)x \ b</code>) and related operations like determinants.</p><h2 id="man-linalg-factorizations"><a class="docs-heading-anchor" href="#man-linalg-factorizations">Matrix factorizations</a><a id="man-linalg-factorizations-1"></a><a class="docs-heading-anchor-permalink" href="#man-linalg-factorizations" title="Permalink"></a></h2><p><a href="https://en.wikipedia.org/wiki/Matrix_decomposition">Matrix factorizations (a.k.a. matrix decompositions)</a> compute the factorization of a matrix into a product of matrices, and are one of the central concepts in linear algebra.</p><p>The following table summarizes the types of matrix factorizations that have been implemented in Julia. Details of their associated methods can be found in the <a href="#Standard-functions">Standard functions</a> section of the Linear Algebra documentation.</p><table><tr><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><code>BunchKaufman</code></td><td style="text-align: left">Bunch-Kaufman factorization</td></tr><tr><td style="text-align: left"><code>Cholesky</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky factorization</a></td></tr><tr><td style="text-align: left"><code>CholeskyPivoted</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Pivot_element">Pivoted</a> Cholesky factorization</td></tr><tr><td style="text-align: left"><code>LDLt</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Cholesky_decomposition#LDL_decomposition">LDL(T) factorization</a></td></tr><tr><td style="text-align: left"><code>LU</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/LU_decomposition">LU factorization</a></td></tr><tr><td style="text-align: left"><code>QR</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/QR_decomposition">QR factorization</a></td></tr><tr><td style="text-align: left"><code>QRCompactWY</code></td><td style="text-align: left">Compact WY form of the QR factorization</td></tr><tr><td style="text-align: left"><code>QRPivoted</code></td><td style="text-align: left">Pivoted <a href="https://en.wikipedia.org/wiki/QR_decomposition">QR factorization</a></td></tr><tr><td style="text-align: left"><code>LQ</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/QR_decomposition">QR factorization</a> of <code>transpose(A)</code></td></tr><tr><td style="text-align: left"><code>Hessenberg</code></td><td style="text-align: left"><a href="http://mathworld.wolfram.com/HessenbergDecomposition.html">Hessenberg decomposition</a></td></tr><tr><td style="text-align: left"><code>Eigen</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">Spectral decomposition</a></td></tr><tr><td style="text-align: left"><code>GeneralizedEigen</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix#Generalized_eigenvalue_problem">Generalized spectral decomposition</a></td></tr><tr><td style="text-align: left"><code>SVD</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Singular value decomposition</a></td></tr><tr><td style="text-align: left"><code>GeneralizedSVD</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Generalized_singular_value_decomposition#Higher_order_version">Generalized SVD</a></td></tr><tr><td style="text-align: left"><code>Schur</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Schur_decomposition">Schur decomposition</a></td></tr><tr><td style="text-align: left"><code>GeneralizedSchur</code></td><td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Schur_decomposition#Generalized_Schur_decomposition">Generalized Schur decomposition</a></td></tr></table><h2 id="Standard-functions"><a class="docs-heading-anchor" href="#Standard-functions">Standard functions</a><a id="Standard-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-functions" title="Permalink"></a></h2><p>Linear algebra functions in Julia are largely implemented by calling functions from <a href="http://www.netlib.org/lapack/">LAPACK</a>.  Sparse factorizations call functions from <a href="http://faculty.cse.tamu.edu/davis/suitesparse.html">SuiteSparse</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Base.:*-Tuple{AbstractMatrix{T} where T, AbstractMatrix{T} where T}" href="#Base.:*-Tuple{AbstractMatrix{T} where T, AbstractMatrix{T} where T}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">*(A::AbstractMatrix, B::AbstractMatrix)</code></pre><p>Matrix multiplication.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; [1 1; 0 1] * [1 0; 1 1]
2×2 Matrix{Int64}:
 2  1
 1  1</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\-Tuple{AbstractMatrix{T} where T, AbstractVecOrMat{T} where T}" href="#Base.:\\-Tuple{AbstractMatrix{T} where T, AbstractVecOrMat{T} where T}"><code>Base.:\</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">\(A, B)</code></pre><p>Matrix division using a polyalgorithm. For input matrices <code>A</code> and <code>B</code>, the result <code>X</code> is such that <code>A*X == B</code> when <code>A</code> is square. The solver that is used depends upon the structure of <code>A</code>.  If <code>A</code> is upper or lower triangular (or diagonal), no factorization of <code>A</code> is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used.</p><p>For rectangular <code>A</code> the result is the minimum-norm least squares solution computed by a pivoted QR factorization of <code>A</code> and a rank estimate of <code>A</code> based on the R factor.</p><p>When <code>A</code> is sparse, a similar polyalgorithm is used. For indefinite matrices, the <code>LDLt</code> factorization does not use pivoting during the numerical factorization and therefore the procedure can fail even for invertible matrices.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0; 1 -2]; B = [32; -4];

julia&gt; X = A \ B
2-element Vector{Float64}:
 32.0
 18.0

julia&gt; A * X == B
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.SingularException" href="#LinearAlgebra.SingularException"><code>LinearAlgebra.SingularException</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SingularException</code></pre><p>Exception thrown when the input matrix has one or more zero-valued eigenvalues, and is not invertible. A linear solve involving such a matrix cannot be computed. The <code>info</code> field indicates the location of (one of) the singular value(s).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.PosDefException" href="#LinearAlgebra.PosDefException"><code>LinearAlgebra.PosDefException</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PosDefException</code></pre><p>Exception thrown when the input matrix was not <a href="https://en.wikipedia.org/wiki/Definiteness_of_a_matrix">positive definite</a>. Some linear algebra functions and factorizations are only applicable to positive definite matrices. The <code>info</code> field indicates the location of (one of) the eigenvalue(s) which is (are) less than/equal to 0.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ZeroPivotException" href="#LinearAlgebra.ZeroPivotException"><code>LinearAlgebra.ZeroPivotException</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ZeroPivotException &lt;: Exception</code></pre><p>Exception thrown when a matrix factorization/solve encounters a zero in a pivot (diagonal) position and cannot proceed.  This may <em>not</em> mean that the matrix is singular: it may be fruitful to switch to a diffent factorization such as pivoted LU that can re-order variables to eliminate spurious zero pivots. The <code>info</code> field indicates the location of (one of) the zero pivot(s).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.dot" href="#LinearAlgebra.dot"><code>LinearAlgebra.dot</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dot(x, y)
x ⋅ y</code></pre><p>Compute the dot product between two vectors. For complex vectors, the first vector is conjugated.</p><p><code>dot</code> also works on arbitrary iterable objects, including arrays of any dimension, as long as <code>dot</code> is defined on the elements.</p><p><code>dot</code> is semantically equivalent to <code>sum(dot(vx,vy) for (vx,vy) in zip(x, y))</code>, with the added restriction that the arguments must have equal lengths.</p><p><code>x ⋅ y</code> (where <code>⋅</code> can be typed by tab-completing <code>\cdot</code> in the REPL) is a synonym for <code>dot(x, y)</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; dot([1; 1], [2; 3])
5

julia&gt; dot([im; im], [1; 1])
0 - 2im

julia&gt; dot(1:5, 2:6)
70

julia&gt; x = fill(2., (5,5));

julia&gt; y = fill(3., (5,5));

julia&gt; dot(x, y)
150.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.cross" href="#LinearAlgebra.cross"><code>LinearAlgebra.cross</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">cross(x, y)
×(x,y)</code></pre><p>Compute the cross product of two 3-vectors.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [0;1;0]
3-element Vector{Int64}:
 0
 1
 0

julia&gt; b = [0;0;1]
3-element Vector{Int64}:
 0
 0
 1

julia&gt; cross(a,b)
3-element Vector{Int64}:
 1
 0
 0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.factorize" href="#LinearAlgebra.factorize"><code>LinearAlgebra.factorize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">factorize(A)</code></pre><p>Compute a convenient factorization of <code>A</code>, based upon the type of the input matrix. <code>factorize</code> checks <code>A</code> to see if it is symmetric/triangular/etc. if <code>A</code> is passed as a generic matrix. <code>factorize</code> checks every element of <code>A</code> to verify/rule out each property. It will short-circuit as soon as it can rule out symmetry/triangular structure. The return value can be reused for efficient solving of multiple systems. For example: <code>A=factorize(A); x=A\b; y=A\C</code>.</p><table><tr><th style="text-align: left">Properties of <code>A</code></th><th style="text-align: left">type of factorization</th></tr><tr><td style="text-align: left">Positive-definite</td><td style="text-align: left">Cholesky (see <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>)</td></tr><tr><td style="text-align: left">Dense Symmetric/Hermitian</td><td style="text-align: left">Bunch-Kaufman (see <a href="#LinearAlgebra.bunchkaufman"><code>bunchkaufman</code></a>)</td></tr><tr><td style="text-align: left">Sparse Symmetric/Hermitian</td><td style="text-align: left">LDLt (see <a href="#LinearAlgebra.ldlt"><code>ldlt</code></a>)</td></tr><tr><td style="text-align: left">Triangular</td><td style="text-align: left">Triangular</td></tr><tr><td style="text-align: left">Diagonal</td><td style="text-align: left">Diagonal</td></tr><tr><td style="text-align: left">Bidiagonal</td><td style="text-align: left">Bidiagonal</td></tr><tr><td style="text-align: left">Tridiagonal</td><td style="text-align: left">LU (see <a href="#LinearAlgebra.lu"><code>lu</code></a>)</td></tr><tr><td style="text-align: left">Symmetric real tridiagonal</td><td style="text-align: left">LDLt (see <a href="#LinearAlgebra.ldlt"><code>ldlt</code></a>)</td></tr><tr><td style="text-align: left">General square</td><td style="text-align: left">LU (see <a href="#LinearAlgebra.lu"><code>lu</code></a>)</td></tr><tr><td style="text-align: left">General non-square</td><td style="text-align: left">QR (see <a href="#LinearAlgebra.qr"><code>qr</code></a>)</td></tr></table><p>If <code>factorize</code> is called on a Hermitian positive-definite matrix, for instance, then <code>factorize</code> will return a Cholesky factorization.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = Array(Bidiagonal(fill(1.0, (5, 5)), :U))
5×5 Matrix{Float64}:
 1.0  1.0  0.0  0.0  0.0
 0.0  1.0  1.0  0.0  0.0
 0.0  0.0  1.0  1.0  0.0
 0.0  0.0  0.0  1.0  1.0
 0.0  0.0  0.0  0.0  1.0

julia&gt; factorize(A) # factorize will check to see that A is already factorized
5×5 Bidiagonal{Float64, Vector{Float64}}:
 1.0  1.0   ⋅    ⋅    ⋅
  ⋅   1.0  1.0   ⋅    ⋅
  ⋅    ⋅   1.0  1.0   ⋅
  ⋅    ⋅    ⋅   1.0  1.0
  ⋅    ⋅    ⋅    ⋅   1.0</code></pre><p>This returns a <code>5×5 Bidiagonal{Float64}</code>, which can now be passed to other linear algebra functions (e.g. eigensolvers) which will use specialized methods for <code>Bidiagonal</code> types.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Diagonal" href="#LinearAlgebra.Diagonal"><code>LinearAlgebra.Diagonal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Diagonal(A::AbstractMatrix)</code></pre><p>Construct a matrix from the diagonal of <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3; 4 5 6; 7 8 9]
3×3 Matrix{Int64}:
 1  2  3
 4  5  6
 7  8  9

julia&gt; Diagonal(A)
3×3 Diagonal{Int64, Vector{Int64}}:
 1  ⋅  ⋅
 ⋅  5  ⋅
 ⋅  ⋅  9</code></pre></div></section><section><div><pre><code class="language-none">Diagonal(V::AbstractVector)</code></pre><p>Construct a matrix with <code>V</code> as its diagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; V = [1, 2]
2-element Vector{Int64}:
 1
 2

julia&gt; Diagonal(V)
2×2 Diagonal{Int64, Vector{Int64}}:
 1  ⋅
 ⋅  2</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Bidiagonal" href="#LinearAlgebra.Bidiagonal"><code>LinearAlgebra.Bidiagonal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Bidiagonal(dv::V, ev::V, uplo::Symbol) where V &lt;: AbstractVector</code></pre><p>Constructs an upper (<code>uplo=:U</code>) or lower (<code>uplo=:L</code>) bidiagonal matrix using the given diagonal (<code>dv</code>) and off-diagonal (<code>ev</code>) vectors. The result is of type <code>Bidiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a href="../../base/base/#Base.convert"><code>convert(Array, _)</code></a> (or <code>Array(_)</code> for short). The length of <code>ev</code> must be one less than the length of <code>dv</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; dv = [1, 2, 3, 4]
4-element Vector{Int64}:
 1
 2
 3
 4

julia&gt; ev = [7, 8, 9]
3-element Vector{Int64}:
 7
 8
 9

julia&gt; Bu = Bidiagonal(dv, ev, :U) # ev is on the first superdiagonal
4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  7  ⋅  ⋅
 ⋅  2  8  ⋅
 ⋅  ⋅  3  9
 ⋅  ⋅  ⋅  4

julia&gt; Bl = Bidiagonal(dv, ev, :L) # ev is on the first subdiagonal
4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  ⋅  ⋅  ⋅
 7  2  ⋅  ⋅
 ⋅  8  3  ⋅
 ⋅  ⋅  9  4</code></pre></div></section><section><div><pre><code class="language-none">Bidiagonal(A, uplo::Symbol)</code></pre><p>Construct a <code>Bidiagonal</code> matrix from the main diagonal of <code>A</code> and its first super- (if <code>uplo=:U</code>) or sub-diagonal (if <code>uplo=:L</code>).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 1 1 1; 2 2 2 2; 3 3 3 3; 4 4 4 4]
4×4 Matrix{Int64}:
 1  1  1  1
 2  2  2  2
 3  3  3  3
 4  4  4  4

julia&gt; Bidiagonal(A, :U) # contains the main diagonal and first superdiagonal of A
4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  1  ⋅  ⋅
 ⋅  2  2  ⋅
 ⋅  ⋅  3  3
 ⋅  ⋅  ⋅  4

julia&gt; Bidiagonal(A, :L) # contains the main diagonal and first subdiagonal of A
4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  ⋅  ⋅  ⋅
 2  2  ⋅  ⋅
 ⋅  3  3  ⋅
 ⋅  ⋅  4  4</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.SymTridiagonal" href="#LinearAlgebra.SymTridiagonal"><code>LinearAlgebra.SymTridiagonal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SymTridiagonal(dv::V, ev::V) where V &lt;: AbstractVector</code></pre><p>Construct a symmetric tridiagonal matrix from the diagonal (<code>dv</code>) and first sub/super-diagonal (<code>ev</code>), respectively. The result is of type <code>SymTridiagonal</code> and provides efficient specialized eigensolvers, but may be converted into a regular matrix with <a href="../../base/base/#Base.convert"><code>convert(Array, _)</code></a> (or <code>Array(_)</code> for short).</p><p>For <code>SymTridiagonal</code> block matrices, the elements of <code>dv</code> are symmetrized. The argument <code>ev</code> is interpreted as the superdiagonal. Blocks from the subdiagonal are (materialized) transpose of the corresponding superdiagonal blocks.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; dv = [1, 2, 3, 4]
4-element Vector{Int64}:
 1
 2
 3
 4

julia&gt; ev = [7, 8, 9]
3-element Vector{Int64}:
 7
 8
 9

julia&gt; SymTridiagonal(dv, ev)
4×4 SymTridiagonal{Int64, Vector{Int64}}:
 1  7  ⋅  ⋅
 7  2  8  ⋅
 ⋅  8  3  9
 ⋅  ⋅  9  4

julia&gt; A = SymTridiagonal(fill([1 2; 3 4], 3), fill([1 2; 3 4], 2));

julia&gt; A[1,1]
2×2 Symmetric{Int64, Matrix{Int64}}:
 1  2
 2  4

julia&gt; A[1,2]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; A[2,1]
2×2 Matrix{Int64}:
 1  3
 2  4</code></pre></div></section><section><div><pre><code class="language-none">SymTridiagonal(A::AbstractMatrix)</code></pre><p>Construct a symmetric tridiagonal matrix from the diagonal and first superdiagonal of the symmetric matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3; 2 4 5; 3 5 6]
3×3 Matrix{Int64}:
 1  2  3
 2  4  5
 3  5  6

julia&gt; SymTridiagonal(A)
3×3 SymTridiagonal{Int64, Vector{Int64}}:
 1  2  ⋅
 2  4  5
 ⋅  5  6

julia&gt; B = reshape([[1 2; 2 3], [1 2; 3 4], [1 3; 2 4], [1 2; 2 3]], 2, 2);

julia&gt; SymTridiagonal(B)
2×2 SymTridiagonal{Matrix{Int64}, Vector{Matrix{Int64}}}:
 [1 2; 2 3]  [1 3; 2 4]
 [1 2; 3 4]  [1 2; 2 3]</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Tridiagonal" href="#LinearAlgebra.Tridiagonal"><code>LinearAlgebra.Tridiagonal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Tridiagonal(dl::V, d::V, du::V) where V &lt;: AbstractVector</code></pre><p>Construct a tridiagonal matrix from the first subdiagonal, diagonal, and first superdiagonal, respectively. The result is of type <code>Tridiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a href="../../base/base/#Base.convert"><code>convert(Array, _)</code></a> (or <code>Array(_)</code> for short). The lengths of <code>dl</code> and <code>du</code> must be one less than the length of <code>d</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; dl = [1, 2, 3];

julia&gt; du = [4, 5, 6];

julia&gt; d = [7, 8, 9, 0];

julia&gt; Tridiagonal(dl, d, du)
4×4 Tridiagonal{Int64, Vector{Int64}}:
 7  4  ⋅  ⋅
 1  8  5  ⋅
 ⋅  2  9  6
 ⋅  ⋅  3  0</code></pre></div></section><section><div><pre><code class="language-none">Tridiagonal(A)</code></pre><p>Construct a tridiagonal matrix from the first sub-diagonal, diagonal and first super-diagonal of the matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3 4; 1 2 3 4; 1 2 3 4; 1 2 3 4]
4×4 Matrix{Int64}:
 1  2  3  4
 1  2  3  4
 1  2  3  4
 1  2  3  4

julia&gt; Tridiagonal(A)
4×4 Tridiagonal{Int64, Vector{Int64}}:
 1  2  ⋅  ⋅
 1  2  3  ⋅
 ⋅  2  3  4
 ⋅  ⋅  3  4</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Symmetric" href="#LinearAlgebra.Symmetric"><code>LinearAlgebra.Symmetric</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Symmetric(A, uplo=:U)</code></pre><p>Construct a <code>Symmetric</code> view of the upper (if <code>uplo = :U</code>) or lower (if <code>uplo = :L</code>) triangle of the matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0 2 0 3; 0 4 0 5 0; 6 0 7 0 8; 0 9 0 1 0; 2 0 3 0 4]
5×5 Matrix{Int64}:
 1  0  2  0  3
 0  4  0  5  0
 6  0  7  0  8
 0  9  0  1  0
 2  0  3  0  4

julia&gt; Supper = Symmetric(A)
5×5 Symmetric{Int64, Matrix{Int64}}:
 1  0  2  0  3
 0  4  0  5  0
 2  0  7  0  8
 0  5  0  1  0
 3  0  8  0  4

julia&gt; Slower = Symmetric(A, :L)
5×5 Symmetric{Int64, Matrix{Int64}}:
 1  0  6  0  2
 0  4  0  9  0
 6  0  7  0  3
 0  9  0  1  0
 2  0  3  0  4</code></pre><p>Note that <code>Supper</code> will not be equal to <code>Slower</code> unless <code>A</code> is itself symmetric (e.g. if <code>A == transpose(A)</code>).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Hermitian" href="#LinearAlgebra.Hermitian"><code>LinearAlgebra.Hermitian</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Hermitian(A, uplo=:U)</code></pre><p>Construct a <code>Hermitian</code> view of the upper (if <code>uplo = :U</code>) or lower (if <code>uplo = :L</code>) triangle of the matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0 2+2im 0 3-3im; 0 4 0 5 0; 6-6im 0 7 0 8+8im; 0 9 0 1 0; 2+2im 0 3-3im 0 4];

julia&gt; Hupper = Hermitian(A)
5×5 Hermitian{Complex{Int64}, Matrix{Complex{Int64}}}:
 1+0im  0+0im  2+2im  0+0im  3-3im
 0+0im  4+0im  0+0im  5+0im  0+0im
 2-2im  0+0im  7+0im  0+0im  8+8im
 0+0im  5+0im  0+0im  1+0im  0+0im
 3+3im  0+0im  8-8im  0+0im  4+0im

julia&gt; Hlower = Hermitian(A, :L)
5×5 Hermitian{Complex{Int64}, Matrix{Complex{Int64}}}:
 1+0im  0+0im  6+6im  0+0im  2-2im
 0+0im  4+0im  0+0im  9+0im  0+0im
 6-6im  0+0im  7+0im  0+0im  3+3im
 0+0im  9+0im  0+0im  1+0im  0+0im
 2+2im  0+0im  3-3im  0+0im  4+0im</code></pre><p>Note that <code>Hupper</code> will not be equal to <code>Hlower</code> unless <code>A</code> is itself Hermitian (e.g. if <code>A == adjoint(A)</code>).</p><p>All non-real parts of the diagonal will be ignored.</p><pre><code class="language-julia">Hermitian(fill(complex(1,1), 1, 1)) == fill(1, 1, 1)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LowerTriangular" href="#LinearAlgebra.LowerTriangular"><code>LinearAlgebra.LowerTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LowerTriangular(A::AbstractMatrix)</code></pre><p>Construct a <code>LowerTriangular</code> view of the matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]
3×3 Matrix{Float64}:
 1.0  2.0  3.0
 4.0  5.0  6.0
 7.0  8.0  9.0

julia&gt; LowerTriangular(A)
3×3 LowerTriangular{Float64, Matrix{Float64}}:
 1.0   ⋅    ⋅
 4.0  5.0   ⋅
 7.0  8.0  9.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.UpperTriangular" href="#LinearAlgebra.UpperTriangular"><code>LinearAlgebra.UpperTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UpperTriangular(A::AbstractMatrix)</code></pre><p>Construct an <code>UpperTriangular</code> view of the matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]
3×3 Matrix{Float64}:
 1.0  2.0  3.0
 4.0  5.0  6.0
 7.0  8.0  9.0

julia&gt; UpperTriangular(A)
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 1.0  2.0  3.0
  ⋅   5.0  6.0
  ⋅    ⋅   9.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.UnitLowerTriangular" href="#LinearAlgebra.UnitLowerTriangular"><code>LinearAlgebra.UnitLowerTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UnitLowerTriangular(A::AbstractMatrix)</code></pre><p>Construct a <code>UnitLowerTriangular</code> view of the matrix <code>A</code>. Such a view has the <a href="../../base/numbers/#Base.oneunit"><code>oneunit</code></a> of the <a href="../../base/collections/#Base.eltype"><code>eltype</code></a> of <code>A</code> on its diagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]
3×3 Matrix{Float64}:
 1.0  2.0  3.0
 4.0  5.0  6.0
 7.0  8.0  9.0

julia&gt; UnitLowerTriangular(A)
3×3 UnitLowerTriangular{Float64, Matrix{Float64}}:
 1.0   ⋅    ⋅
 4.0  1.0   ⋅
 7.0  8.0  1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.UnitUpperTriangular" href="#LinearAlgebra.UnitUpperTriangular"><code>LinearAlgebra.UnitUpperTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UnitUpperTriangular(A::AbstractMatrix)</code></pre><p>Construct an <code>UnitUpperTriangular</code> view of the matrix <code>A</code>. Such a view has the <a href="../../base/numbers/#Base.oneunit"><code>oneunit</code></a> of the <a href="../../base/collections/#Base.eltype"><code>eltype</code></a> of <code>A</code> on its diagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]
3×3 Matrix{Float64}:
 1.0  2.0  3.0
 4.0  5.0  6.0
 7.0  8.0  9.0

julia&gt; UnitUpperTriangular(A)
3×3 UnitUpperTriangular{Float64, Matrix{Float64}}:
 1.0  2.0  3.0
  ⋅   1.0  6.0
  ⋅    ⋅   1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.UpperHessenberg" href="#LinearAlgebra.UpperHessenberg"><code>LinearAlgebra.UpperHessenberg</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UpperHessenberg(A::AbstractMatrix)</code></pre><p>Construct an <code>UpperHessenberg</code> view of the matrix <code>A</code>. Entries of <code>A</code> below the first subdiagonal are ignored.</p><p>Efficient algorithms are implemented for <code>H \ b</code>, <code>det(H)</code>, and similar.</p><p>See also the <a href="#LinearAlgebra.hessenberg"><code>hessenberg</code></a> function to factor any matrix into a similar upper-Hessenberg matrix.</p><p>If <code>F::Hessenberg</code> is the factorization object, the unitary matrix can be accessed with <code>F.Q</code> and the Hessenberg matrix with <code>F.H</code>. When <code>Q</code> is extracted, the resulting type is the <code>HessenbergQ</code> object, and may be converted to a regular matrix with <a href="../../base/base/#Base.convert"><code>convert(Array, _)</code></a> (or <code>Array(_)</code> for short).</p><p>Iterating the decomposition produces the factors <code>F.Q</code> and <code>F.H</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3 4; 5 6 7 8; 9 10 11 12; 13 14 15 16]
4×4 Matrix{Int64}:
  1   2   3   4
  5   6   7   8
  9  10  11  12
 13  14  15  16

julia&gt; UpperHessenberg(A)
4×4 UpperHessenberg{Int64, Matrix{Int64}}:
 1   2   3   4
 5   6   7   8
 ⋅  10  11  12
 ⋅   ⋅  15  16</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.UniformScaling" href="#LinearAlgebra.UniformScaling"><code>LinearAlgebra.UniformScaling</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UniformScaling{T&lt;:Number}</code></pre><p>Generically sized uniform scaling operator defined as a scalar times the identity operator, <code>λ*I</code>. Although without an explicit <code>size</code>, it acts similarly to a matrix in many cases and includes support for some indexing. See also <a href="#LinearAlgebra.I"><code>I</code></a>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.6</header><div class="admonition-body"><p>Indexing using ranges is available as of Julia 1.6.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; J = UniformScaling(2.)
UniformScaling{Float64}
2.0*I

julia&gt; A = [1. 2.; 3. 4.]
2×2 Matrix{Float64}:
 1.0  2.0
 3.0  4.0

julia&gt; J*A
2×2 Matrix{Float64}:
 2.0  4.0
 6.0  8.0

julia&gt; J[1:2, 1:2]
2×2 Matrix{Float64}:
 2.0  0.0
 0.0  2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.I" href="#LinearAlgebra.I"><code>LinearAlgebra.I</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">I</code></pre><p>An object of type <a href="#LinearAlgebra.UniformScaling"><code>UniformScaling</code></a>, representing an identity matrix of any size.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; fill(1, (5,6)) * I == fill(1, (5,6))
true

julia&gt; [1 2im 3; 1im 2 3] * I
2×3 Matrix{Complex{Int64}}:
 1+0im  0+2im  3+0im
 0+1im  2+0im  3+0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Factorization" href="#LinearAlgebra.Factorization"><code>LinearAlgebra.Factorization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearAlgebra.Factorization</code></pre><p>Abstract type for <a href="https://en.wikipedia.org/wiki/Matrix_decomposition">matrix factorizations</a> a.k.a. matrix decompositions. See <a href="#man-linalg-factorizations">online documentation</a> for a list of available matrix factorizations.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LU" href="#LinearAlgebra.LU"><code>LinearAlgebra.LU</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LU &lt;: Factorization</code></pre><p>Matrix factorization type of the <code>LU</code> factorization of a square matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.lu"><code>lu</code></a>, the corresponding matrix factorization function.</p><p>The individual components of the factorization <code>F::LU</code> can be accessed via <a href="../../base/base/#Base.getproperty"><code>getproperty</code></a>:</p><table><tr><th style="text-align: left">Component</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><code>F.L</code></td><td style="text-align: left"><code>L</code> (unit lower triangular) part of <code>LU</code></td></tr><tr><td style="text-align: left"><code>F.U</code></td><td style="text-align: left"><code>U</code> (upper triangular) part of <code>LU</code></td></tr><tr><td style="text-align: left"><code>F.p</code></td><td style="text-align: left">(right) permutation <code>Vector</code></td></tr><tr><td style="text-align: left"><code>F.P</code></td><td style="text-align: left">(right) permutation <code>Matrix</code></td></tr></table><p>Iterating the factorization produces the components <code>F.L</code>, <code>F.U</code>, and <code>F.p</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4 3; 6 3]
2×2 Matrix{Int64}:
 4  3
 6  3

julia&gt; F = lu(A)
LU{Float64, Matrix{Float64}}
L factor:
2×2 Matrix{Float64}:
 1.0       0.0
 0.666667  1.0
U factor:
2×2 Matrix{Float64}:
 6.0  3.0
 0.0  1.0

julia&gt; F.L * F.U == A[F.p, :]
true

julia&gt; l, u, p = lu(A); # destructuring via iteration

julia&gt; l == F.L &amp;&amp; u == F.U &amp;&amp; p == F.p
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lu" href="#LinearAlgebra.lu"><code>LinearAlgebra.lu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lu(A, pivot=Val(true); check = true) -&gt; F::LU</code></pre><p>Compute the LU factorization of <code>A</code>.</p><p>When <code>check = true</code>, an error is thrown if the decomposition fails. When <code>check = false</code>, responsibility for checking the decomposition&#39;s validity (via <a href="#LinearAlgebra.issuccess"><code>issuccess</code></a>) lies with the user.</p><p>In most cases, if <code>A</code> is a subtype <code>S</code> of <code>AbstractMatrix{T}</code> with an element type <code>T</code> supporting <code>+</code>, <code>-</code>, <code>*</code> and <code>/</code>, the return type is <code>LU{T,S{T}}</code>. If pivoting is chosen (default) the element type should also support <a href="../../base/math/#Base.abs"><code>abs</code></a> and <a href="../../base/math/#Base.:&lt;"><code>&lt;</code></a>.</p><p>The individual components of the factorization <code>F</code> can be accessed via <a href="../../base/base/#Base.getproperty"><code>getproperty</code></a>:</p><table><tr><th style="text-align: left">Component</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><code>F.L</code></td><td style="text-align: left"><code>L</code> (lower triangular) part of <code>LU</code></td></tr><tr><td style="text-align: left"><code>F.U</code></td><td style="text-align: left"><code>U</code> (upper triangular) part of <code>LU</code></td></tr><tr><td style="text-align: left"><code>F.p</code></td><td style="text-align: left">(right) permutation <code>Vector</code></td></tr><tr><td style="text-align: left"><code>F.P</code></td><td style="text-align: left">(right) permutation <code>Matrix</code></td></tr></table><p>Iterating the factorization produces the components <code>F.L</code>, <code>F.U</code>, and <code>F.p</code>.</p><p>The relationship between <code>F</code> and <code>A</code> is</p><p><code>F.L*F.U == A[F.p, :]</code></p><p><code>F</code> further supports the following functions:</p><table><tr><th style="text-align: left">Supported function</th><th style="text-align: left"><code>LU</code></th><th style="text-align: left"><code>LU{T,Tridiagonal{T}}</code></th></tr><tr><td style="text-align: left"><a href="../../base/math/#Base.:/"><code>/</code></a></td><td style="text-align: left">✓</td><td style="text-align: left"></td></tr><tr><td style="text-align: left"><a href="../../base/math/#Base.:\\-Tuple{Any, Any}"><code>\</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr><tr><td style="text-align: left"><a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.det"><code>det</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.logdet"><code>logdet</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr><tr><td style="text-align: left"><a href="#LinearAlgebra.logabsdet"><code>logabsdet</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr><tr><td style="text-align: left"><a href="../../base/arrays/#Base.size"><code>size</code></a></td><td style="text-align: left">✓</td><td style="text-align: left">✓</td></tr></table><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4 3; 6 3]
2×2 Matrix{Int64}:
 4  3
 6  3

julia&gt; F = lu(A)
LU{Float64, Matrix{Float64}}
L factor:
2×2 Matrix{Float64}:
 1.0       0.0
 0.666667  1.0
U factor:
2×2 Matrix{Float64}:
 6.0  3.0
 0.0  1.0

julia&gt; F.L * F.U == A[F.p, :]
true

julia&gt; l, u, p = lu(A); # destructuring via iteration

julia&gt; l == F.L &amp;&amp; u == F.U &amp;&amp; p == F.p
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lu!" href="#LinearAlgebra.lu!"><code>LinearAlgebra.lu!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lu!(A, pivot=Val(true); check = true) -&gt; LU</code></pre><p><code>lu!</code> is the same as <a href="#LinearAlgebra.lu"><code>lu</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <a href="../../base/base/#Core.InexactError"><code>InexactError</code></a> exception is thrown if the factorization produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4. 3.; 6. 3.]
2×2 Matrix{Float64}:
 4.0  3.0
 6.0  3.0

julia&gt; F = lu!(A)
LU{Float64, Matrix{Float64}}
L factor:
2×2 Matrix{Float64}:
 1.0       0.0
 0.666667  1.0
U factor:
2×2 Matrix{Float64}:
 6.0  3.0
 0.0  1.0

julia&gt; iA = [4 3; 6 3]
2×2 Matrix{Int64}:
 4  3
 6  3

julia&gt; lu!(iA)
ERROR: InexactError: Int64(0.6666666666666666)
Stacktrace:
[...]</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Cholesky" href="#LinearAlgebra.Cholesky"><code>LinearAlgebra.Cholesky</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Cholesky &lt;: Factorization</code></pre><p>Matrix factorization type of the Cholesky factorization of a dense symmetric/Hermitian positive definite matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>, the corresponding matrix factorization function.</p><p>The triangular Cholesky factor can be obtained from the factorization <code>F::Cholesky</code> via <code>F.L</code> and <code>F.U</code>.</p><p>Iterating the decomposition produces the components <code>L</code> and <code>U</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4. 12. -16.; 12. 37. -43.; -16. -43. 98.]
3×3 Matrix{Float64}:
   4.0   12.0  -16.0
  12.0   37.0  -43.0
 -16.0  -43.0   98.0

julia&gt; C = cholesky(A)
Cholesky{Float64, Matrix{Float64}}
U factor:
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 2.0  6.0  -8.0
  ⋅   1.0   5.0
  ⋅    ⋅    3.0

julia&gt; C.U
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 2.0  6.0  -8.0
  ⋅   1.0   5.0
  ⋅    ⋅    3.0

julia&gt; C.L
3×3 LowerTriangular{Float64, Matrix{Float64}}:
  2.0   ⋅    ⋅
  6.0  1.0   ⋅
 -8.0  5.0  3.0

julia&gt; C.L * C.U == A
true

julia&gt; l, u = C; # destructuring via iteration

julia&gt; l == C.L &amp;&amp; u == C.U
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.CholeskyPivoted" href="#LinearAlgebra.CholeskyPivoted"><code>LinearAlgebra.CholeskyPivoted</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CholeskyPivoted</code></pre><p>Matrix factorization type of the pivoted Cholesky factorization of a dense symmetric/Hermitian positive semi-definite matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.cholesky"><code>cholesky(_, Val(true))</code></a>, the corresponding matrix factorization function.</p><p>The triangular Cholesky factor can be obtained from the factorization <code>F::CholeskyPivoted</code> via <code>F.L</code> and <code>F.U</code>.</p><p>Iterating the decomposition produces the components <code>L</code> and <code>U</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4. 12. -16.; 12. 37. -43.; -16. -43. 98.]
3×3 Matrix{Float64}:
   4.0   12.0  -16.0
  12.0   37.0  -43.0
 -16.0  -43.0   98.0

julia&gt; C = cholesky(A, Val(true))
CholeskyPivoted{Float64, Matrix{Float64}}
U factor with rank 3:
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 9.89949  -4.34366  -1.61624
  ⋅        4.25825   1.1694
  ⋅         ⋅        0.142334
permutation:
3-element Vector{Int64}:
 3
 2
 1

julia&gt; l, u = C; # destructuring via iteration

julia&gt; l == C.L &amp;&amp; u == C.U
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.cholesky" href="#LinearAlgebra.cholesky"><code>LinearAlgebra.cholesky</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">cholesky(A, Val(false); check = true) -&gt; Cholesky</code></pre><p>Compute the Cholesky factorization of a dense symmetric positive definite matrix <code>A</code> and return a <a href="#LinearAlgebra.Cholesky"><code>Cholesky</code></a> factorization. The matrix <code>A</code> can either be a <a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a> or <a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a> <a href="../../base/arrays/#Base.StridedMatrix"><code>StridedMatrix</code></a> or a <em>perfectly</em> symmetric or Hermitian <code>StridedMatrix</code>. The triangular Cholesky factor can be obtained from the factorization <code>F</code> with: <code>F.L</code> and <code>F.U</code>. The following functions are available for <code>Cholesky</code> objects: <a href="../../base/arrays/#Base.size"><code>size</code></a>, <a href="../../base/math/#Base.:\\-Tuple{Any, Any}"><code>\</code></a>, <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, <a href="#LinearAlgebra.logdet"><code>logdet</code></a> and <a href="#LinearAlgebra.isposdef"><code>isposdef</code></a>.</p><p>If you have a matrix <code>A</code> that is slightly non-Hermitian due to roundoff errors in its construction, wrap it in <code>Hermitian(A)</code> before passing it to <code>cholesky</code> in order to treat it as perfectly Hermitian.</p><p>When <code>check = true</code>, an error is thrown if the decomposition fails. When <code>check = false</code>, responsibility for checking the decomposition&#39;s validity (via <a href="#LinearAlgebra.issuccess"><code>issuccess</code></a>) lies with the user.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4. 12. -16.; 12. 37. -43.; -16. -43. 98.]
3×3 Matrix{Float64}:
   4.0   12.0  -16.0
  12.0   37.0  -43.0
 -16.0  -43.0   98.0

julia&gt; C = cholesky(A)
Cholesky{Float64, Matrix{Float64}}
U factor:
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 2.0  6.0  -8.0
  ⋅   1.0   5.0
  ⋅    ⋅    3.0

julia&gt; C.U
3×3 UpperTriangular{Float64, Matrix{Float64}}:
 2.0  6.0  -8.0
  ⋅   1.0   5.0
  ⋅    ⋅    3.0

julia&gt; C.L
3×3 LowerTriangular{Float64, Matrix{Float64}}:
  2.0   ⋅    ⋅
  6.0  1.0   ⋅
 -8.0  5.0  3.0

julia&gt; C.L * C.U == A
true</code></pre></div></section><section><div><pre><code class="language-none">cholesky(A, Val(true); tol = 0.0, check = true) -&gt; CholeskyPivoted</code></pre><p>Compute the pivoted Cholesky factorization of a dense symmetric positive semi-definite matrix <code>A</code> and return a <a href="#LinearAlgebra.CholeskyPivoted"><code>CholeskyPivoted</code></a> factorization. The matrix <code>A</code> can either be a <a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a> or <a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a> <a href="../../base/arrays/#Base.StridedMatrix"><code>StridedMatrix</code></a> or a <em>perfectly</em> symmetric or Hermitian <code>StridedMatrix</code>. The triangular Cholesky factor can be obtained from the factorization <code>F</code> with: <code>F.L</code> and <code>F.U</code>. The following functions are available for <code>CholeskyPivoted</code> objects: <a href="../../base/arrays/#Base.size"><code>size</code></a>, <a href="../../base/math/#Base.:\\-Tuple{Any, Any}"><code>\</code></a>, <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, and <a href="#LinearAlgebra.rank"><code>rank</code></a>. The argument <code>tol</code> determines the tolerance for determining the rank. For negative values, the tolerance is the machine precision.</p><p>If you have a matrix <code>A</code> that is slightly non-Hermitian due to roundoff errors in its construction, wrap it in <code>Hermitian(A)</code> before passing it to <code>cholesky</code> in order to treat it as perfectly Hermitian.</p><p>When <code>check = true</code>, an error is thrown if the decomposition fails. When <code>check = false</code>, responsibility for checking the decomposition&#39;s validity (via <a href="#LinearAlgebra.issuccess"><code>issuccess</code></a>) lies with the user.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.cholesky!" href="#LinearAlgebra.cholesky!"><code>LinearAlgebra.cholesky!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">cholesky!(A::StridedMatrix, Val(false); check = true) -&gt; Cholesky</code></pre><p>The same as <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <a href="../../base/base/#Core.InexactError"><code>InexactError</code></a> exception is thrown if the factorization produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 2 50]
2×2 Matrix{Int64}:
 1   2
 2  50

julia&gt; cholesky!(A)
ERROR: InexactError: Int64(6.782329983125268)
Stacktrace:
[...]</code></pre></div></section><section><div><pre><code class="language-none">cholesky!(A::StridedMatrix, Val(true); tol = 0.0, check = true) -&gt; CholeskyPivoted</code></pre><p>The same as <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <a href="../../base/base/#Core.InexactError"><code>InexactError</code></a> exception is thrown if the factorization produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lowrankupdate" href="#LinearAlgebra.lowrankupdate"><code>LinearAlgebra.lowrankupdate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lowrankupdate(C::Cholesky, v::StridedVector) -&gt; CC::Cholesky</code></pre><p>Update a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C.U&#39;C.U</code> then <code>CC = cholesky(C.U&#39;C.U + v*v&#39;)</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lowrankdowndate" href="#LinearAlgebra.lowrankdowndate"><code>LinearAlgebra.lowrankdowndate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lowrankdowndate(C::Cholesky, v::StridedVector) -&gt; CC::Cholesky</code></pre><p>Downdate a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C.U&#39;C.U</code> then <code>CC = cholesky(C.U&#39;C.U - v*v&#39;)</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lowrankupdate!" href="#LinearAlgebra.lowrankupdate!"><code>LinearAlgebra.lowrankupdate!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lowrankupdate!(C::Cholesky, v::StridedVector) -&gt; CC::Cholesky</code></pre><p>Update a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C.U&#39;C.U</code> then <code>CC = cholesky(C.U&#39;C.U + v*v&#39;)</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations. The input factorization <code>C</code> is updated in place such that on exit <code>C == CC</code>. The vector <code>v</code> is destroyed during the computation.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lowrankdowndate!" href="#LinearAlgebra.lowrankdowndate!"><code>LinearAlgebra.lowrankdowndate!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lowrankdowndate!(C::Cholesky, v::StridedVector) -&gt; CC::Cholesky</code></pre><p>Downdate a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C.U&#39;C.U</code> then <code>CC = cholesky(C.U&#39;C.U - v*v&#39;)</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations. The input factorization <code>C</code> is updated in place such that on exit <code>C == CC</code>. The vector <code>v</code> is destroyed during the computation.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LDLt" href="#LinearAlgebra.LDLt"><code>LinearAlgebra.LDLt</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LDLt &lt;: Factorization</code></pre><p>Matrix factorization type of the <code>LDLt</code> factorization of a real <a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a> matrix <code>S</code> such that <code>S = L*Diagonal(d)*L&#39;</code>, where <code>L</code> is a <a href="#LinearAlgebra.UnitLowerTriangular"><code>UnitLowerTriangular</code></a> matrix and <code>d</code> is a vector. The main use of an <code>LDLt</code> factorization <code>F = ldlt(S)</code> is to solve the linear system of equations <code>Sx = b</code> with <code>F\b</code>. This is the return type of <a href="#LinearAlgebra.ldlt"><code>ldlt</code></a>, the corresponding matrix factorization function.</p><p>The individual components of the factorization <code>F::LDLt</code> can be accessed via <code>getproperty</code>:</p><table><tr><th style="text-align: center">Component</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: center"><code>F.L</code></td><td style="text-align: left"><code>L</code> (unit lower triangular) part of <code>LDLt</code></td></tr><tr><td style="text-align: center"><code>F.D</code></td><td style="text-align: left"><code>D</code> (diagonal) part of <code>LDLt</code></td></tr><tr><td style="text-align: center"><code>F.Lt</code></td><td style="text-align: left"><code>Lt</code> (unit upper triangular) part of <code>LDLt</code></td></tr><tr><td style="text-align: center"><code>F.d</code></td><td style="text-align: left">diagonal values of <code>D</code> as a <code>Vector</code></td></tr></table><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; S = SymTridiagonal([3., 4., 5.], [1., 2.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 3.0  1.0   ⋅
 1.0  4.0  2.0
  ⋅   2.0  5.0

julia&gt; F = ldlt(S)
LDLt{Float64, SymTridiagonal{Float64, Vector{Float64}}}
L factor:
3×3 UnitLowerTriangular{Float64, SymTridiagonal{Float64, Vector{Float64}}}:
 1.0        ⋅         ⋅
 0.333333  1.0        ⋅
 0.0       0.545455  1.0
D factor:
3×3 Diagonal{Float64, Vector{Float64}}:
 3.0   ⋅        ⋅
  ⋅   3.66667   ⋅
  ⋅    ⋅       3.90909</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ldlt" href="#LinearAlgebra.ldlt"><code>LinearAlgebra.ldlt</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ldlt(S::SymTridiagonal) -&gt; LDLt</code></pre><p>Compute an <code>LDLt</code> factorization of the real symmetric tridiagonal matrix <code>S</code> such that <code>S = L*Diagonal(d)*L&#39;</code> where <code>L</code> is a unit lower triangular matrix and <code>d</code> is a vector. The main use of an <code>LDLt</code> factorization <code>F = ldlt(S)</code> is to solve the linear system of equations <code>Sx = b</code> with <code>F\b</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; S = SymTridiagonal([3., 4., 5.], [1., 2.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 3.0  1.0   ⋅
 1.0  4.0  2.0
  ⋅   2.0  5.0

julia&gt; ldltS = ldlt(S);

julia&gt; b = [6., 7., 8.];

julia&gt; ldltS \ b
3-element Vector{Float64}:
 1.7906976744186047
 0.627906976744186
 1.3488372093023255

julia&gt; S \ b
3-element Vector{Float64}:
 1.7906976744186047
 0.627906976744186
 1.3488372093023255</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ldlt!" href="#LinearAlgebra.ldlt!"><code>LinearAlgebra.ldlt!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ldlt!(S::SymTridiagonal) -&gt; LDLt</code></pre><p>Same as <a href="#LinearAlgebra.ldlt"><code>ldlt</code></a>, but saves space by overwriting the input <code>S</code>, instead of creating a copy.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; S = SymTridiagonal([3., 4., 5.], [1., 2.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 3.0  1.0   ⋅
 1.0  4.0  2.0
  ⋅   2.0  5.0

julia&gt; ldltS = ldlt!(S);

julia&gt; ldltS === S
false

julia&gt; S
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 3.0       0.333333   ⋅
 0.333333  3.66667   0.545455
  ⋅        0.545455  3.90909</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.QR" href="#LinearAlgebra.QR"><code>LinearAlgebra.QR</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">QR &lt;: Factorization</code></pre><p>A QR matrix factorization stored in a packed format, typically obtained from <a href="#LinearAlgebra.qr"><code>qr</code></a>. If <span>$A$</span> is an <code>m</code>×<code>n</code> matrix, then</p><p class="math-container">\[A = Q R\]</p><p>where <span>$Q$</span> is an orthogonal/unitary matrix and <span>$R$</span> is upper triangular. The matrix <span>$Q$</span> is stored as a sequence of Householder reflectors <span>$v_i$</span> and coefficients <span>$\tau_i$</span> where:</p><p class="math-container">\[Q = \prod_{i=1}^{\min(m,n)} (I - \tau_i v_i v_i^T).\]</p><p>Iterating the decomposition produces the components <code>Q</code> and <code>R</code>.</p><p>The object has two fields:</p><ul><li><p><code>factors</code> is an <code>m</code>×<code>n</code> matrix.</p><ul><li><p>The upper triangular part contains the elements of <span>$R$</span>, that is <code>R = triu(F.factors)</code> for a <code>QR</code> object <code>F</code>.</p></li><li><p>The subdiagonal part contains the reflectors <span>$v_i$</span> stored in a packed format where <span>$v_i$</span> is the <span>$i$</span>th column of the matrix <code>V = I + tril(F.factors, -1)</code>.</p></li></ul></li><li><p><code>τ</code> is a vector  of length <code>min(m,n)</code> containing the coefficients <span>$au_i$</span>.</p></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.QRCompactWY" href="#LinearAlgebra.QRCompactWY"><code>LinearAlgebra.QRCompactWY</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">QRCompactWY &lt;: Factorization</code></pre><p>A QR matrix factorization stored in a compact blocked format, typically obtained from <a href="#LinearAlgebra.qr"><code>qr</code></a>. If <span>$A$</span> is an <code>m</code>×<code>n</code> matrix, then</p><p class="math-container">\[A = Q R\]</p><p>where <span>$Q$</span> is an orthogonal/unitary matrix and <span>$R$</span> is upper triangular. It is similar to the <a href="#LinearAlgebra.QR"><code>QR</code></a> format except that the orthogonal/unitary matrix <span>$Q$</span> is stored in <em>Compact WY</em> format <sup class="footnote-reference"><a id="citeref-Schreiber1989" href="#footnote-Schreiber1989">[Schreiber1989]</a></sup>.  For the block size <span>$n_b$</span>, it is stored as a <code>m</code>×<code>n</code> lower trapezoidal matrix <span>$V$</span> and a matrix <span>$T = (T_1 \; T_2 \; ... \; T_{b-1} \; T_b&#39;)$</span> composed of <span>$b = \lceil \min(m,n) / n_b \rceil$</span> upper triangular matrices <span>$T_j$</span> of size <span>$n_b$</span>×<span>$n_b$</span> (<span>$j = 1, ..., b-1$</span>) and an upper trapezoidal <span>$n_b$</span>×<span>$\min(m,n) - (b-1) n_b$</span> matrix <span>$T_b&#39;$</span> (<span>$j=b$</span>) whose upper square part denoted with <span>$T_b$</span> satisfying</p><p class="math-container">\[Q = \prod_{i=1}^{\min(m,n)} (I - \tau_i v_i v_i^T)
= \prod_{j=1}^{b} (I - V_j T_j V_j^T)\]</p><p>such that <span>$v_i$</span> is the <span>$i$</span>th column of <span>$V$</span>, <span>$\tau_i$</span> is the <span>$i$</span>th element of <code>[diag(T_1); diag(T_2); …; diag(T_b)]</code>, and <span>$(V_1 \; V_2 \; ... \; V_b)$</span> is the left <code>m</code>×<code>min(m, n)</code> block of <span>$V$</span>.  When constructed using <a href="#LinearAlgebra.qr"><code>qr</code></a>, the block size is given by <span>$n_b = \min(m, n, 36)$</span>.</p><p>Iterating the decomposition produces the components <code>Q</code> and <code>R</code>.</p><p>The object has two fields:</p><ul><li><p><code>factors</code>, as in the <a href="#LinearAlgebra.QR"><code>QR</code></a> type, is an <code>m</code>×<code>n</code> matrix.</p><ul><li><p>The upper triangular part contains the elements of <span>$R$</span>, that is <code>R = triu(F.factors)</code> for a <code>QR</code> object <code>F</code>.</p></li><li><p>The subdiagonal part contains the reflectors <span>$v_i$</span> stored in a packed format such that <code>V = I + tril(F.factors, -1)</code>.</p></li></ul></li><li><p><code>T</code> is a <span>$n_b$</span>-by-<span>$\min(m,n)$</span> matrix as described above. The subdiagonal elements for each triangular matrix <span>$T_j$</span> are ignored.</p></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This format should not to be confused with the older <em>WY</em> representation <sup class="footnote-reference"><a id="citeref-Bischof1987" href="#footnote-Bischof1987">[Bischof1987]</a></sup>.</p></div></div></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.QRPivoted" href="#LinearAlgebra.QRPivoted"><code>LinearAlgebra.QRPivoted</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">QRPivoted &lt;: Factorization</code></pre><p>A QR matrix factorization with column pivoting in a packed format, typically obtained from <a href="#LinearAlgebra.qr"><code>qr</code></a>. If <span>$A$</span> is an <code>m</code>×<code>n</code> matrix, then</p><p class="math-container">\[A P = Q R\]</p><p>where <span>$P$</span> is a permutation matrix, <span>$Q$</span> is an orthogonal/unitary matrix and <span>$R$</span> is upper triangular. The matrix <span>$Q$</span> is stored as a sequence of Householder reflectors:</p><p class="math-container">\[Q = \prod_{i=1}^{\min(m,n)} (I - \tau_i v_i v_i^T).\]</p><p>Iterating the decomposition produces the components <code>Q</code>, <code>R</code>, and <code>p</code>.</p><p>The object has three fields:</p><ul><li><p><code>factors</code> is an <code>m</code>×<code>n</code> matrix.</p><ul><li><p>The upper triangular part contains the elements of <span>$R$</span>, that is <code>R = triu(F.factors)</code> for a <code>QR</code> object <code>F</code>.</p></li><li><p>The subdiagonal part contains the reflectors <span>$v_i$</span> stored in a packed format where <span>$v_i$</span> is the <span>$i$</span>th column of the matrix <code>V = I + tril(F.factors, -1)</code>.</p></li></ul></li><li><p><code>τ</code> is a vector of length <code>min(m,n)</code> containing the coefficients <span>$au_i$</span>.</p></li><li><p><code>jpvt</code> is an integer vector of length <code>n</code> corresponding to the permutation <span>$P$</span>.</p></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.qr" href="#LinearAlgebra.qr"><code>LinearAlgebra.qr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">qr(A, pivot=Val(false); blocksize) -&gt; F</code></pre><p>Compute the QR factorization of the matrix <code>A</code>: an orthogonal (or unitary if <code>A</code> is complex-valued) matrix <code>Q</code>, and an upper triangular matrix <code>R</code> such that</p><p class="math-container">\[A = Q R\]</p><p>The returned object <code>F</code> stores the factorization in a packed format:</p><ul><li><p>if <code>pivot == Val(true)</code> then <code>F</code> is a <a href="#LinearAlgebra.QRPivoted"><code>QRPivoted</code></a> object,</p></li><li><p>otherwise if the element type of <code>A</code> is a BLAS type (<a href="../../base/numbers/#Core.Float32"><code>Float32</code></a>, <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a>, <code>ComplexF32</code> or <code>ComplexF64</code>), then <code>F</code> is a <a href="#LinearAlgebra.QRCompactWY"><code>QRCompactWY</code></a> object,</p></li><li><p>otherwise <code>F</code> is a <a href="#LinearAlgebra.QR"><code>QR</code></a> object.</p></li></ul><p>The individual components of the decomposition <code>F</code> can be retrieved via property accessors:</p><ul><li><code>F.Q</code>: the orthogonal/unitary matrix <code>Q</code></li><li><code>F.R</code>: the upper triangular matrix <code>R</code></li><li><code>F.p</code>: the permutation vector of the pivot (<a href="#LinearAlgebra.QRPivoted"><code>QRPivoted</code></a> only)</li><li><code>F.P</code>: the permutation matrix of the pivot (<a href="#LinearAlgebra.QRPivoted"><code>QRPivoted</code></a> only)</li></ul><p>Iterating the decomposition produces the components <code>Q</code>, <code>R</code>, and if extant <code>p</code>.</p><p>The following functions are available for the <code>QR</code> objects: <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="../../base/arrays/#Base.size"><code>size</code></a>, and <a href="../../base/math/#Base.:\\-Tuple{Any, Any}"><code>\</code></a>. When <code>A</code> is rectangular, <code>\</code> will return a least squares solution and if the solution is not unique, the one with smallest norm is returned. When <code>A</code> is not full rank, factorization with (column) pivoting is required to obtain a minimum norm solution.</p><p>Multiplication with respect to either full/square or non-full/square <code>Q</code> is allowed, i.e. both <code>F.Q*F.R</code> and <code>F.Q*A</code> are supported. A <code>Q</code> matrix can be converted into a regular matrix with <a href="../../base/arrays/#Base.Matrix"><code>Matrix</code></a>.  This operation returns the &quot;thin&quot; Q factor, i.e., if <code>A</code> is <code>m</code>×<code>n</code> with <code>m&gt;=n</code>, then <code>Matrix(F.Q)</code> yields an <code>m</code>×<code>n</code> matrix with orthonormal columns.  To retrieve the &quot;full&quot; Q factor, an <code>m</code>×<code>m</code> orthogonal matrix, use <code>F.Q*Matrix(I,m,m)</code>.  If <code>m&lt;=n</code>, then <code>Matrix(F.Q)</code> yields an <code>m</code>×<code>m</code> orthogonal matrix.</p><p>The block size for QR decomposition can be specified by keyword argument <code>blocksize :: Integer</code> when <code>pivot == Val(false)</code> and <code>A isa StridedMatrix{&lt;:BlasFloat}</code>. It is ignored when <code>blocksize &gt; minimum(size(A))</code>.  See <a href="#LinearAlgebra.QRCompactWY"><code>QRCompactWY</code></a>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.4</header><div class="admonition-body"><p>The <code>blocksize</code> keyword argument requires Julia 1.4 or later.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3.0 -6.0; 4.0 -8.0; 0.0 1.0]
3×2 Matrix{Float64}:
 3.0  -6.0
 4.0  -8.0
 0.0   1.0

julia&gt; F = qr(A)
LinearAlgebra.QRCompactWY{Float64, Matrix{Float64}}
Q factor:
3×3 LinearAlgebra.QRCompactWYQ{Float64, Matrix{Float64}}:
 -0.6   0.0   0.8
 -0.8   0.0  -0.6
  0.0  -1.0   0.0
R factor:
2×2 Matrix{Float64}:
 -5.0  10.0
  0.0  -1.0

julia&gt; F.Q * F.R == A
true</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>qr</code> returns multiple types because LAPACK uses several representations that minimize the memory storage requirements of products of Householder elementary reflectors, so that the <code>Q</code> and <code>R</code> matrices can be stored compactly rather as two separate dense matrices.</p></div></div></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.qr!" href="#LinearAlgebra.qr!"><code>LinearAlgebra.qr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">qr!(A, pivot=Val(false); blocksize)</code></pre><p><code>qr!</code> is the same as <a href="#LinearAlgebra.qr"><code>qr</code></a> when <code>A</code> is a subtype of <a href="../../base/arrays/#Base.StridedMatrix"><code>StridedMatrix</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <a href="../../base/base/#Core.InexactError"><code>InexactError</code></a> exception is thrown if the factorization produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.4</header><div class="admonition-body"><p>The <code>blocksize</code> keyword argument requires Julia 1.4 or later.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1. 2.; 3. 4.]
2×2 Matrix{Float64}:
 1.0  2.0
 3.0  4.0

julia&gt; qr!(a)
LinearAlgebra.QRCompactWY{Float64, Matrix{Float64}}
Q factor:
2×2 LinearAlgebra.QRCompactWYQ{Float64, Matrix{Float64}}:
 -0.316228  -0.948683
 -0.948683   0.316228
R factor:
2×2 Matrix{Float64}:
 -3.16228  -4.42719
  0.0      -0.632456

julia&gt; a = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; qr!(a)
ERROR: InexactError: Int64(-3.1622776601683795)
Stacktrace:
[...]</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LQ" href="#LinearAlgebra.LQ"><code>LinearAlgebra.LQ</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LQ &lt;: Factorization</code></pre><p>Matrix factorization type of the <code>LQ</code> factorization of a matrix <code>A</code>. The <code>LQ</code> decomposition is the <a href="#LinearAlgebra.QR"><code>QR</code></a> decomposition of <code>transpose(A)</code>. This is the return type of <a href="#LinearAlgebra.lq"><code>lq</code></a>, the corresponding matrix factorization function.</p><p>If <code>S::LQ</code> is the factorization object, the lower triangular component can be obtained via <code>S.L</code>, and the orthogonal/unitary component via <code>S.Q</code>, such that <code>A ≈ S.L*S.Q</code>.</p><p>Iterating the decomposition produces the components <code>S.L</code> and <code>S.Q</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [5. 7.; -2. -4.]
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; S = lq(A)
LQ{Float64, Matrix{Float64}} with factors L and Q:
[-8.60233 0.0; 4.41741 -0.697486]
[-0.581238 -0.813733; -0.813733 0.581238]

julia&gt; S.L * S.Q
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; l, q = S; # destructuring via iteration

julia&gt; l == S.L &amp;&amp;  q == S.Q
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lq" href="#LinearAlgebra.lq"><code>LinearAlgebra.lq</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lq(A) -&gt; S::LQ</code></pre><p>Compute the LQ decomposition of <code>A</code>. The decomposition&#39;s lower triangular component can be obtained from the <a href="#LinearAlgebra.LQ"><code>LQ</code></a> object <code>S</code> via <code>S.L</code>, and the orthogonal/unitary component via <code>S.Q</code>, such that <code>A ≈ S.L*S.Q</code>.</p><p>Iterating the decomposition produces the components <code>S.L</code> and <code>S.Q</code>.</p><p>The LQ decomposition is the QR decomposition of <code>transpose(A)</code>, and it is useful in order to compute the minimum-norm solution <code>lq(A) \ b</code> to an underdetermined system of equations (<code>A</code> has more columns than rows, but has full row rank).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [5. 7.; -2. -4.]
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; S = lq(A)
LQ{Float64, Matrix{Float64}} with factors L and Q:
[-8.60233 0.0; 4.41741 -0.697486]
[-0.581238 -0.813733; -0.813733 0.581238]

julia&gt; S.L * S.Q
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; l, q = S; # destructuring via iteration

julia&gt; l == S.L &amp;&amp;  q == S.Q
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lq!" href="#LinearAlgebra.lq!"><code>LinearAlgebra.lq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lq!(A) -&gt; LQ</code></pre><p>Compute the <a href="#LinearAlgebra.LQ"><code>LQ</code></a> factorization of <code>A</code>, using the input matrix as a workspace. See also <a href="#LinearAlgebra.lq"><code>lq</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BunchKaufman" href="#LinearAlgebra.BunchKaufman"><code>LinearAlgebra.BunchKaufman</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">BunchKaufman &lt;: Factorization</code></pre><p>Matrix factorization type of the Bunch-Kaufman factorization of a symmetric or Hermitian matrix <code>A</code> as <code>P&#39;UDU&#39;P</code> or <code>P&#39;LDL&#39;P</code>, depending on whether the upper (the default) or the lower triangle is stored in <code>A</code>. If <code>A</code> is complex symmetric then <code>U&#39;</code> and <code>L&#39;</code> denote the unconjugated transposes, i.e. <code>transpose(U)</code> and <code>transpose(L)</code>, respectively. This is the return type of <a href="#LinearAlgebra.bunchkaufman"><code>bunchkaufman</code></a>, the corresponding matrix factorization function.</p><p>If <code>S::BunchKaufman</code> is the factorization object, the components can be obtained via <code>S.D</code>, <code>S.U</code> or <code>S.L</code> as appropriate given <code>S.uplo</code>, and <code>S.p</code>.</p><p>Iterating the decomposition produces the components <code>S.D</code>, <code>S.U</code> or <code>S.L</code> as appropriate given <code>S.uplo</code>, and <code>S.p</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 2 3]
2×2 Matrix{Int64}:
 1  2
 2  3

julia&gt; S = bunchkaufman(A) # A gets wrapped internally by Symmetric(A)
BunchKaufman{Float64, Matrix{Float64}}
D factor:
2×2 Tridiagonal{Float64, Vector{Float64}}:
 -0.333333  0.0
  0.0       3.0
U factor:
2×2 UnitUpperTriangular{Float64, Matrix{Float64}}:
 1.0  0.666667
  ⋅   1.0
permutation:
2-element Vector{Int64}:
 1
 2

julia&gt; d, u, p = S; # destructuring via iteration

julia&gt; d == S.D &amp;&amp; u == S.U &amp;&amp; p == S.p
true

julia&gt; S = bunchkaufman(Symmetric(A, :L))
BunchKaufman{Float64, Matrix{Float64}}
D factor:
2×2 Tridiagonal{Float64, Vector{Float64}}:
 3.0   0.0
 0.0  -0.333333
L factor:
2×2 UnitLowerTriangular{Float64, Matrix{Float64}}:
 1.0        ⋅
 0.666667  1.0
permutation:
2-element Vector{Int64}:
 2
 1</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.bunchkaufman" href="#LinearAlgebra.bunchkaufman"><code>LinearAlgebra.bunchkaufman</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bunchkaufman(A, rook::Bool=false; check = true) -&gt; S::BunchKaufman</code></pre><p>Compute the Bunch-Kaufman <sup class="footnote-reference"><a id="citeref-Bunch1977" href="#footnote-Bunch1977">[Bunch1977]</a></sup> factorization of a symmetric or Hermitian matrix <code>A</code> as <code>P&#39;*U*D*U&#39;*P</code> or <code>P&#39;*L*D*L&#39;*P</code>, depending on which triangle is stored in <code>A</code>, and return a <a href="#LinearAlgebra.BunchKaufman"><code>BunchKaufman</code></a> object. Note that if <code>A</code> is complex symmetric then <code>U&#39;</code> and <code>L&#39;</code> denote the unconjugated transposes, i.e. <code>transpose(U)</code> and <code>transpose(L)</code>.</p><p>Iterating the decomposition produces the components <code>S.D</code>, <code>S.U</code> or <code>S.L</code> as appropriate given <code>S.uplo</code>, and <code>S.p</code>.</p><p>If <code>rook</code> is <code>true</code>, rook pivoting is used. If <code>rook</code> is false, rook pivoting is not used.</p><p>When <code>check = true</code>, an error is thrown if the decomposition fails. When <code>check = false</code>, responsibility for checking the decomposition&#39;s validity (via <a href="#LinearAlgebra.issuccess"><code>issuccess</code></a>) lies with the user.</p><p>The following functions are available for <code>BunchKaufman</code> objects: <a href="../../base/arrays/#Base.size"><code>size</code></a>, <code>\</code>, <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.issymmetric"><code>issymmetric</code></a>, <a href="#LinearAlgebra.ishermitian"><code>ishermitian</code></a>, <a href="../../base/collections/#Base.getindex"><code>getindex</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 2 3]
2×2 Matrix{Int64}:
 1  2
 2  3

julia&gt; S = bunchkaufman(A) # A gets wrapped internally by Symmetric(A)
BunchKaufman{Float64, Matrix{Float64}}
D factor:
2×2 Tridiagonal{Float64, Vector{Float64}}:
 -0.333333  0.0
  0.0       3.0
U factor:
2×2 UnitUpperTriangular{Float64, Matrix{Float64}}:
 1.0  0.666667
  ⋅   1.0
permutation:
2-element Vector{Int64}:
 1
 2

julia&gt; d, u, p = S; # destructuring via iteration

julia&gt; d == S.D &amp;&amp; u == S.U &amp;&amp; p == S.p
true

julia&gt; S = bunchkaufman(Symmetric(A, :L))
BunchKaufman{Float64, Matrix{Float64}}
D factor:
2×2 Tridiagonal{Float64, Vector{Float64}}:
 3.0   0.0
 0.0  -0.333333
L factor:
2×2 UnitLowerTriangular{Float64, Matrix{Float64}}:
 1.0        ⋅
 0.666667  1.0
permutation:
2-element Vector{Int64}:
 2
 1</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.bunchkaufman!" href="#LinearAlgebra.bunchkaufman!"><code>LinearAlgebra.bunchkaufman!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bunchkaufman!(A, rook::Bool=false; check = true) -&gt; BunchKaufman</code></pre><p><code>bunchkaufman!</code> is the same as <a href="#LinearAlgebra.bunchkaufman"><code>bunchkaufman</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Eigen" href="#LinearAlgebra.Eigen"><code>LinearAlgebra.Eigen</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Eigen &lt;: Factorization</code></pre><p>Matrix factorization type of the eigenvalue/spectral decomposition of a square matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.eigen"><code>eigen</code></a>, the corresponding matrix factorization function.</p><p>If <code>F::Eigen</code> is the factorization object, the eigenvalues can be obtained via <code>F.values</code> and the eigenvectors as the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; F = eigen([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])
Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}
values:
3-element Vector{Float64}:
  1.0
  3.0
 18.0
vectors:
3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0

julia&gt; F.values
3-element Vector{Float64}:
  1.0
  3.0
 18.0

julia&gt; F.vectors
3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0

julia&gt; vals, vecs = F; # destructuring via iteration

julia&gt; vals == F.values &amp;&amp; vecs == F.vectors
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.GeneralizedEigen" href="#LinearAlgebra.GeneralizedEigen"><code>LinearAlgebra.GeneralizedEigen</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GeneralizedEigen &lt;: Factorization</code></pre><p>Matrix factorization type of the generalized eigenvalue/spectral decomposition of <code>A</code> and <code>B</code>. This is the return type of <a href="#LinearAlgebra.eigen"><code>eigen</code></a>, the corresponding matrix factorization function, when called with two matrix arguments.</p><p>If <code>F::GeneralizedEigen</code> is the factorization object, the eigenvalues can be obtained via <code>F.values</code> and the eigenvectors as the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0; 0 -1]
2×2 Matrix{Int64}:
 1   0
 0  -1

julia&gt; B = [0 1; 1 0]
2×2 Matrix{Int64}:
 0  1
 1  0

julia&gt; F = eigen(A, B)
GeneralizedEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}
values:
2-element Vector{ComplexF64}:
 0.0 - 1.0im
 0.0 + 1.0im
vectors:
2×2 Matrix{ComplexF64}:
  0.0+1.0im   0.0-1.0im
 -1.0+0.0im  -1.0-0.0im

julia&gt; F.values
2-element Vector{ComplexF64}:
 0.0 - 1.0im
 0.0 + 1.0im

julia&gt; F.vectors
2×2 Matrix{ComplexF64}:
  0.0+1.0im   0.0-1.0im
 -1.0+0.0im  -1.0-0.0im

julia&gt; vals, vecs = F; # destructuring via iteration

julia&gt; vals == F.values &amp;&amp; vecs == F.vectors
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals" href="#LinearAlgebra.eigvals"><code>LinearAlgebra.eigvals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigvals(A; permute::Bool=true, scale::Bool=true, sortby) -&gt; values</code></pre><p>Return the eigenvalues of <code>A</code>.</p><p>For general non-symmetric matrices it is possible to specify how the matrix is balanced before the eigenvalue calculation. The <code>permute</code>, <code>scale</code>, and <code>sortby</code> keywords are the same as for <a href="#LinearAlgebra.eigen!"><code>eigen!</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; diag_matrix = [1 0; 0 4]
2×2 Matrix{Int64}:
 1  0
 0  4

julia&gt; eigvals(diag_matrix)
2-element Vector{Float64}:
 1.0
 4.0</code></pre></div></section><section><div><p>For a scalar input, <code>eigvals</code> will return a scalar.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; eigvals(-2)
-2</code></pre></div></section><section><div><pre><code class="language-none">eigvals(A, B) -&gt; values</code></pre><p>Computes the generalized eigenvalues of <code>A</code> and <code>B</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0; 0 -1]
2×2 Matrix{Int64}:
 1   0
 0  -1

julia&gt; B = [0 1; 1 0]
2×2 Matrix{Int64}:
 0  1
 1  0

julia&gt; eigvals(A,B)
2-element Vector{ComplexF64}:
 0.0 - 1.0im
 0.0 + 1.0im</code></pre></div></section><section><div><pre><code class="language-none">eigvals(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -&gt; values</code></pre><p>Returns the eigenvalues of <code>A</code>. It is possible to calculate only a subset of the eigenvalues by specifying a <a href="../../base/collections/#Base.UnitRange"><code>UnitRange</code></a> <code>irange</code> covering indices of the sorted eigenvalues, e.g. the 2nd to 8th eigenvalues.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 1.0  2.0   ⋅
 2.0  2.0  3.0
  ⋅   3.0  1.0

julia&gt; eigvals(A, 2:2)
1-element Vector{Float64}:
 0.9999999999999996

julia&gt; eigvals(A)
3-element Vector{Float64}:
 -2.1400549446402604
  1.0000000000000002
  5.140054944640259</code></pre></div></section><section><div><pre><code class="language-none">eigvals(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -&gt; values</code></pre><p>Returns the eigenvalues of <code>A</code>. It is possible to calculate only a subset of the eigenvalues by specifying a pair <code>vl</code> and <code>vu</code> for the lower and upper boundaries of the eigenvalues.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 1.0  2.0   ⋅
 2.0  2.0  3.0
  ⋅   3.0  1.0

julia&gt; eigvals(A, -1, 2)
1-element Vector{Float64}:
 1.0000000000000009

julia&gt; eigvals(A)
3-element Vector{Float64}:
 -2.1400549446402604
  1.0000000000000002
  5.140054944640259</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals!" href="#LinearAlgebra.eigvals!"><code>LinearAlgebra.eigvals!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigvals!(A; permute::Bool=true, scale::Bool=true, sortby) -&gt; values</code></pre><p>Same as <a href="#LinearAlgebra.eigvals"><code>eigvals</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. The <code>permute</code>, <code>scale</code>, and <code>sortby</code> keywords are the same as for <a href="#LinearAlgebra.eigen"><code>eigen</code></a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The input matrix <code>A</code> will not contain its eigenvalues after <code>eigvals!</code> is called on it - <code>A</code> is used as a workspace.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 2.; 3. 4.]
2×2 Matrix{Float64}:
 1.0  2.0
 3.0  4.0

julia&gt; eigvals!(A)
2-element Vector{Float64}:
 -0.3722813232690143
  5.372281323269014

julia&gt; A
2×2 Matrix{Float64}:
 -0.372281  -1.0
  0.0        5.37228</code></pre></div></section><section><div><pre><code class="language-none">eigvals!(A, B; sortby) -&gt; values</code></pre><p>Same as <a href="#LinearAlgebra.eigvals"><code>eigvals</code></a>, but saves space by overwriting the input <code>A</code> (and <code>B</code>), instead of creating copies.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The input matrices <code>A</code> and <code>B</code> will not contain their eigenvalues after <code>eigvals!</code> is called. They are used as workspaces.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 0.; 0. -1.]
2×2 Matrix{Float64}:
 1.0   0.0
 0.0  -1.0

julia&gt; B = [0. 1.; 1. 0.]
2×2 Matrix{Float64}:
 0.0  1.0
 1.0  0.0

julia&gt; eigvals!(A, B)
2-element Vector{ComplexF64}:
 0.0 - 1.0im
 0.0 + 1.0im

julia&gt; A
2×2 Matrix{Float64}:
 -0.0  -1.0
  1.0  -0.0

julia&gt; B
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0</code></pre></div></section><section><div><pre><code class="language-none">eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -&gt; values</code></pre><p>Same as <a href="#LinearAlgebra.eigvals"><code>eigvals</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. <code>irange</code> is a range of eigenvalue <em>indices</em> to search for - for instance, the 2nd to 8th eigenvalues.</p></div></section><section><div><pre><code class="language-none">eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -&gt; values</code></pre><p>Same as <a href="#LinearAlgebra.eigvals"><code>eigvals</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. <code>vl</code> is the lower bound of the interval to search for eigenvalues, and <code>vu</code> is the upper bound.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigmax" href="#LinearAlgebra.eigmax"><code>LinearAlgebra.eigmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigmax(A; permute::Bool=true, scale::Bool=true)</code></pre><p>Return the largest eigenvalue of <code>A</code>. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of <code>A</code> are complex, this method will fail, since complex numbers cannot be sorted.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [0 im; -im 0]
2×2 Matrix{Complex{Int64}}:
 0+0im  0+1im
 0-1im  0+0im

julia&gt; eigmax(A)
1.0

julia&gt; A = [0 im; -1 0]
2×2 Matrix{Complex{Int64}}:
  0+0im  0+1im
 -1+0im  0+0im

julia&gt; eigmax(A)
ERROR: DomainError with Complex{Int64}[0+0im 0+1im; -1+0im 0+0im]:
`A` cannot have complex eigenvalues.
Stacktrace:
[...]</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigmin" href="#LinearAlgebra.eigmin"><code>LinearAlgebra.eigmin</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigmin(A; permute::Bool=true, scale::Bool=true)</code></pre><p>Return the smallest eigenvalue of <code>A</code>. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of <code>A</code> are complex, this method will fail, since complex numbers cannot be sorted.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [0 im; -im 0]
2×2 Matrix{Complex{Int64}}:
 0+0im  0+1im
 0-1im  0+0im

julia&gt; eigmin(A)
-1.0

julia&gt; A = [0 im; -1 0]
2×2 Matrix{Complex{Int64}}:
  0+0im  0+1im
 -1+0im  0+0im

julia&gt; eigmin(A)
ERROR: DomainError with Complex{Int64}[0+0im 0+1im; -1+0im 0+0im]:
`A` cannot have complex eigenvalues.
Stacktrace:
[...]</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvecs" href="#LinearAlgebra.eigvecs"><code>LinearAlgebra.eigvecs</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigvecs(A::SymTridiagonal[, eigvals]) -&gt; Matrix</code></pre><p>Return a matrix <code>M</code> whose columns are the eigenvectors of <code>A</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>M[:, k]</code>.)</p><p>If the optional vector of eigenvalues <code>eigvals</code> is specified, <code>eigvecs</code> returns the specific corresponding eigenvectors.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])
3×3 SymTridiagonal{Float64, Vector{Float64}}:
 1.0  2.0   ⋅
 2.0  2.0  3.0
  ⋅   3.0  1.0

julia&gt; eigvals(A)
3-element Vector{Float64}:
 -2.1400549446402604
  1.0000000000000002
  5.140054944640259

julia&gt; eigvecs(A)
3×3 Matrix{Float64}:
  0.418304  -0.83205      0.364299
 -0.656749  -7.39009e-16  0.754109
  0.627457   0.5547       0.546448

julia&gt; eigvecs(A, [1.])
3×1 Matrix{Float64}:
  0.8320502943378438
  4.263514128092366e-17
 -0.5547001962252291</code></pre></div></section><section><div><pre><code class="language-none">eigvecs(A; permute::Bool=true, scale::Bool=true, `sortby`) -&gt; Matrix</code></pre><p>Return a matrix <code>M</code> whose columns are the eigenvectors of <code>A</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>M[:, k]</code>.) The <code>permute</code>, <code>scale</code>, and <code>sortby</code> keywords are the same as for <a href="#LinearAlgebra.eigen"><code>eigen</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; eigvecs([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])
3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0</code></pre></div></section><section><div><pre><code class="language-none">eigvecs(A, B) -&gt; Matrix</code></pre><p>Return a matrix <code>M</code> whose columns are the generalized eigenvectors of <code>A</code> and <code>B</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>M[:, k]</code>.)</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0; 0 -1]
2×2 Matrix{Int64}:
 1   0
 0  -1

julia&gt; B = [0 1; 1 0]
2×2 Matrix{Int64}:
 0  1
 1  0

julia&gt; eigvecs(A, B)
2×2 Matrix{ComplexF64}:
  0.0+1.0im   0.0-1.0im
 -1.0+0.0im  -1.0-0.0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigen" href="#LinearAlgebra.eigen"><code>LinearAlgebra.eigen</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigen(A; permute::Bool=true, scale::Bool=true, sortby) -&gt; Eigen</code></pre><p>Computes the eigenvalue decomposition of <code>A</code>, returning an <a href="#LinearAlgebra.Eigen"><code>Eigen</code></a> factorization object <code>F</code> which contains the eigenvalues in <code>F.values</code> and the eigenvectors in the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p>The following functions are available for <code>Eigen</code> objects: <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, and <a href="#LinearAlgebra.isposdef"><code>isposdef</code></a>.</p><p>For general nonsymmetric matrices it is possible to specify how the matrix is balanced before the eigenvector calculation. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. The default is <code>true</code> for both options.</p><p>By default, the eigenvalues and vectors are sorted lexicographically by <code>(real(λ),imag(λ))</code>. A different comparison function <code>by(λ)</code> can be passed to <code>sortby</code>, or you can pass <code>sortby=nothing</code> to leave the eigenvalues in an arbitrary order.   Some special matrix types (e.g. <a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a> or <a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a>) may implement their own sorting convention and not accept a <code>sortby</code> keyword.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; F = eigen([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])
Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}
values:
3-element Vector{Float64}:
  1.0
  3.0
 18.0
vectors:
3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0

julia&gt; F.values
3-element Vector{Float64}:
  1.0
  3.0
 18.0

julia&gt; F.vectors
3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0

julia&gt; vals, vecs = F; # destructuring via iteration

julia&gt; vals == F.values &amp;&amp; vecs == F.vectors
true</code></pre></div></section><section><div><pre><code class="language-none">eigen(A, B) -&gt; GeneralizedEigen</code></pre><p>Computes the generalized eigenvalue decomposition of <code>A</code> and <code>B</code>, returning a <a href="#LinearAlgebra.GeneralizedEigen"><code>GeneralizedEigen</code></a> factorization object <code>F</code> which contains the generalized eigenvalues in <code>F.values</code> and the generalized eigenvectors in the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th generalized eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p>Any keyword arguments passed to <code>eigen</code> are passed through to the lower-level <a href="#LinearAlgebra.eigen!"><code>eigen!</code></a> function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 0; 0 -1]
2×2 Matrix{Int64}:
 1   0
 0  -1

julia&gt; B = [0 1; 1 0]
2×2 Matrix{Int64}:
 0  1
 1  0

julia&gt; F = eigen(A, B);

julia&gt; F.values
2-element Vector{ComplexF64}:
 0.0 - 1.0im
 0.0 + 1.0im

julia&gt; F.vectors
2×2 Matrix{ComplexF64}:
  0.0+1.0im   0.0-1.0im
 -1.0+0.0im  -1.0-0.0im

julia&gt; vals, vecs = F; # destructuring via iteration

julia&gt; vals == F.values &amp;&amp; vecs == F.vectors
true</code></pre></div></section><section><div><pre><code class="language-none">eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -&gt; Eigen</code></pre><p>Computes the eigenvalue decomposition of <code>A</code>, returning an <a href="#LinearAlgebra.Eigen"><code>Eigen</code></a> factorization object <code>F</code> which contains the eigenvalues in <code>F.values</code> and the eigenvectors in the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p>The following functions are available for <code>Eigen</code> objects: <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, and <a href="#LinearAlgebra.isposdef"><code>isposdef</code></a>.</p><p>The <a href="../../base/collections/#Base.UnitRange"><code>UnitRange</code></a> <code>irange</code> specifies indices of the sorted eigenvalues to search for.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If <code>irange</code> is not <code>1:n</code>, where <code>n</code> is the dimension of <code>A</code>, then the returned factorization will be a <em>truncated</em> factorization.</p></div></div></div></section><section><div><pre><code class="language-none">eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -&gt; Eigen</code></pre><p>Computes the eigenvalue decomposition of <code>A</code>, returning an <a href="#LinearAlgebra.Eigen"><code>Eigen</code></a> factorization object <code>F</code> which contains the eigenvalues in <code>F.values</code> and the eigenvectors in the columns of the matrix <code>F.vectors</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F.vectors[:, k]</code>.)</p><p>Iterating the decomposition produces the components <code>F.values</code> and <code>F.vectors</code>.</p><p>The following functions are available for <code>Eigen</code> objects: <a href="../../base/math/#Base.inv-Tuple{Number}"><code>inv</code></a>, <a href="#LinearAlgebra.det"><code>det</code></a>, and <a href="#LinearAlgebra.isposdef"><code>isposdef</code></a>.</p><p><code>vl</code> is the lower bound of the window of eigenvalues to search for, and <code>vu</code> is the upper bound.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If [<code>vl</code>, <code>vu</code>] does not contain all eigenvalues of <code>A</code>, then the returned factorization will be a <em>truncated</em> factorization.</p></div></div></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigen!" href="#LinearAlgebra.eigen!"><code>LinearAlgebra.eigen!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">eigen!(A, [B]; permute, scale, sortby)</code></pre><p>Same as <a href="#LinearAlgebra.eigen"><code>eigen</code></a>, but saves space by overwriting the input <code>A</code> (and <code>B</code>), instead of creating a copy.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Hessenberg" href="#LinearAlgebra.Hessenberg"><code>LinearAlgebra.Hessenberg</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Hessenberg &lt;: Factorization</code></pre><p>A <code>Hessenberg</code> object represents the Hessenberg factorization <code>QHQ&#39;</code> of a square matrix, or a shift <code>Q(H+μI)Q&#39;</code> thereof, which is produced by the <a href="#LinearAlgebra.hessenberg"><code>hessenberg</code></a> function.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.hessenberg" href="#LinearAlgebra.hessenberg"><code>LinearAlgebra.hessenberg</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hessenberg(A) -&gt; Hessenberg</code></pre><p>Compute the Hessenberg decomposition of <code>A</code> and return a <code>Hessenberg</code> object. If <code>F</code> is the factorization object, the unitary matrix can be accessed with <code>F.Q</code> (of type <code>LinearAlgebra.HessenbergQ</code>) and the Hessenberg matrix with <code>F.H</code> (of type <a href="#LinearAlgebra.UpperHessenberg"><code>UpperHessenberg</code></a>), either of which may be converted to a regular matrix with <code>Matrix(F.H)</code> or <code>Matrix(F.Q)</code>.</p><p>If <code>A</code> is <a href="#LinearAlgebra.Hermitian"><code>Hermitian</code></a> or real-<a href="#LinearAlgebra.Symmetric"><code>Symmetric</code></a>, then the Hessenberg decomposition produces a real-symmetric tridiagonal matrix and <code>F.H</code> is of type <a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a>.</p><p>Note that the shifted factorization <code>A+μI = Q (H+μI) Q&#39;</code> can be constructed efficiently by <code>F + μ*I</code> using the <a href="#LinearAlgebra.UniformScaling"><code>UniformScaling</code></a> object <a href="#LinearAlgebra.I"><code>I</code></a>, which creates a new <code>Hessenberg</code> object with shared storage and a modified shift.   The shift of a given <code>F</code> is obtained by <code>F.μ</code>. This is useful because multiple shifted solves <code>(F + μ*I) \ b</code> (for different <code>μ</code> and/or <code>b</code>) can be performed efficiently once <code>F</code> is created.</p><p>Iterating the decomposition produces the factors <code>F.Q, F.H, F.μ</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4. 9. 7.; 4. 4. 1.; 4. 3. 2.]
3×3 Matrix{Float64}:
 4.0  9.0  7.0
 4.0  4.0  1.0
 4.0  3.0  2.0

julia&gt; F = hessenberg(A)
Hessenberg{Float64, UpperHessenberg{Float64, Matrix{Float64}}, Matrix{Float64}, Vector{Float64}, Bool}
Q factor:
3×3 LinearAlgebra.HessenbergQ{Float64, Matrix{Float64}, Vector{Float64}, false}:
 1.0   0.0        0.0
 0.0  -0.707107  -0.707107
 0.0  -0.707107   0.707107
H factor:
3×3 UpperHessenberg{Float64, Matrix{Float64}}:
  4.0      -11.3137       -1.41421
 -5.65685    5.0           2.0
   ⋅        -8.88178e-16   1.0

julia&gt; F.Q * F.H * F.Q&#39;
3×3 Matrix{Float64}:
 4.0  9.0  7.0
 4.0  4.0  1.0
 4.0  3.0  2.0

julia&gt; q, h = F; # destructuring via iteration

julia&gt; q == F.Q &amp;&amp; h == F.H
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.hessenberg!" href="#LinearAlgebra.hessenberg!"><code>LinearAlgebra.hessenberg!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hessenberg!(A) -&gt; Hessenberg</code></pre><p><code>hessenberg!</code> is the same as <a href="#LinearAlgebra.hessenberg"><code>hessenberg</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Schur" href="#LinearAlgebra.Schur"><code>LinearAlgebra.Schur</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Schur &lt;: Factorization</code></pre><p>Matrix factorization type of the Schur factorization of a matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.schur"><code>schur(_)</code></a>, the corresponding matrix factorization function.</p><p>If <code>F::Schur</code> is the factorization object, the (quasi) triangular Schur factor can be obtained via either <code>F.Schur</code> or <code>F.T</code> and the orthogonal/unitary Schur vectors via <code>F.vectors</code> or <code>F.Z</code> such that <code>A = F.vectors * F.Schur * F.vectors&#39;</code>. The eigenvalues of <code>A</code> can be obtained with <code>F.values</code>.</p><p>Iterating the decomposition produces the components <code>F.T</code>, <code>F.Z</code>, and <code>F.values</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [5. 7.; -2. -4.]
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; F = schur(A)
Schur{Float64, Matrix{Float64}}
T factor:
2×2 Matrix{Float64}:
 3.0   9.0
 0.0  -2.0
Z factor:
2×2 Matrix{Float64}:
  0.961524  0.274721
 -0.274721  0.961524
eigenvalues:
2-element Vector{Float64}:
  3.0
 -2.0

julia&gt; F.vectors * F.Schur * F.vectors&#39;
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; t, z, vals = F; # destructuring via iteration

julia&gt; t == F.T &amp;&amp; z == F.Z &amp;&amp; vals == F.values
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.GeneralizedSchur" href="#LinearAlgebra.GeneralizedSchur"><code>LinearAlgebra.GeneralizedSchur</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GeneralizedSchur &lt;: Factorization</code></pre><p>Matrix factorization type of the generalized Schur factorization of two matrices <code>A</code> and <code>B</code>. This is the return type of <a href="#LinearAlgebra.schur"><code>schur(_, _)</code></a>, the corresponding matrix factorization function.</p><p>If <code>F::GeneralizedSchur</code> is the factorization object, the (quasi) triangular Schur factors can be obtained via <code>F.S</code> and <code>F.T</code>, the left unitary/orthogonal Schur vectors via <code>F.left</code> or <code>F.Q</code>, and the right unitary/orthogonal Schur vectors can be obtained with <code>F.right</code> or <code>F.Z</code> such that <code>A=F.left*F.S*F.right&#39;</code> and <code>B=F.left*F.T*F.right&#39;</code>. The generalized eigenvalues of <code>A</code> and <code>B</code> can be obtained with <code>F.α./F.β</code>.</p><p>Iterating the decomposition produces the components <code>F.S</code>, <code>F.T</code>, <code>F.Q</code>, <code>F.Z</code>, <code>F.α</code>, and <code>F.β</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.schur" href="#LinearAlgebra.schur"><code>LinearAlgebra.schur</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">schur(A::StridedMatrix) -&gt; F::Schur</code></pre><p>Computes the Schur factorization of the matrix <code>A</code>. The (quasi) triangular Schur factor can be obtained from the <code>Schur</code> object <code>F</code> with either <code>F.Schur</code> or <code>F.T</code> and the orthogonal/unitary Schur vectors can be obtained with <code>F.vectors</code> or <code>F.Z</code> such that <code>A = F.vectors * F.Schur * F.vectors&#39;</code>. The eigenvalues of <code>A</code> can be obtained with <code>F.values</code>.</p><p>Iterating the decomposition produces the components <code>F.T</code>, <code>F.Z</code>, and <code>F.values</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [5. 7.; -2. -4.]
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; F = schur(A)
Schur{Float64, Matrix{Float64}}
T factor:
2×2 Matrix{Float64}:
 3.0   9.0
 0.0  -2.0
Z factor:
2×2 Matrix{Float64}:
  0.961524  0.274721
 -0.274721  0.961524
eigenvalues:
2-element Vector{Float64}:
  3.0
 -2.0

julia&gt; F.vectors * F.Schur * F.vectors&#39;
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; t, z, vals = F; # destructuring via iteration

julia&gt; t == F.T &amp;&amp; z == F.Z &amp;&amp; vals == F.values
true</code></pre></div></section><section><div><pre><code class="language-none">schur(A::StridedMatrix, B::StridedMatrix) -&gt; F::GeneralizedSchur</code></pre><p>Computes the Generalized Schur (or QZ) factorization of the matrices <code>A</code> and <code>B</code>. The (quasi) triangular Schur factors can be obtained from the <code>Schur</code> object <code>F</code> with <code>F.S</code> and <code>F.T</code>, the left unitary/orthogonal Schur vectors can be obtained with <code>F.left</code> or <code>F.Q</code> and the right unitary/orthogonal Schur vectors can be obtained with <code>F.right</code> or <code>F.Z</code> such that <code>A=F.left*F.S*F.right&#39;</code> and <code>B=F.left*F.T*F.right&#39;</code>. The generalized eigenvalues of <code>A</code> and <code>B</code> can be obtained with <code>F.α./F.β</code>.</p><p>Iterating the decomposition produces the components <code>F.S</code>, <code>F.T</code>, <code>F.Q</code>, <code>F.Z</code>, <code>F.α</code>, and <code>F.β</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.schur!" href="#LinearAlgebra.schur!"><code>LinearAlgebra.schur!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">schur!(A::StridedMatrix) -&gt; F::Schur</code></pre><p>Same as <a href="#LinearAlgebra.schur"><code>schur</code></a> but uses the input argument <code>A</code> as workspace.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [5. 7.; -2. -4.]
2×2 Matrix{Float64}:
  5.0   7.0
 -2.0  -4.0

julia&gt; F = schur!(A)
Schur{Float64, Matrix{Float64}}
T factor:
2×2 Matrix{Float64}:
 3.0   9.0
 0.0  -2.0
Z factor:
2×2 Matrix{Float64}:
  0.961524  0.274721
 -0.274721  0.961524
eigenvalues:
2-element Vector{Float64}:
  3.0
 -2.0

julia&gt; A
2×2 Matrix{Float64}:
 3.0   9.0
 0.0  -2.0</code></pre></div></section><section><div><pre><code class="language-none">schur!(A::StridedMatrix, B::StridedMatrix) -&gt; F::GeneralizedSchur</code></pre><p>Same as <a href="#LinearAlgebra.schur"><code>schur</code></a> but uses the input matrices <code>A</code> and <code>B</code> as workspace.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ordschur" href="#LinearAlgebra.ordschur"><code>LinearAlgebra.ordschur</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ordschur(F::Schur, select::Union{Vector{Bool},BitVector}) -&gt; F::Schur</code></pre><p>Reorders the Schur factorization <code>F</code> of a matrix <code>A = Z*T*Z&#39;</code> according to the logical array <code>select</code> returning the reordered factorization <code>F</code> object. The selected eigenvalues appear in the leading diagonal of <code>F.Schur</code> and the corresponding leading columns of <code>F.vectors</code> form an orthogonal/unitary basis of the corresponding right invariant subspace. In the real case, a complex conjugate pair of eigenvalues must be either both included or both excluded via <code>select</code>.</p></div></section><section><div><pre><code class="language-none">ordschur(F::GeneralizedSchur, select::Union{Vector{Bool},BitVector}) -&gt; F::GeneralizedSchur</code></pre><p>Reorders the Generalized Schur factorization <code>F</code> of a matrix pair <code>(A, B) = (Q*S*Z&#39;, Q*T*Z&#39;)</code> according to the logical array <code>select</code> and returns a GeneralizedSchur object <code>F</code>. The selected eigenvalues appear in the leading diagonal of both <code>F.S</code> and <code>F.T</code>, and the left and right orthogonal/unitary Schur vectors are also reordered such that <code>(A, B) = F.Q*(F.S, F.T)*F.Z&#39;</code> still holds and the generalized eigenvalues of <code>A</code> and <code>B</code> can still be obtained with <code>F.α./F.β</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ordschur!" href="#LinearAlgebra.ordschur!"><code>LinearAlgebra.ordschur!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ordschur!(F::Schur, select::Union{Vector{Bool},BitVector}) -&gt; F::Schur</code></pre><p>Same as <a href="#LinearAlgebra.ordschur"><code>ordschur</code></a> but overwrites the factorization <code>F</code>.</p></div></section><section><div><pre><code class="language-none">ordschur!(F::GeneralizedSchur, select::Union{Vector{Bool},BitVector}) -&gt; F::GeneralizedSchur</code></pre><p>Same as <code>ordschur</code> but overwrites the factorization <code>F</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.SVD" href="#LinearAlgebra.SVD"><code>LinearAlgebra.SVD</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SVD &lt;: Factorization</code></pre><p>Matrix factorization type of the singular value decomposition (SVD) of a matrix <code>A</code>. This is the return type of <a href="#LinearAlgebra.svd"><code>svd(_)</code></a>, the corresponding matrix factorization function.</p><p>If <code>F::SVD</code> is the factorization object, <code>U</code>, <code>S</code>, <code>V</code> and <code>Vt</code> can be obtained via <code>F.U</code>, <code>F.S</code>, <code>F.V</code> and <code>F.Vt</code>, such that <code>A = U * Diagonal(S) * Vt</code>. The singular values in <code>S</code> are sorted in descending order.</p><p>Iterating the decomposition produces the components <code>U</code>, <code>S</code>, and <code>V</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 0. 0. 0. 2.; 0. 0. 3. 0. 0.; 0. 0. 0. 0. 0.; 0. 2. 0. 0. 0.]
4×5 Matrix{Float64}:
 1.0  0.0  0.0  0.0  2.0
 0.0  0.0  3.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  2.0  0.0  0.0  0.0

julia&gt; F = svd(A)
SVD{Float64, Float64, Matrix{Float64}}
U factor:
4×4 Matrix{Float64}:
 0.0  1.0  0.0   0.0
 1.0  0.0  0.0   0.0
 0.0  0.0  0.0  -1.0
 0.0  0.0  1.0   0.0
singular values:
4-element Vector{Float64}:
 3.0
 2.23606797749979
 2.0
 0.0
Vt factor:
4×5 Matrix{Float64}:
 -0.0       0.0  1.0  -0.0  0.0
  0.447214  0.0  0.0   0.0  0.894427
 -0.0       1.0  0.0  -0.0  0.0
  0.0       0.0  0.0   1.0  0.0

julia&gt; F.U * Diagonal(F.S) * F.Vt
4×5 Matrix{Float64}:
 1.0  0.0  0.0  0.0  2.0
 0.0  0.0  3.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  2.0  0.0  0.0  0.0

julia&gt; u, s, v = F; # destructuring via iteration

julia&gt; u == F.U &amp;&amp; s == F.S &amp;&amp; v == F.V
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.GeneralizedSVD" href="#LinearAlgebra.GeneralizedSVD"><code>LinearAlgebra.GeneralizedSVD</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GeneralizedSVD &lt;: Factorization</code></pre><p>Matrix factorization type of the generalized singular value decomposition (SVD) of two matrices <code>A</code> and <code>B</code>, such that <code>A = F.U*F.D1*F.R0*F.Q&#39;</code> and <code>B = F.V*F.D2*F.R0*F.Q&#39;</code>. This is the return type of <a href="#LinearAlgebra.svd"><code>svd(_, _)</code></a>, the corresponding matrix factorization function.</p><p>For an M-by-N matrix <code>A</code> and P-by-N matrix <code>B</code>,</p><ul><li><code>U</code> is a M-by-M orthogonal matrix,</li><li><code>V</code> is a P-by-P orthogonal matrix,</li><li><code>Q</code> is a N-by-N orthogonal matrix,</li><li><code>D1</code> is a M-by-(K+L) diagonal matrix with 1s in the first K entries,</li><li><code>D2</code> is a P-by-(K+L) matrix whose top right L-by-L block is diagonal,</li><li><code>R0</code> is a (K+L)-by-N matrix whose rightmost (K+L)-by-(K+L) block is          nonsingular upper block triangular,</li></ul><p><code>K+L</code> is the effective numerical rank of the matrix <code>[A; B]</code>.</p><p>Iterating the decomposition produces the components <code>U</code>, <code>V</code>, <code>Q</code>, <code>D1</code>, <code>D2</code>, and <code>R0</code>.</p><p>The entries of <code>F.D1</code> and <code>F.D2</code> are related, as explained in the LAPACK documentation for the <a href="http://www.netlib.org/lapack/lug/node36.html">generalized SVD</a> and the <a href="http://www.netlib.org/lapack/explore-html/d6/db3/dggsvd3_8f.html">xGGSVD3</a> routine which is called underneath (in LAPACK 3.6.0 and newer).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 0.; 0. -1.]
2×2 Matrix{Float64}:
 1.0   0.0
 0.0  -1.0

julia&gt; B = [0. 1.; 1. 0.]
2×2 Matrix{Float64}:
 0.0  1.0
 1.0  0.0

julia&gt; F = svd(A, B)
GeneralizedSVD{Float64, Matrix{Float64}}
U factor:
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0
V factor:
2×2 Matrix{Float64}:
 -0.0  -1.0
  1.0   0.0
Q factor:
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0
D1 factor:
2×2 SparseArrays.SparseMatrixCSC{Float64, Int64} with 2 stored entries:
 0.707107   ⋅
  ⋅        0.707107
D2 factor:
2×2 SparseArrays.SparseMatrixCSC{Float64, Int64} with 2 stored entries:
 0.707107   ⋅
  ⋅        0.707107
R0 factor:
2×2 Matrix{Float64}:
 1.41421   0.0
 0.0      -1.41421

julia&gt; F.U*F.D1*F.R0*F.Q&#39;
2×2 Matrix{Float64}:
 1.0   0.0
 0.0  -1.0

julia&gt; F.V*F.D2*F.R0*F.Q&#39;
2×2 Matrix{Float64}:
 0.0  1.0
 1.0  0.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svd" href="#LinearAlgebra.svd"><code>LinearAlgebra.svd</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">svd(A; full::Bool = false, alg::Algorithm = default_svd_alg(A)) -&gt; SVD</code></pre><p>Compute the singular value decomposition (SVD) of <code>A</code> and return an <code>SVD</code> object.</p><p><code>U</code>, <code>S</code>, <code>V</code> and <code>Vt</code> can be obtained from the factorization <code>F</code> with <code>F.U</code>, <code>F.S</code>, <code>F.V</code> and <code>F.Vt</code>, such that <code>A = U * Diagonal(S) * Vt</code>. The algorithm produces <code>Vt</code> and hence <code>Vt</code> is more efficient to extract than <code>V</code>. The singular values in <code>S</code> are sorted in descending order.</p><p>Iterating the decomposition produces the components <code>U</code>, <code>S</code>, and <code>V</code>.</p><p>If <code>full = false</code> (default), a &quot;thin&quot; SVD is returned. For a <span>$M \times N$</span> matrix <code>A</code>, in the full factorization <code>U</code> is <code>M \times M</code> and <code>V</code> is <code>N \times N</code>, while in the thin factorization <code>U</code> is <code>M \times K</code> and <code>V</code> is <code>N \times K</code>, where <code>K = \min(M,N)</code> is the number of singular values.</p><p>If <code>alg = DivideAndConquer()</code> a divide-and-conquer algorithm is used to calculate the SVD. Another (typically slower but more accurate) option is <code>alg = QRIteration()</code>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.3</header><div class="admonition-body"><p>The <code>alg</code> keyword argument requires Julia 1.3 or later.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = rand(4,3);

julia&gt; F = svd(A); # Store the Factorization Object

julia&gt; A ≈ F.U * Diagonal(F.S) * F.Vt
true

julia&gt; U, S, V = F; # destructuring via iteration

julia&gt; A ≈ U * Diagonal(S) * V&#39;
true

julia&gt; Uonly, = svd(A); # Store U only

julia&gt; Uonly == U
true</code></pre></div></section><section><div><pre><code class="language-none">svd(A, B) -&gt; GeneralizedSVD</code></pre><p>Compute the generalized SVD of <code>A</code> and <code>B</code>, returning a <code>GeneralizedSVD</code> factorization object <code>F</code> such that <code>[A;B] = [F.U * F.D1; F.V * F.D2] * F.R0 * F.Q&#39;</code></p><ul><li><code>U</code> is a M-by-M orthogonal matrix,</li><li><code>V</code> is a P-by-P orthogonal matrix,</li><li><code>Q</code> is a N-by-N orthogonal matrix,</li><li><code>D1</code> is a M-by-(K+L) diagonal matrix with 1s in the first K entries,</li><li><code>D2</code> is a P-by-(K+L) matrix whose top right L-by-L block is diagonal,</li><li><code>R0</code> is a (K+L)-by-N matrix whose rightmost (K+L)-by-(K+L) block is          nonsingular upper block triangular,</li></ul><p><code>K+L</code> is the effective numerical rank of the matrix <code>[A; B]</code>.</p><p>Iterating the decomposition produces the components <code>U</code>, <code>V</code>, <code>Q</code>, <code>D1</code>, <code>D2</code>, and <code>R0</code>.</p><p>The generalized SVD is used in applications such as when one wants to compare how much belongs to <code>A</code> vs. how much belongs to <code>B</code>, as in human vs yeast genome, or signal vs noise, or between clusters vs within clusters. (See Edelman and Wang for discussion: https://arxiv.org/abs/1901.00485)</p><p>It decomposes <code>[A; B]</code> into <code>[UC; VS]H</code>, where <code>[UC; VS]</code> is a natural orthogonal basis for the column space of <code>[A; B]</code>, and <code>H = RQ&#39;</code> is a natural non-orthogonal basis for the rowspace of <code>[A;B]</code>, where the top rows are most closely attributed to the <code>A</code> matrix, and the bottom to the <code>B</code> matrix. The multi-cosine/sine matrices <code>C</code> and <code>S</code> provide a multi-measure of how much <code>A</code> vs how much <code>B</code>, and <code>U</code> and <code>V</code> provide directions in which these are measured.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = randn(3,2); B=randn(4,2);

julia&gt; F = svd(A, B);

julia&gt; U,V,Q,C,S,R = F;

julia&gt; H = R*Q&#39;;

julia&gt; [A; B] ≈ [U*C; V*S]*H
true

julia&gt; [A; B] ≈ [F.U*F.D1; F.V*F.D2]*F.R0*F.Q&#39;
true

julia&gt; Uonly, = svd(A,B);

julia&gt; U == Uonly
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svd!" href="#LinearAlgebra.svd!"><code>LinearAlgebra.svd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">svd!(A; full::Bool = false, alg::Algorithm = default_svd_alg(A)) -&gt; SVD</code></pre><p><code>svd!</code> is the same as <a href="#LinearAlgebra.svd"><code>svd</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. See documentation of <a href="#LinearAlgebra.svd"><code>svd</code></a> for details.</p></div></section><section><div><pre><code class="language-none">svd!(A, B) -&gt; GeneralizedSVD</code></pre><p><code>svd!</code> is the same as <a href="#LinearAlgebra.svd"><code>svd</code></a>, but modifies the arguments <code>A</code> and <code>B</code> in-place, instead of making copies. See documentation of <a href="#LinearAlgebra.svd"><code>svd</code></a> for details.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svdvals" href="#LinearAlgebra.svdvals"><code>LinearAlgebra.svdvals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">svdvals(A)</code></pre><p>Return the singular values of <code>A</code> in descending order.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 0. 0. 0. 2.; 0. 0. 3. 0. 0.; 0. 0. 0. 0. 0.; 0. 2. 0. 0. 0.]
4×5 Matrix{Float64}:
 1.0  0.0  0.0  0.0  2.0
 0.0  0.0  3.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  2.0  0.0  0.0  0.0

julia&gt; svdvals(A)
4-element Vector{Float64}:
 3.0
 2.23606797749979
 2.0
 0.0</code></pre></div></section><section><div><pre><code class="language-none">svdvals(A, B)</code></pre><p>Return the generalized singular values from the generalized singular value decomposition of <code>A</code> and <code>B</code>. See also <a href="#LinearAlgebra.svd"><code>svd</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 0.; 0. -1.]
2×2 Matrix{Float64}:
 1.0   0.0
 0.0  -1.0

julia&gt; B = [0. 1.; 1. 0.]
2×2 Matrix{Float64}:
 0.0  1.0
 1.0  0.0

julia&gt; svdvals(A, B)
2-element Vector{Float64}:
 1.0
 1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svdvals!" href="#LinearAlgebra.svdvals!"><code>LinearAlgebra.svdvals!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">svdvals!(A)</code></pre><p>Return the singular values of <code>A</code>, saving space by overwriting the input. See also <a href="#LinearAlgebra.svdvals"><code>svdvals</code></a> and <a href="#LinearAlgebra.svd"><code>svd</code></a>. ```</p></div></section><section><div><pre><code class="language-none">svdvals!(A, B)</code></pre><p>Return the generalized singular values from the generalized singular value decomposition of <code>A</code> and <code>B</code>, saving space by overwriting <code>A</code> and <code>B</code>. See also <a href="#LinearAlgebra.svd"><code>svd</code></a> and <a href="#LinearAlgebra.svdvals"><code>svdvals</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Givens" href="#LinearAlgebra.Givens"><code>LinearAlgebra.Givens</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearAlgebra.Givens(i1,i2,c,s) -&gt; G</code></pre><p>A Givens rotation linear operator. The fields <code>c</code> and <code>s</code> represent the cosine and sine of the rotation angle, respectively. The <code>Givens</code> type supports left multiplication <code>G*A</code> and conjugated transpose right multiplication <code>A*G&#39;</code>. The type doesn&#39;t have a <code>size</code> and can therefore be multiplied with matrices of arbitrary size as long as <code>i2&lt;=size(A,2)</code> for <code>G*A</code> or <code>i2&lt;=size(A,1)</code> for <code>A*G&#39;</code>.</p><p>See also: <a href="#LinearAlgebra.givens"><code>givens</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.givens" href="#LinearAlgebra.givens"><code>LinearAlgebra.givens</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">givens(f::T, g::T, i1::Integer, i2::Integer) where {T} -&gt; (G::Givens, r::T)</code></pre><p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that for any vector <code>x</code> where</p><pre><code class="language-none">x[i1] = f
x[i2] = g</code></pre><p>the result of the multiplication</p><pre><code class="language-none">y = G*x</code></pre><p>has the property that</p><pre><code class="language-none">y[i1] = r
y[i2] = 0</code></pre><p>See also: <a href="#LinearAlgebra.Givens"><code>LinearAlgebra.Givens</code></a></p></div></section><section><div><pre><code class="language-none">givens(A::AbstractArray, i1::Integer, i2::Integer, j::Integer) -&gt; (G::Givens, r)</code></pre><p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that the result of the multiplication</p><pre><code class="language-none">B = G*A</code></pre><p>has the property that</p><pre><code class="language-none">B[i1,j] = r
B[i2,j] = 0</code></pre><p>See also: <a href="#LinearAlgebra.Givens"><code>LinearAlgebra.Givens</code></a></p></div></section><section><div><pre><code class="language-none">givens(x::AbstractVector, i1::Integer, i2::Integer) -&gt; (G::Givens, r)</code></pre><p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that the result of the multiplication</p><pre><code class="language-none">B = G*x</code></pre><p>has the property that</p><pre><code class="language-none">B[i1] = r
B[i2] = 0</code></pre><p>See also: <a href="#LinearAlgebra.Givens"><code>LinearAlgebra.Givens</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.triu" href="#LinearAlgebra.triu"><code>LinearAlgebra.triu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">triu(M)</code></pre><p>Upper triangle of a matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = fill(1.0, (4,4))
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0

julia&gt; triu(a)
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 0.0  1.0  1.0  1.0
 0.0  0.0  1.0  1.0
 0.0  0.0  0.0  1.0</code></pre></div></section><section><div><pre><code class="language-none">triu(M, k::Integer)</code></pre><p>Returns the upper triangle of <code>M</code> starting from the <code>k</code>th superdiagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = fill(1.0, (4,4))
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0

julia&gt; triu(a,3)
4×4 Matrix{Float64}:
 0.0  0.0  0.0  1.0
 0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0

julia&gt; triu(a,-3)
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.triu!" href="#LinearAlgebra.triu!"><code>LinearAlgebra.triu!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">triu!(M)</code></pre><p>Upper triangle of a matrix, overwriting <code>M</code> in the process. See also <a href="#LinearAlgebra.triu"><code>triu</code></a>.</p></div></section><section><div><pre><code class="language-none">triu!(M, k::Integer)</code></pre><p>Return the upper triangle of <code>M</code> starting from the <code>k</code>th superdiagonal, overwriting <code>M</code> in the process.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5]
5×5 Matrix{Int64}:
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5

julia&gt; triu!(M, 1)
5×5 Matrix{Int64}:
 0  2  3  4  5
 0  0  3  4  5
 0  0  0  4  5
 0  0  0  0  5
 0  0  0  0  0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.tril" href="#LinearAlgebra.tril"><code>LinearAlgebra.tril</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tril(M)</code></pre><p>Lower triangle of a matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = fill(1.0, (4,4))
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0

julia&gt; tril(a)
4×4 Matrix{Float64}:
 1.0  0.0  0.0  0.0
 1.0  1.0  0.0  0.0
 1.0  1.0  1.0  0.0
 1.0  1.0  1.0  1.0</code></pre></div></section><section><div><pre><code class="language-none">tril(M, k::Integer)</code></pre><p>Returns the lower triangle of <code>M</code> starting from the <code>k</code>th superdiagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = fill(1.0, (4,4))
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0

julia&gt; tril(a,3)
4×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0
 1.0  1.0  1.0  1.0

julia&gt; tril(a,-3)
4×4 Matrix{Float64}:
 0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0
 1.0  0.0  0.0  0.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.tril!" href="#LinearAlgebra.tril!"><code>LinearAlgebra.tril!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tril!(M)</code></pre><p>Lower triangle of a matrix, overwriting <code>M</code> in the process. See also <a href="#LinearAlgebra.tril"><code>tril</code></a>.</p></div></section><section><div><pre><code class="language-none">tril!(M, k::Integer)</code></pre><p>Return the lower triangle of <code>M</code> starting from the <code>k</code>th superdiagonal, overwriting <code>M</code> in the process.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5]
5×5 Matrix{Int64}:
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5

julia&gt; tril!(M, 2)
5×5 Matrix{Int64}:
 1  2  3  0  0
 1  2  3  4  0
 1  2  3  4  5
 1  2  3  4  5
 1  2  3  4  5</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.diagind" href="#LinearAlgebra.diagind"><code>LinearAlgebra.diagind</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">diagind(M, k::Integer=0)</code></pre><p>An <code>AbstractRange</code> giving the indices of the <code>k</code>th diagonal of the matrix <code>M</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3; 4 5 6; 7 8 9]
3×3 Matrix{Int64}:
 1  2  3
 4  5  6
 7  8  9

julia&gt; diagind(A,-1)
2:4:6</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.diag" href="#LinearAlgebra.diag"><code>LinearAlgebra.diag</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">diag(M, k::Integer=0)</code></pre><p>The <code>k</code>th diagonal of a matrix, as a vector.</p><p>See also: <a href="#LinearAlgebra.diagm"><code>diagm</code></a></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2 3; 4 5 6; 7 8 9]
3×3 Matrix{Int64}:
 1  2  3
 4  5  6
 7  8  9

julia&gt; diag(A,1)
2-element Vector{Int64}:
 2
 6</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.diagm" href="#LinearAlgebra.diagm"><code>LinearAlgebra.diagm</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">diagm(kv::Pair{&lt;:Integer,&lt;:AbstractVector}...)
diagm(m::Integer, n::Integer, kv::Pair{&lt;:Integer,&lt;:AbstractVector}...)</code></pre><p>Construct a matrix from <code>Pair</code>s of diagonals and vectors. Vector <code>kv.second</code> will be placed on the <code>kv.first</code> diagonal. By default the matrix is square and its size is inferred from <code>kv</code>, but a non-square size <code>m</code>×<code>n</code> (padded with zeros as needed) can be specified by passing <code>m,n</code> as the first arguments.</p><p><code>diagm</code> constructs a full matrix; if you want storage-efficient versions with fast arithmetic, see <a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a>, <a href="#LinearAlgebra.Bidiagonal"><code>Bidiagonal</code></a> <a href="#LinearAlgebra.Tridiagonal"><code>Tridiagonal</code></a> and <a href="#LinearAlgebra.SymTridiagonal"><code>SymTridiagonal</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; diagm(1 =&gt; [1,2,3])
4×4 Matrix{Int64}:
 0  1  0  0
 0  0  2  0
 0  0  0  3
 0  0  0  0

julia&gt; diagm(1 =&gt; [1,2,3], -1 =&gt; [4,5])
4×4 Matrix{Int64}:
 0  1  0  0
 4  0  2  0
 0  5  0  3
 0  0  0  0</code></pre></div></section><section><div><pre><code class="language-none">diagm(v::AbstractVector)
diagm(m::Integer, n::Integer, v::AbstractVector)</code></pre><p>Construct a matrix with elements of the vector as diagonal elements. By default, the matrix is square and its size is given by <code>length(v)</code>, but a non-square size <code>m</code>×<code>n</code> can be specified by passing <code>m,n</code> as the first arguments.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; diagm([1,2,3])
3×3 Matrix{Int64}:
 1  0  0
 0  2  0
 0  0  3</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.rank" href="#LinearAlgebra.rank"><code>LinearAlgebra.rank</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rank(A::AbstractMatrix; atol::Real=0, rtol::Real=atol&gt;0 ? 0 : n*ϵ)
rank(A::AbstractMatrix, rtol::Real)</code></pre><p>Compute the rank of a matrix by counting how many singular values of <code>A</code> have magnitude greater than <code>max(atol, rtol*σ₁)</code> where <code>σ₁</code> is <code>A</code>&#39;s largest singular value. <code>atol</code> and <code>rtol</code> are the absolute and relative tolerances, respectively. The default relative tolerance is <code>n*ϵ</code>, where <code>n</code> is the size of the smallest dimension of <code>A</code>, and <code>ϵ</code> is the <a href="../Dates/#Base.eps"><code>eps</code></a> of the element type of <code>A</code>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.1</header><div class="admonition-body"><p>The <code>atol</code> and <code>rtol</code> keyword arguments requires at least Julia 1.1. In Julia 1.0 <code>rtol</code> is available as a positional argument, but this will be deprecated in Julia 2.0.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; rank(Matrix(I, 3, 3))
3

julia&gt; rank(diagm(0 =&gt; [1, 0, 2]))
2

julia&gt; rank(diagm(0 =&gt; [1, 0.001, 2]), rtol=0.1)
2

julia&gt; rank(diagm(0 =&gt; [1, 0.001, 2]), rtol=0.00001)
3

julia&gt; rank(diagm(0 =&gt; [1, 0.001, 2]), atol=1.5)
1</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.norm" href="#LinearAlgebra.norm"><code>LinearAlgebra.norm</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">norm(A, p::Real=2)</code></pre><p>For any iterable container <code>A</code> (including arrays of any dimension) of numbers (or any element type for which <code>norm</code> is defined), compute the <code>p</code>-norm (defaulting to <code>p=2</code>) as if <code>A</code> were a vector of the corresponding length.</p><p>The <code>p</code>-norm is defined as</p><p class="math-container">\[\|A\|_p = \left( \sum_{i=1}^n | a_i | ^p \right)^{1/p}\]</p><p>with <span>$a_i$</span> the entries of <span>$A$</span>, <span>$| a_i |$</span> the <a href="#LinearAlgebra.norm"><code>norm</code></a> of <span>$a_i$</span>, and <span>$n$</span> the length of <span>$A$</span>. Since the <code>p</code>-norm is computed using the <a href="#LinearAlgebra.norm"><code>norm</code></a>s of the entries of <code>A</code>, the <code>p</code>-norm of a vector of vectors is not compatible with the interpretation of it as a block vector in general if <code>p != 2</code>.</p><p><code>p</code> can assume any numeric value (even though not all values produce a mathematically valid vector norm). In particular, <code>norm(A, Inf)</code> returns the largest value in <code>abs.(A)</code>, whereas <code>norm(A, -Inf)</code> returns the smallest. If <code>A</code> is a matrix and <code>p=2</code>, then this is equivalent to the Frobenius norm.</p><p>The second argument <code>p</code> is not necessarily a part of the interface for <code>norm</code>, i.e. a custom type may only implement <code>norm(A)</code> without second argument.</p><p>Use <a href="#LinearAlgebra.opnorm"><code>opnorm</code></a> to compute the operator norm of a matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; v = [3, -2, 6]
3-element Vector{Int64}:
  3
 -2
  6

julia&gt; norm(v)
7.0

julia&gt; norm(v, 1)
11.0

julia&gt; norm(v, Inf)
6.0

julia&gt; norm([1 2 3; 4 5 6; 7 8 9])
16.881943016134134

julia&gt; norm([1 2 3 4 5 6 7 8 9])
16.881943016134134

julia&gt; norm(1:9)
16.881943016134134

julia&gt; norm(hcat(v,v), 1) == norm(vcat(v,v), 1) != norm([v,v], 1)
true

julia&gt; norm(hcat(v,v), 2) == norm(vcat(v,v), 2) == norm([v,v], 2)
true

julia&gt; norm(hcat(v,v), Inf) == norm(vcat(v,v), Inf) != norm([v,v], Inf)
true</code></pre></div></section><section><div><pre><code class="language-none">norm(x::Number, p::Real=2)</code></pre><p>For numbers, return <span>$\left( |x|^p \right)^{1/p}$</span>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; norm(2, 1)
2.0

julia&gt; norm(-2, 1)
2.0

julia&gt; norm(2, 2)
2.0

julia&gt; norm(-2, 2)
2.0

julia&gt; norm(2, Inf)
2.0

julia&gt; norm(-2, Inf)
2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.opnorm" href="#LinearAlgebra.opnorm"><code>LinearAlgebra.opnorm</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">opnorm(A::AbstractMatrix, p::Real=2)</code></pre><p>Compute the operator norm (or matrix norm) induced by the vector <code>p</code>-norm, where valid values of <code>p</code> are <code>1</code>, <code>2</code>, or <code>Inf</code>. (Note that for sparse matrices, <code>p=2</code> is currently not implemented.) Use <a href="#LinearAlgebra.norm"><code>norm</code></a> to compute the Frobenius norm.</p><p>When <code>p=1</code>, the operator norm is the maximum absolute column sum of <code>A</code>:</p><p class="math-container">\[\|A\|_1 = \max_{1 ≤ j ≤ n} \sum_{i=1}^m | a_{ij} |\]</p><p>with <span>$a_{ij}$</span> the entries of <span>$A$</span>, and <span>$m$</span> and <span>$n$</span> its dimensions.</p><p>When <code>p=2</code>, the operator norm is the spectral norm, equal to the largest singular value of <code>A</code>.</p><p>When <code>p=Inf</code>, the operator norm is the maximum absolute row sum of <code>A</code>:</p><p class="math-container">\[\|A\|_\infty = \max_{1 ≤ i ≤ m} \sum _{j=1}^n | a_{ij} |\]</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 -2 -3; 2 3 -1]
2×3 Matrix{Int64}:
 1  -2  -3
 2   3  -1

julia&gt; opnorm(A, Inf)
6.0

julia&gt; opnorm(A, 1)
5.0</code></pre></div></section><section><div><pre><code class="language-none">opnorm(x::Number, p::Real=2)</code></pre><p>For numbers, return <span>$\left( |x|^p \right)^{1/p}$</span>. This is equivalent to <a href="#LinearAlgebra.norm"><code>norm</code></a>.</p></div></section><section><div><pre><code class="language-none">opnorm(A::Adjoint{&lt;:Any,&lt;:AbstracVector}, q::Real=2)
opnorm(A::Transpose{&lt;:Any,&lt;:AbstracVector}, q::Real=2)</code></pre><p>For Adjoint/Transpose-wrapped vectors, return the operator <span>$q$</span>-norm of <code>A</code>, which is equivalent to the <code>p</code>-norm with value <code>p = q/(q-1)</code>. They coincide at <code>p = q = 2</code>. Use <a href="#LinearAlgebra.norm"><code>norm</code></a> to compute the <code>p</code> norm of <code>A</code> as a vector.</p><p>The difference in norm between a vector space and its dual arises to preserve the relationship between duality and the dot product, and the result is consistent with the operator <code>p</code>-norm of a <code>1 × n</code> matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; v = [1; im];

julia&gt; vc = v&#39;;

julia&gt; opnorm(vc, 1)
1.0

julia&gt; norm(vc, 1)
2.0

julia&gt; norm(v, 1)
2.0

julia&gt; opnorm(vc, 2)
1.4142135623730951

julia&gt; norm(vc, 2)
1.4142135623730951

julia&gt; norm(v, 2)
1.4142135623730951

julia&gt; opnorm(vc, Inf)
2.0

julia&gt; norm(vc, Inf)
1.0

julia&gt; norm(v, Inf)
1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.normalize!" href="#LinearAlgebra.normalize!"><code>LinearAlgebra.normalize!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">normalize!(a::AbstractArray, p::Real=2)</code></pre><p>Normalize the array <code>a</code> in-place so that its <code>p</code>-norm equals unity, i.e. <code>norm(a, p) == 1</code>. See also <a href="#LinearAlgebra.normalize"><code>normalize</code></a> and <a href="#LinearAlgebra.norm"><code>norm</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.normalize" href="#LinearAlgebra.normalize"><code>LinearAlgebra.normalize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">normalize(a::AbstractArray, p::Real=2)</code></pre><p>Normalize the array <code>a</code> so that its <code>p</code>-norm equals unity, i.e. <code>norm(a, p) == 1</code>. See also <a href="#LinearAlgebra.normalize!"><code>normalize!</code></a> and <a href="#LinearAlgebra.norm"><code>norm</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1,2,4];

julia&gt; b = normalize(a)
3-element Vector{Float64}:
 0.2182178902359924
 0.4364357804719848
 0.8728715609439696

julia&gt; norm(b)
1.0

julia&gt; c = normalize(a, 1)
3-element Vector{Float64}:
 0.14285714285714285
 0.2857142857142857
 0.5714285714285714

julia&gt; norm(c, 1)
1.0

julia&gt; a = [1 2 4 ; 1 2 4]
2×3 Matrix{Int64}:
 1  2  4
 1  2  4

julia&gt; norm(a)
6.48074069840786

julia&gt; normalize(a)
2×3 Matrix{Float64}:
 0.154303  0.308607  0.617213
 0.154303  0.308607  0.617213
</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.cond" href="#LinearAlgebra.cond"><code>LinearAlgebra.cond</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">cond(M, p::Real=2)</code></pre><p>Condition number of the matrix <code>M</code>, computed using the operator <code>p</code>-norm. Valid values for <code>p</code> are <code>1</code>, <code>2</code> (default), or <code>Inf</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.condskeel" href="#LinearAlgebra.condskeel"><code>LinearAlgebra.condskeel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">condskeel(M, [x, p::Real=Inf])</code></pre><p class="math-container">\[\kappa_S(M, p) = \left\Vert \left\vert M \right\vert \left\vert M^{-1} \right\vert \right\Vert_p \\
\kappa_S(M, x, p) = \frac{\left\Vert \left\vert M \right\vert \left\vert M^{-1} \right\vert \left\vert x \right\vert \right\Vert_p}{\left \Vert x \right \Vert_p}\]</p><p>Skeel condition number <span>$\kappa_S$</span> of the matrix <code>M</code>, optionally with respect to the vector <code>x</code>, as computed using the operator <code>p</code>-norm. <span>$\left\vert M \right\vert$</span> denotes the matrix of (entry wise) absolute values of <span>$M$</span>; <span>$\left\vert M \right\vert_{ij} = \left\vert M_{ij} \right\vert$</span>. Valid values for <code>p</code> are <code>1</code>, <code>2</code> and <code>Inf</code> (default).</p><p>This quantity is also known in the literature as the Bauer condition number, relative condition number, or componentwise relative condition number.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.tr" href="#LinearAlgebra.tr"><code>LinearAlgebra.tr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tr(M)</code></pre><p>Matrix trace. Sums the diagonal elements of <code>M</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; tr(A)
5</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.det" href="#LinearAlgebra.det"><code>LinearAlgebra.det</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">det(M)</code></pre><p>Matrix determinant.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1 0; 2 2]
2×2 Matrix{Int64}:
 1  0
 2  2

julia&gt; det(M)
2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.logdet" href="#LinearAlgebra.logdet"><code>LinearAlgebra.logdet</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">logdet(M)</code></pre><p>Log of matrix determinant. Equivalent to <code>log(det(M))</code>, but may provide increased accuracy and/or speed.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1 0; 2 2]
2×2 Matrix{Int64}:
 1  0
 2  2

julia&gt; logdet(M)
0.6931471805599453

julia&gt; logdet(Matrix(I, 3, 3))
0.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.logabsdet" href="#LinearAlgebra.logabsdet"><code>LinearAlgebra.logabsdet</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">logabsdet(M)</code></pre><p>Log of absolute value of matrix determinant. Equivalent to <code>(log(abs(det(M))), sign(det(M)))</code>, but may provide increased accuracy and/or speed.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [-1. 0.; 0. 1.]
2×2 Matrix{Float64}:
 -1.0  0.0
  0.0  1.0

julia&gt; det(A)
-1.0

julia&gt; logabsdet(A)
(0.0, -1.0)

julia&gt; B = [2. 0.; 0. 1.]
2×2 Matrix{Float64}:
 2.0  0.0
 0.0  1.0

julia&gt; det(B)
2.0

julia&gt; logabsdet(B)
(0.6931471805599453, 1.0)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.inv-Tuple{AbstractMatrix{T} where T}" href="#Base.inv-Tuple{AbstractMatrix{T} where T}"><code>Base.inv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">inv(M)</code></pre><p>Matrix inverse. Computes matrix <code>N</code> such that <code>M * N = I</code>, where <code>I</code> is the identity matrix. Computed by solving the left-division <code>N = M \ I</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [2 5; 1 3]
2×2 Matrix{Int64}:
 2  5
 1  3

julia&gt; N = inv(M)
2×2 Matrix{Float64}:
  3.0  -5.0
 -1.0   2.0

julia&gt; M*N == N*M == Matrix(I, 2, 2)
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.pinv" href="#LinearAlgebra.pinv"><code>LinearAlgebra.pinv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pinv(M; atol::Real=0, rtol::Real=atol&gt;0 ? 0 : n*ϵ)
pinv(M, rtol::Real) = pinv(M; rtol=rtol) # to be deprecated in Julia 2.0</code></pre><p>Computes the Moore-Penrose pseudoinverse.</p><p>For matrices <code>M</code> with floating point elements, it is convenient to compute the pseudoinverse by inverting only singular values greater than <code>max(atol, rtol*σ₁)</code> where <code>σ₁</code> is the largest singular value of <code>M</code>.</p><p>The optimal choice of absolute (<code>atol</code>) and relative tolerance (<code>rtol</code>) varies both with the value of <code>M</code> and the intended application of the pseudoinverse. The default relative tolerance is <code>n*ϵ</code>, where <code>n</code> is the size of the smallest dimension of <code>M</code>, and <code>ϵ</code> is the <a href="../Dates/#Base.eps"><code>eps</code></a> of the element type of <code>M</code>.</p><p>For inverting dense ill-conditioned matrices in a least-squares sense, <code>rtol = sqrt(eps(real(float(one(eltype(M))))))</code> is recommended.</p><p>For more information, see <sup class="footnote-reference"><a id="citeref-issue8859" href="#footnote-issue8859">[issue8859]</a></sup>, <sup class="footnote-reference"><a id="citeref-B96" href="#footnote-B96">[B96]</a></sup>, <sup class="footnote-reference"><a id="citeref-S84" href="#footnote-S84">[S84]</a></sup>, <sup class="footnote-reference"><a id="citeref-KY88" href="#footnote-KY88">[KY88]</a></sup>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1.5 1.3; 1.2 1.9]
2×2 Matrix{Float64}:
 1.5  1.3
 1.2  1.9

julia&gt; N = pinv(M)
2×2 Matrix{Float64}:
  1.47287   -1.00775
 -0.930233   1.16279

julia&gt; M * N
2×2 Matrix{Float64}:
 1.0          -2.22045e-16
 4.44089e-16   1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.nullspace" href="#LinearAlgebra.nullspace"><code>LinearAlgebra.nullspace</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">nullspace(M; atol::Real=0, rtol::Real=atol&gt;0 ? 0 : n*ϵ)
nullspace(M, rtol::Real) = nullspace(M; rtol=rtol) # to be deprecated in Julia 2.0</code></pre><p>Computes a basis for the nullspace of <code>M</code> by including the singular vectors of <code>M</code> whose singular values have magnitudes greater than <code>max(atol, rtol*σ₁)</code>, where <code>σ₁</code> is <code>M</code>&#39;s largest singular value.</p><p>By default, the relative tolerance <code>rtol</code> is <code>n*ϵ</code>, where <code>n</code> is the size of the smallest dimension of <code>M</code>, and <code>ϵ</code> is the <a href="../Dates/#Base.eps"><code>eps</code></a> of the element type of <code>M</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; M = [1 0 0; 0 1 0; 0 0 0]
3×3 Matrix{Int64}:
 1  0  0
 0  1  0
 0  0  0

julia&gt; nullspace(M)
3×1 Matrix{Float64}:
 0.0
 0.0
 1.0

julia&gt; nullspace(M, rtol=3)
3×3 Matrix{Float64}:
 0.0  1.0  0.0
 1.0  0.0  0.0
 0.0  0.0  1.0

julia&gt; nullspace(M, atol=0.95)
3×1 Matrix{Float64}:
 0.0
 0.0
 1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.kron" href="#Base.kron"><code>Base.kron</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kron(A, B)</code></pre><p>Kronecker tensor product of two vectors or two matrices.</p><p>For real vectors <code>v</code> and <code>w</code>, the Kronecker product is related to the outer product by <code>kron(v,w) == vec(w * transpose(v))</code> or <code>w * transpose(v) == reshape(kron(v,w), (length(w), length(v)))</code>. Note how the ordering of <code>v</code> and <code>w</code> differs on the left and right of these expressions (due to column-major storage). For complex vectors, the outer product <code>w * v&#39;</code> also differs by conjugation of <code>v</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; B = [im 1; 1 -im]
2×2 Matrix{Complex{Int64}}:
 0+1im  1+0im
 1+0im  0-1im

julia&gt; kron(A, B)
4×4 Matrix{Complex{Int64}}:
 0+1im  1+0im  0+2im  2+0im
 1+0im  0-1im  2+0im  0-2im
 0+3im  3+0im  0+4im  4+0im
 3+0im  0-3im  4+0im  0-4im

julia&gt; v = [1, 2]; w = [3, 4, 5];

julia&gt; w*transpose(v)
3×2 Matrix{Int64}:
 3   6
 4   8
 5  10

julia&gt; reshape(kron(v,w), (length(w), length(v)))
3×2 Matrix{Int64}:
 3   6
 4   8
 5  10</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.exp-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Union{Float32, Float64, ComplexF32, ComplexF64}}" href="#Base.exp-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Union{Float32, Float64, ComplexF32, ComplexF64}}"><code>Base.exp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">exp(A::AbstractMatrix)</code></pre><p>Compute the matrix exponential of <code>A</code>, defined by</p><p class="math-container">\[e^A = \sum_{n=0}^{\infty} \frac{A^n}{n!}.\]</p><p>For symmetric or Hermitian <code>A</code>, an eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used, otherwise the scaling and squaring algorithm (see <sup class="footnote-reference"><a id="citeref-H05" href="#footnote-H05">[H05]</a></sup>) is chosen.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = Matrix(1.0I, 2, 2)
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0

julia&gt; exp(A)
2×2 Matrix{Float64}:
 2.71828  0.0
 0.0      2.71828</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:^-Tuple{AbstractMatrix{T} where T, Number}" href="#Base.:^-Tuple{AbstractMatrix{T} where T, Number}"><code>Base.:^</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">^(A::AbstractMatrix, p::Number)</code></pre><p>Matrix power, equivalent to <span>$\exp(p\log(A))$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; [1 2; 0 3]^3
2×2 Matrix{Int64}:
 1  26
 0  27</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:^-Tuple{Number, AbstractMatrix{T} where T}" href="#Base.:^-Tuple{Number, AbstractMatrix{T} where T}"><code>Base.:^</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">^(b::Number, A::AbstractMatrix)</code></pre><p>Matrix exponential, equivalent to <span>$\exp(\log(b)A)$</span>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.1</header><div class="admonition-body"><p>Support for raising <code>Irrational</code> numbers (like <code>ℯ</code>) to a matrix was added in Julia 1.1.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; 2^[1 2; 0 3]
2×2 Matrix{Float64}:
 2.0  6.0
 0.0  8.0

julia&gt; ℯ^[1 2; 0 3]
2×2 Matrix{Float64}:
 2.71828  17.3673
 0.0      20.0855</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.log-Tuple{StridedMatrix{T} where T}" href="#Base.log-Tuple{StridedMatrix{T} where T}"><code>Base.log</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">log(A{T}::StridedMatrix{T})</code></pre><p>If <code>A</code> has no negative real eigenvalue, compute the principal matrix logarithm of <code>A</code>, i.e. the unique matrix <span>$X$</span> such that <span>$e^X = A$</span> and <span>$-\pi &lt; Im(\lambda) &lt; \pi$</span> for all the eigenvalues <span>$\lambda$</span> of <span>$X$</span>. If <code>A</code> has nonpositive eigenvalues, a nonprincipal matrix function is returned whenever possible.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used, if <code>A</code> is triangular an improved version of the inverse scaling and squaring method is employed (see <sup class="footnote-reference"><a id="citeref-AH12" href="#footnote-AH12">[AH12]</a></sup> and <sup class="footnote-reference"><a id="citeref-AHR13" href="#footnote-AHR13">[AHR13]</a></sup>). For general matrices, the complex Schur form (<a href="#LinearAlgebra.schur"><code>schur</code></a>) is computed and the triangular algorithm is used on the triangular factor.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = Matrix(2.7182818*I, 2, 2)
2×2 Matrix{Float64}:
 2.71828  0.0
 0.0      2.71828

julia&gt; log(A)
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sqrt-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}" href="#Base.sqrt-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}"><code>Base.sqrt</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sqrt(A::AbstractMatrix)</code></pre><p>If <code>A</code> has no negative real eigenvalues, compute the principal matrix square root of <code>A</code>, that is the unique matrix <span>$X$</span> with eigenvalues having positive real part such that <span>$X^2 = A$</span>. Otherwise, a nonprincipal square root is returned.</p><p>If <code>A</code> is real-symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the square root.   For such matrices, eigenvalues λ that appear to be slightly negative due to roundoff errors are treated as if they were zero More precisely, matrices with all eigenvalues <code>≥ -rtol*(max |λ|)</code> are treated as semidefinite (yielding a Hermitian square root), with negative eigenvalues taken to be zero. <code>rtol</code> is a keyword argument to <code>sqrt</code> (in the Hermitian/real-symmetric case only) that defaults to machine precision scaled by <code>size(A,1)</code>.</p><p>Otherwise, the square root is determined by means of the Björck-Hammarling method <sup class="footnote-reference"><a id="citeref-BH83" href="#footnote-BH83">[BH83]</a></sup>, which computes the complex Schur form (<a href="#LinearAlgebra.schur"><code>schur</code></a>) and then the complex square root of the triangular factor.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [4 0; 0 4]
2×2 Matrix{Int64}:
 4  0
 0  4

julia&gt; sqrt(A)
2×2 Matrix{Float64}:
 2.0  0.0
 0.0  2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.cos-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}" href="#Base.cos-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}"><code>Base.cos</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cos(A::AbstractMatrix)</code></pre><p>Compute the matrix cosine of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the cosine. Otherwise, the cosine is determined by calling <a href="../../base/math/#Base.exp-Tuple{Float64}"><code>exp</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; cos(fill(1.0, (2,2)))
2×2 Matrix{Float64}:
  0.291927  -0.708073
 -0.708073   0.291927</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sin-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}" href="#Base.sin-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}"><code>Base.sin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sin(A::AbstractMatrix)</code></pre><p>Compute the matrix sine of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the sine. Otherwise, the sine is determined by calling <a href="../../base/math/#Base.exp-Tuple{Float64}"><code>exp</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; sin(fill(1.0, (2,2)))
2×2 Matrix{Float64}:
 0.454649  0.454649
 0.454649  0.454649</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.sincos-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}" href="#Base.Math.sincos-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}"><code>Base.Math.sincos</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sincos(A::AbstractMatrix)</code></pre><p>Compute the matrix sine and cosine of a square matrix <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; S, C = sincos(fill(1.0, (2,2)));

julia&gt; S
2×2 Matrix{Float64}:
 0.454649  0.454649
 0.454649  0.454649

julia&gt; C
2×2 Matrix{Float64}:
  0.291927  -0.708073
 -0.708073   0.291927</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.tan-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}" href="#Base.tan-Tuple{StridedMatrix{var&quot;#s387&quot;} where var&quot;#s387&quot;&lt;:Real}"><code>Base.tan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tan(A::AbstractMatrix)</code></pre><p>Compute the matrix tangent of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the tangent. Otherwise, the tangent is determined by calling <a href="../../base/math/#Base.exp-Tuple{Float64}"><code>exp</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; tan(fill(1.0, (2,2)))
2×2 Matrix{Float64}:
 -1.09252  -1.09252
 -1.09252  -1.09252</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.sec-Tuple{StridedMatrix{T} where T}" href="#Base.Math.sec-Tuple{StridedMatrix{T} where T}"><code>Base.Math.sec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sec(A::AbstractMatrix)</code></pre><p>Compute the matrix secant of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.csc-Tuple{StridedMatrix{T} where T}" href="#Base.Math.csc-Tuple{StridedMatrix{T} where T}"><code>Base.Math.csc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">csc(A::AbstractMatrix)</code></pre><p>Compute the matrix cosecant of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.cot-Tuple{StridedMatrix{T} where T}" href="#Base.Math.cot-Tuple{StridedMatrix{T} where T}"><code>Base.Math.cot</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cot(A::AbstractMatrix)</code></pre><p>Compute the matrix cotangent of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.cosh-Tuple{StridedMatrix{T} where T}" href="#Base.cosh-Tuple{StridedMatrix{T} where T}"><code>Base.cosh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cosh(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic cosine of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sinh-Tuple{StridedMatrix{T} where T}" href="#Base.sinh-Tuple{StridedMatrix{T} where T}"><code>Base.sinh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sinh(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic sine of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.tanh-Tuple{StridedMatrix{T} where T}" href="#Base.tanh-Tuple{StridedMatrix{T} where T}"><code>Base.tanh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tanh(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic tangent of a square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.sech-Tuple{StridedMatrix{T} where T}" href="#Base.Math.sech-Tuple{StridedMatrix{T} where T}"><code>Base.Math.sech</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sech(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic secant of square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.csch-Tuple{StridedMatrix{T} where T}" href="#Base.Math.csch-Tuple{StridedMatrix{T} where T}"><code>Base.Math.csch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">csch(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic cosecant of square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.coth-Tuple{StridedMatrix{T} where T}" href="#Base.Math.coth-Tuple{StridedMatrix{T} where T}"><code>Base.Math.coth</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">coth(A::AbstractMatrix)</code></pre><p>Compute the matrix hyperbolic cotangent of square matrix <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.acos-Tuple{StridedMatrix{T} where T}" href="#Base.acos-Tuple{StridedMatrix{T} where T}"><code>Base.acos</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acos(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix cosine of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the inverse cosine. Otherwise, the inverse cosine is determined by using <a href="../../base/math/#Base.log-Tuple{Number}"><code>log</code></a> and <a href="../../base/math/#Base.sqrt-Tuple{Real}"><code>sqrt</code></a>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_1" href="#footnote-AH16_1">[AH16_1]</a></sup>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; acos(cos([0.5 0.1; -0.2 0.3]))
2×2 Matrix{ComplexF64}:
  0.5-8.32667e-17im  0.1+0.0im
 -0.2+2.63678e-16im  0.3-3.46945e-16im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.asin-Tuple{StridedMatrix{T} where T}" href="#Base.asin-Tuple{StridedMatrix{T} where T}"><code>Base.asin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">asin(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix sine of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the inverse sine. Otherwise, the inverse sine is determined by using <a href="../../base/math/#Base.log-Tuple{Number}"><code>log</code></a> and <a href="../../base/math/#Base.sqrt-Tuple{Real}"><code>sqrt</code></a>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_2" href="#footnote-AH16_2">[AH16_2]</a></sup>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; asin(sin([0.5 0.1; -0.2 0.3]))
2×2 Matrix{ComplexF64}:
  0.5-4.16334e-17im  0.1-5.55112e-17im
 -0.2+9.71445e-17im  0.3-1.249e-16im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.atan-Tuple{StridedMatrix{T} where T}" href="#Base.atan-Tuple{StridedMatrix{T} where T}"><code>Base.atan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">atan(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix tangent of a square matrix <code>A</code>.</p><p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a href="#LinearAlgebra.eigen"><code>eigen</code></a>) is used to compute the inverse tangent. Otherwise, the inverse tangent is determined by using <a href="../../base/math/#Base.log-Tuple{Number}"><code>log</code></a>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_3" href="#footnote-AH16_3">[AH16_3]</a></sup>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; atan(tan([0.5 0.1; -0.2 0.3]))
2×2 Matrix{ComplexF64}:
  0.5+1.38778e-17im  0.1-2.77556e-17im
 -0.2+6.93889e-17im  0.3-4.16334e-17im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.asec-Tuple{StridedMatrix{T} where T}" href="#Base.Math.asec-Tuple{StridedMatrix{T} where T}"><code>Base.Math.asec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">asec(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix secant of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.acsc-Tuple{StridedMatrix{T} where T}" href="#Base.Math.acsc-Tuple{StridedMatrix{T} where T}"><code>Base.Math.acsc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acsc(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix cosecant of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.acot-Tuple{StridedMatrix{T} where T}" href="#Base.Math.acot-Tuple{StridedMatrix{T} where T}"><code>Base.Math.acot</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acot(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix cotangent of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.acosh-Tuple{StridedMatrix{T} where T}" href="#Base.acosh-Tuple{StridedMatrix{T} where T}"><code>Base.acosh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acosh(A::AbstractMatrix)</code></pre><p>Compute the inverse hyperbolic matrix cosine of a square matrix <code>A</code>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_4" href="#footnote-AH16_4">[AH16_4]</a></sup>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.asinh-Tuple{StridedMatrix{T} where T}" href="#Base.asinh-Tuple{StridedMatrix{T} where T}"><code>Base.asinh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">asinh(A::AbstractMatrix)</code></pre><p>Compute the inverse hyperbolic matrix sine of a square matrix <code>A</code>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_5" href="#footnote-AH16_5">[AH16_5]</a></sup>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.atanh-Tuple{StridedMatrix{T} where T}" href="#Base.atanh-Tuple{StridedMatrix{T} where T}"><code>Base.atanh</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">atanh(A::AbstractMatrix)</code></pre><p>Compute the inverse hyperbolic matrix tangent of a square matrix <code>A</code>.  For the theory and logarithmic formulas used to compute this function, see <sup class="footnote-reference"><a id="citeref-AH16_6" href="#footnote-AH16_6">[AH16_6]</a></sup>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.asech-Tuple{StridedMatrix{T} where T}" href="#Base.Math.asech-Tuple{StridedMatrix{T} where T}"><code>Base.Math.asech</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">asech(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix hyperbolic secant of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.acsch-Tuple{StridedMatrix{T} where T}" href="#Base.Math.acsch-Tuple{StridedMatrix{T} where T}"><code>Base.Math.acsch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acsch(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix hyperbolic cosecant of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.Math.acoth-Tuple{StridedMatrix{T} where T}" href="#Base.Math.acoth-Tuple{StridedMatrix{T} where T}"><code>Base.Math.acoth</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">acoth(A::AbstractMatrix)</code></pre><p>Compute the inverse matrix hyperbolic cotangent of <code>A</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lyap" href="#LinearAlgebra.lyap"><code>LinearAlgebra.lyap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lyap(A, C)</code></pre><p>Computes the solution <code>X</code> to the continuous Lyapunov equation <code>AX + XA&#39; + C = 0</code>, where no eigenvalue of <code>A</code> has a zero real part and no two eigenvalues are negative complex conjugates of each other.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3. 4.; 5. 6]
2×2 Matrix{Float64}:
 3.0  4.0
 5.0  6.0

julia&gt; B = [1. 1.; 1. 2.]
2×2 Matrix{Float64}:
 1.0  1.0
 1.0  2.0

julia&gt; X = lyap(A, B)
2×2 Matrix{Float64}:
  0.5  -0.5
 -0.5   0.25

julia&gt; A*X + X*A&#39; + B
2×2 Matrix{Float64}:
 0.0          6.66134e-16
 6.66134e-16  8.88178e-16</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.sylvester" href="#LinearAlgebra.sylvester"><code>LinearAlgebra.sylvester</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sylvester(A, B, C)</code></pre><p>Computes the solution <code>X</code> to the Sylvester equation <code>AX + XB + C = 0</code>, where <code>A</code>, <code>B</code> and <code>C</code> have compatible dimensions and <code>A</code> and <code>-B</code> have no eigenvalues with equal real part.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3. 4.; 5. 6]
2×2 Matrix{Float64}:
 3.0  4.0
 5.0  6.0

julia&gt; B = [1. 1.; 1. 2.]
2×2 Matrix{Float64}:
 1.0  1.0
 1.0  2.0

julia&gt; C = [1. 2.; -2. 1]
2×2 Matrix{Float64}:
  1.0  2.0
 -2.0  1.0

julia&gt; X = sylvester(A, B, C)
2×2 Matrix{Float64}:
 -4.46667   1.93333
  3.73333  -1.8

julia&gt; A*X + X*B + C
2×2 Matrix{Float64}:
  2.66454e-15  1.77636e-15
 -3.77476e-15  4.44089e-16</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.issuccess" href="#LinearAlgebra.issuccess"><code>LinearAlgebra.issuccess</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">issuccess(F::Factorization)</code></pre><p>Test that a factorization of a matrix succeeded.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.6</header><div class="admonition-body"><p><code>issuccess(::CholeskyPivoted)</code> requires Julia 1.6 or later.</p></div></div><pre><code class="language-julia-repl">julia&gt; F = cholesky([1 0; 0 1]);

julia&gt; LinearAlgebra.issuccess(F)
true

julia&gt; F = lu([1 0; 0 0]; check = false);

julia&gt; LinearAlgebra.issuccess(F)
false</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.issymmetric" href="#LinearAlgebra.issymmetric"><code>LinearAlgebra.issymmetric</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">issymmetric(A) -&gt; Bool</code></pre><p>Test whether a matrix is symmetric.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1 2; 2 -1]
2×2 Matrix{Int64}:
 1   2
 2  -1

julia&gt; issymmetric(a)
true

julia&gt; b = [1 im; -im 1]
2×2 Matrix{Complex{Int64}}:
 1+0im  0+1im
 0-1im  1+0im

julia&gt; issymmetric(b)
false</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.isposdef" href="#LinearAlgebra.isposdef"><code>LinearAlgebra.isposdef</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">isposdef(A) -&gt; Bool</code></pre><p>Test whether a matrix is positive definite (and Hermitian) by trying to perform a Cholesky factorization of <code>A</code>. See also <a href="#LinearAlgebra.isposdef!"><code>isposdef!</code></a></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 2 50]
2×2 Matrix{Int64}:
 1   2
 2  50

julia&gt; isposdef(A)
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.isposdef!" href="#LinearAlgebra.isposdef!"><code>LinearAlgebra.isposdef!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">isposdef!(A) -&gt; Bool</code></pre><p>Test whether a matrix is positive definite (and Hermitian) by trying to perform a Cholesky factorization of <code>A</code>, overwriting <code>A</code> in the process. See also <a href="#LinearAlgebra.isposdef"><code>isposdef</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1. 2.; 2. 50.];

julia&gt; isposdef!(A)
true

julia&gt; A
2×2 Matrix{Float64}:
 1.0  2.0
 2.0  6.78233</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.istril" href="#LinearAlgebra.istril"><code>LinearAlgebra.istril</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">istril(A::AbstractMatrix, k::Integer = 0) -&gt; Bool</code></pre><p>Test whether <code>A</code> is lower triangular starting from the <code>k</code>th superdiagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1 2; 2 -1]
2×2 Matrix{Int64}:
 1   2
 2  -1

julia&gt; istril(a)
false

julia&gt; istril(a, 1)
true

julia&gt; b = [1 0; -im -1]
2×2 Matrix{Complex{Int64}}:
 1+0im   0+0im
 0-1im  -1+0im

julia&gt; istril(b)
true

julia&gt; istril(b, -1)
false</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.istriu" href="#LinearAlgebra.istriu"><code>LinearAlgebra.istriu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">istriu(A::AbstractMatrix, k::Integer = 0) -&gt; Bool</code></pre><p>Test whether <code>A</code> is upper triangular starting from the <code>k</code>th superdiagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1 2; 2 -1]
2×2 Matrix{Int64}:
 1   2
 2  -1

julia&gt; istriu(a)
false

julia&gt; istriu(a, -1)
true

julia&gt; b = [1 im; 0 -1]
2×2 Matrix{Complex{Int64}}:
 1+0im   0+1im
 0+0im  -1+0im

julia&gt; istriu(b)
true

julia&gt; istriu(b, 1)
false</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.isdiag" href="#LinearAlgebra.isdiag"><code>LinearAlgebra.isdiag</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">isdiag(A) -&gt; Bool</code></pre><p>Test whether a matrix is diagonal.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1 2; 2 -1]
2×2 Matrix{Int64}:
 1   2
 2  -1

julia&gt; isdiag(a)
false

julia&gt; b = [im 0; 0 -im]
2×2 Matrix{Complex{Int64}}:
 0+1im  0+0im
 0+0im  0-1im

julia&gt; isdiag(b)
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ishermitian" href="#LinearAlgebra.ishermitian"><code>LinearAlgebra.ishermitian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ishermitian(A) -&gt; Bool</code></pre><p>Test whether a matrix is Hermitian.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [1 2; 2 -1]
2×2 Matrix{Int64}:
 1   2
 2  -1

julia&gt; ishermitian(a)
true

julia&gt; b = [1 im; -im 1]
2×2 Matrix{Complex{Int64}}:
 1+0im  0+1im
 0-1im  1+0im

julia&gt; ishermitian(b)
true</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.transpose" href="#Base.transpose"><code>Base.transpose</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">transpose(A)</code></pre><p>Lazy transpose. Mutating the returned object should appropriately mutate <code>A</code>. Often, but not always, yields <code>Transpose(A)</code>, where <code>Transpose</code> is a lazy transpose wrapper. Note that this operation is recursive.</p><p>This operation is intended for linear algebra usage - for general data manipulation see <a href="../../base/arrays/#Base.permutedims"><code>permutedims</code></a>, which is non-recursive.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; transpose(A)
2×2 transpose(::Matrix{Complex{Int64}}) with eltype Complex{Int64}:
 3+2im  8+7im
 9+2im  4+6im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.transpose!" href="#LinearAlgebra.transpose!"><code>LinearAlgebra.transpose!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">transpose!(dest,src)</code></pre><p>Transpose array <code>src</code> and store the result in the preallocated array <code>dest</code>, which should have a size corresponding to <code>(size(src,2),size(src,1))</code>. No in-place transposition is supported and unexpected results will happen if <code>src</code> and <code>dest</code> have overlapping memory regions.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; B = zeros(Complex{Int64}, 2, 2)
2×2 Matrix{Complex{Int64}}:
 0+0im  0+0im
 0+0im  0+0im

julia&gt; transpose!(B, A);

julia&gt; B
2×2 Matrix{Complex{Int64}}:
 3+2im  8+7im
 9+2im  4+6im

julia&gt; A
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Transpose" href="#LinearAlgebra.Transpose"><code>LinearAlgebra.Transpose</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Transpose</code></pre><p>Lazy wrapper type for a transpose view of the underlying linear algebra object, usually an <code>AbstractVector</code>/<code>AbstractMatrix</code>, but also some <code>Factorization</code>, for instance. Usually, the <code>Transpose</code> constructor should not be called directly, use <a href="#Base.transpose"><code>transpose</code></a> instead. To materialize the view use <a href="../../base/base/#Base.copy"><code>copy</code></a>.</p><p>This type is intended for linear algebra usage - for general data manipulation see <a href="../../base/arrays/#Base.permutedims"><code>permutedims</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; transpose(A)
2×2 transpose(::Matrix{Complex{Int64}}) with eltype Complex{Int64}:
 3+2im  8+7im
 9+2im  4+6im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.adjoint" href="#Base.adjoint"><code>Base.adjoint</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">A&#39;
adjoint(A)</code></pre><p>Lazy adjoint (conjugate transposition). Note that <code>adjoint</code> is applied recursively to elements.</p><p>For number types, <code>adjoint</code> returns the complex conjugate, and therefore it is equivalent to the identity function for real numbers.</p><p>This operation is intended for linear algebra usage - for general data manipulation see <a href="../../base/arrays/#Base.permutedims"><code>permutedims</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; adjoint(A)
2×2 adjoint(::Matrix{Complex{Int64}}) with eltype Complex{Int64}:
 3-2im  8-7im
 9-2im  4-6im

julia&gt; x = [3, 4im]
2-element Vector{Complex{Int64}}:
 3 + 0im
 0 + 4im

julia&gt; x&#39;x
25 + 0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.adjoint!" href="#LinearAlgebra.adjoint!"><code>LinearAlgebra.adjoint!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">adjoint!(dest,src)</code></pre><p>Conjugate transpose array <code>src</code> and store the result in the preallocated array <code>dest</code>, which should have a size corresponding to <code>(size(src,2),size(src,1))</code>. No in-place transposition is supported and unexpected results will happen if <code>src</code> and <code>dest</code> have overlapping memory regions.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; B = zeros(Complex{Int64}, 2, 2)
2×2 Matrix{Complex{Int64}}:
 0+0im  0+0im
 0+0im  0+0im

julia&gt; adjoint!(B, A);

julia&gt; B
2×2 Matrix{Complex{Int64}}:
 3-2im  8-7im
 9-2im  4-6im

julia&gt; A
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.Adjoint" href="#LinearAlgebra.Adjoint"><code>LinearAlgebra.Adjoint</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Adjoint</code></pre><p>Lazy wrapper type for an adjoint view of the underlying linear algebra object, usually an <code>AbstractVector</code>/<code>AbstractMatrix</code>, but also some <code>Factorization</code>, for instance. Usually, the <code>Adjoint</code> constructor should not be called directly, use <a href="#Base.adjoint"><code>adjoint</code></a> instead. To materialize the view use <a href="../../base/base/#Base.copy"><code>copy</code></a>.</p><p>This type is intended for linear algebra usage - for general data manipulation see <a href="../../base/arrays/#Base.permutedims"><code>permutedims</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [3+2im 9+2im; 8+7im  4+6im]
2×2 Matrix{Complex{Int64}}:
 3+2im  9+2im
 8+7im  4+6im

julia&gt; adjoint(A)
2×2 adjoint(::Matrix{Complex{Int64}}) with eltype Complex{Int64}:
 3-2im  8-7im
 9-2im  4-6im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.copy-Tuple{Union{Adjoint, Transpose}}" href="#Base.copy-Tuple{Union{Adjoint, Transpose}}"><code>Base.copy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">copy(A::Transpose)
copy(A::Adjoint)</code></pre><p>Eagerly evaluate the lazy matrix transpose/adjoint. Note that the transposition is applied recursively to elements.</p><p>This operation is intended for linear algebra usage - for general data manipulation see <a href="../../base/arrays/#Base.permutedims"><code>permutedims</code></a>, which is non-recursive.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2im; -3im 4]
2×2 Matrix{Complex{Int64}}:
 1+0im  0+2im
 0-3im  4+0im

julia&gt; T = transpose(A)
2×2 transpose(::Matrix{Complex{Int64}}) with eltype Complex{Int64}:
 1+0im  0-3im
 0+2im  4+0im

julia&gt; copy(T)
2×2 Matrix{Complex{Int64}}:
 1+0im  0-3im
 0+2im  4+0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.stride1" href="#LinearAlgebra.stride1"><code>LinearAlgebra.stride1</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stride1(A) -&gt; Int</code></pre><p>Return the distance between successive array elements in dimension 1 in units of element size.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1,2,3,4]
4-element Vector{Int64}:
 1
 2
 3
 4

julia&gt; LinearAlgebra.stride1(A)
1

julia&gt; B = view(A, 2:2:4)
2-element view(::Vector{Int64}, 2:2:4) with eltype Int64:
 2
 4

julia&gt; LinearAlgebra.stride1(B)
2</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.checksquare" href="#LinearAlgebra.checksquare"><code>LinearAlgebra.checksquare</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">LinearAlgebra.checksquare(A)</code></pre><p>Check that a matrix is square, then return its common dimension. For multiple arguments, return a vector.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = fill(1, (4,4)); B = fill(1, (5,5));

julia&gt; LinearAlgebra.checksquare(A, B)
2-element Vector{Int64}:
 4
 5</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.peakflops" href="#LinearAlgebra.peakflops"><code>LinearAlgebra.peakflops</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">LinearAlgebra.peakflops(n::Integer=2000; parallel::Bool=false)</code></pre><p><code>peakflops</code> computes the peak flop rate of the computer by using double precision <a href="#LinearAlgebra.BLAS.gemm!"><code>gemm!</code></a>. By default, if no arguments are specified, it multiplies a matrix of size <code>n x n</code>, where <code>n = 2000</code>. If the underlying BLAS is using multiple threads, higher flop rates are realized. The number of BLAS threads can be set with <a href="#LinearAlgebra.BLAS.set_num_threads"><code>BLAS.set_num_threads(n)</code></a>.</p><p>If the keyword argument <code>parallel</code> is set to <code>true</code>, <code>peakflops</code> is run in parallel on all the worker processors. The flop rate of the entire parallel computer is returned. When running in parallel, only 1 BLAS thread is used. The argument <code>n</code> still refers to the size of the problem that is solved on each processor.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.1</header><div class="admonition-body"><p>This function requires at least Julia 1.1. In Julia 1.0 it is available from the standard library <code>InteractiveUtils</code>.</p></div></div></div></section></article><h2 id="Low-level-matrix-operations"><a class="docs-heading-anchor" href="#Low-level-matrix-operations">Low-level matrix operations</a><a id="Low-level-matrix-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Low-level-matrix-operations" title="Permalink"></a></h2><p>In many cases there are in-place versions of matrix operations that allow you to supply a pre-allocated output vector or matrix.  This is useful when optimizing critical code in order to avoid the overhead of repeated allocations. These in-place operations are suffixed with <code>!</code> below (e.g. <code>mul!</code>) according to the usual Julia convention.</p><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.mul!" href="#LinearAlgebra.mul!"><code>LinearAlgebra.mul!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mul!(Y, A, B) -&gt; Y</code></pre><p>Calculates the matrix-matrix or matrix-vector product <span>$AB$</span> and stores the result in <code>Y</code>, overwriting the existing value of <code>Y</code>. Note that <code>Y</code> must not be aliased with either <code>A</code> or <code>B</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A=[1.0 2.0; 3.0 4.0]; B=[1.0 1.0; 1.0 1.0]; Y = similar(B); mul!(Y, A, B);

julia&gt; Y
2×2 Matrix{Float64}:
 3.0  3.0
 7.0  7.0</code></pre><p><strong>Implementation</strong></p><p>For custom matrix and vector types, it is recommended to implement 5-argument <code>mul!</code> rather than implementing 3-argument <code>mul!</code> directly if possible.</p></div></section><section><div><pre><code class="language-none">mul!(C, A, B, α, β) -&gt; C</code></pre><p>Combined inplace matrix-matrix or matrix-vector multiply-add <span>$A B α + C β$</span>. The result is stored in <code>C</code> by overwriting it.  Note that <code>C</code> must not be aliased with either <code>A</code> or <code>B</code>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.3</header><div class="admonition-body"><p>Five-argument <code>mul!</code> requires at least Julia 1.3.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A=[1.0 2.0; 3.0 4.0]; B=[1.0 1.0; 1.0 1.0]; C=[1.0 2.0; 3.0 4.0];

julia&gt; mul!(C, A, B, 100.0, 10.0) === C
true

julia&gt; C
2×2 Matrix{Float64}:
 310.0  320.0
 730.0  740.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.lmul!" href="#LinearAlgebra.lmul!"><code>LinearAlgebra.lmul!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lmul!(a::Number, B::AbstractArray)</code></pre><p>Scale an array <code>B</code> by a scalar <code>a</code> overwriting <code>B</code> in-place.  Use <a href="#LinearAlgebra.rmul!"><code>rmul!</code></a> to multiply scalar from right.  The scaling operation respects the semantics of the multiplication <a href="../../base/math/#Base.:*-Tuple{Any, Vararg{Any, N} where N}"><code>*</code></a> between <code>a</code> and an element of <code>B</code>.  In particular, this also applies to multiplication involving non-finite numbers such as <code>NaN</code> and <code>±Inf</code>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.1</header><div class="admonition-body"><p>Prior to Julia 1.1, <code>NaN</code> and <code>±Inf</code> entries in <code>B</code> were treated inconsistently.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; B = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; lmul!(2, B)
2×2 Matrix{Int64}:
 2  4
 6  8

julia&gt; lmul!(0.0, [Inf])
1-element Vector{Float64}:
 NaN</code></pre></div></section><section><div><pre><code class="language-none">lmul!(A, B)</code></pre><p>Calculate the matrix-matrix product <span>$AB$</span>, overwriting <code>B</code>, and return the result. Here, <code>A</code> must be of special matrix type, like, e.g., <a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a>, <a href="#LinearAlgebra.UpperTriangular"><code>UpperTriangular</code></a> or <a href="#LinearAlgebra.LowerTriangular"><code>LowerTriangular</code></a>, or of some orthogonal type, see <a href="#LinearAlgebra.QR"><code>QR</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; B = [0 1; 1 0];

julia&gt; A = LinearAlgebra.UpperTriangular([1 2; 0 3]);

julia&gt; LinearAlgebra.lmul!(A, B);

julia&gt; B
2×2 Matrix{Int64}:
 2  1
 3  0

julia&gt; B = [1.0 2.0; 3.0 4.0];

julia&gt; F = qr([0 1; -1 0]);

julia&gt; lmul!(F.Q, B)
2×2 Matrix{Float64}:
 3.0  4.0
 1.0  2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.rmul!" href="#LinearAlgebra.rmul!"><code>LinearAlgebra.rmul!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rmul!(A::AbstractArray, b::Number)</code></pre><p>Scale an array <code>A</code> by a scalar <code>b</code> overwriting <code>A</code> in-place.  Use <a href="#LinearAlgebra.lmul!"><code>lmul!</code></a> to multiply scalar from left.  The scaling operation respects the semantics of the multiplication <a href="../../base/math/#Base.:*-Tuple{Any, Vararg{Any, N} where N}"><code>*</code></a> between an element of <code>A</code> and <code>b</code>.  In particular, this also applies to multiplication involving non-finite numbers such as <code>NaN</code> and <code>±Inf</code>.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.1</header><div class="admonition-body"><p>Prior to Julia 1.1, <code>NaN</code> and <code>±Inf</code> entries in <code>A</code> were treated inconsistently.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; rmul!(A, 2)
2×2 Matrix{Int64}:
 2  4
 6  8

julia&gt; rmul!([NaN], 0.0)
1-element Vector{Float64}:
 NaN</code></pre></div></section><section><div><pre><code class="language-none">rmul!(A, B)</code></pre><p>Calculate the matrix-matrix product <span>$AB$</span>, overwriting <code>A</code>, and return the result. Here, <code>B</code> must be of special matrix type, like, e.g., <a href="#LinearAlgebra.Diagonal"><code>Diagonal</code></a>, <a href="#LinearAlgebra.UpperTriangular"><code>UpperTriangular</code></a> or <a href="#LinearAlgebra.LowerTriangular"><code>LowerTriangular</code></a>, or of some orthogonal type, see <a href="#LinearAlgebra.QR"><code>QR</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [0 1; 1 0];

julia&gt; B = LinearAlgebra.UpperTriangular([1 2; 0 3]);

julia&gt; LinearAlgebra.rmul!(A, B);

julia&gt; A
2×2 Matrix{Int64}:
 0  3
 1  2

julia&gt; A = [1.0 2.0; 3.0 4.0];

julia&gt; F = qr([0 1; -1 0]);

julia&gt; rmul!(A, F.Q)
2×2 Matrix{Float64}:
 2.0  1.0
 4.0  3.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.ldiv!" href="#LinearAlgebra.ldiv!"><code>LinearAlgebra.ldiv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ldiv!(Y, A, B) -&gt; Y</code></pre><p>Compute <code>A \ B</code> in-place and store the result in <code>Y</code>, returning the result.</p><p>The argument <code>A</code> should <em>not</em> be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by <a href="#LinearAlgebra.factorize"><code>factorize</code></a> or <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., <a href="#LinearAlgebra.lu!"><code>lu!</code></a>), and performance-critical situations requiring <code>ldiv!</code> usually also require fine-grained control over the factorization of <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2.2 4; 3.1 0.2 3; 4 1 2];

julia&gt; X = [1; 2.5; 3];

julia&gt; Y = zero(X);

julia&gt; ldiv!(Y, qr(A), X);

julia&gt; Y
3-element Vector{Float64}:
  0.7128099173553719
 -0.051652892561983674
  0.10020661157024757

julia&gt; A\X
3-element Vector{Float64}:
  0.7128099173553719
 -0.05165289256198333
  0.10020661157024785</code></pre></div></section><section><div><pre><code class="language-none">ldiv!(A, B)</code></pre><p>Compute <code>A \ B</code> in-place and overwriting <code>B</code> to store the result.</p><p>The argument <code>A</code> should <em>not</em> be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by <a href="#LinearAlgebra.factorize"><code>factorize</code></a> or <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., <a href="#LinearAlgebra.lu!"><code>lu!</code></a>), and performance-critical situations requiring <code>ldiv!</code> usually also require fine-grained control over the factorization of <code>A</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1 2.2 4; 3.1 0.2 3; 4 1 2];

julia&gt; X = [1; 2.5; 3];

julia&gt; Y = copy(X);

julia&gt; ldiv!(qr(A), X);

julia&gt; X
3-element Vector{Float64}:
  0.7128099173553719
 -0.051652892561983674
  0.10020661157024757

julia&gt; A\Y
3-element Vector{Float64}:
  0.7128099173553719
 -0.05165289256198333
  0.10020661157024785</code></pre></div></section><section><div><pre><code class="language-none">ldiv!(a::Number, B::AbstractArray)</code></pre><p>Divide each entry in an array <code>B</code> by a scalar <code>a</code> overwriting <code>B</code> in-place.  Use <a href="#LinearAlgebra.rdiv!"><code>rdiv!</code></a> to divide scalar from right.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; B = [1.0 2.0; 3.0 4.0]
2×2 Matrix{Float64}:
 1.0  2.0
 3.0  4.0

julia&gt; ldiv!(2.0, B)
2×2 Matrix{Float64}:
 0.5  1.0
 1.5  2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.rdiv!" href="#LinearAlgebra.rdiv!"><code>LinearAlgebra.rdiv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rdiv!(A, B)</code></pre><p>Compute <code>A / B</code> in-place and overwriting <code>A</code> to store the result.</p><p>The argument <code>B</code> should <em>not</em> be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by <a href="#LinearAlgebra.factorize"><code>factorize</code></a> or <a href="#LinearAlgebra.cholesky"><code>cholesky</code></a>). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., <a href="#LinearAlgebra.lu!"><code>lu!</code></a>), and performance-critical situations requiring <code>rdiv!</code> usually also require fine-grained control over the factorization of <code>B</code>.</p></div></section><section><div><pre><code class="language-none">rdiv!(A::AbstractArray, b::Number)</code></pre><p>Divide each entry in an array <code>A</code> by a scalar <code>b</code> overwriting <code>A</code> in-place.  Use <a href="#LinearAlgebra.ldiv!"><code>ldiv!</code></a> to divide scalar from left.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = [1.0 2.0; 3.0 4.0]
2×2 Matrix{Float64}:
 1.0  2.0
 3.0  4.0

julia&gt; rdiv!(A, 2.0)
2×2 Matrix{Float64}:
 0.5  1.0
 1.5  2.0</code></pre></div></section></article><h2 id="BLAS-functions"><a class="docs-heading-anchor" href="#BLAS-functions">BLAS functions</a><a id="BLAS-functions-1"></a><a class="docs-heading-anchor-permalink" href="#BLAS-functions" title="Permalink"></a></h2><p>In Julia (as in much of scientific computation), dense linear-algebra operations are based on the <a href="http://www.netlib.org/lapack/">LAPACK library</a>, which in turn is built on top of basic linear-algebra building-blocks known as the <a href="http://www.netlib.org/blas/">BLAS</a>. There are highly optimized implementations of BLAS available for every computer architecture, and sometimes in high-performance linear algebra routines it is useful to call the BLAS functions directly.</p><p><code>LinearAlgebra.BLAS</code> provides wrappers for some of the BLAS functions. Those BLAS functions that overwrite one of the input arrays have names ending in <code>&#39;!&#39;</code>.  Usually, a BLAS function has four methods defined, for <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a>, <a href="../../base/numbers/#Core.Float32"><code>Float32</code></a>, <code>ComplexF64</code>, and <code>ComplexF32</code> arrays.</p><h3 id="stdlib-blas-chars"><a class="docs-heading-anchor" href="#stdlib-blas-chars">BLAS character arguments</a><a id="stdlib-blas-chars-1"></a><a class="docs-heading-anchor-permalink" href="#stdlib-blas-chars" title="Permalink"></a></h3><p>Many BLAS functions accept arguments that determine whether to transpose an argument (<code>trans</code>), which triangle of a matrix to reference (<code>uplo</code> or <code>ul</code>), whether the diagonal of a triangular matrix can be assumed to be all ones (<code>dA</code>) or which side of a matrix multiplication the input argument belongs on (<code>side</code>). The possibilities are:</p><h4 id="stdlib-blas-side"><a class="docs-heading-anchor" href="#stdlib-blas-side">Multiplication order</a><a id="stdlib-blas-side-1"></a><a class="docs-heading-anchor-permalink" href="#stdlib-blas-side" title="Permalink"></a></h4><table><tr><th style="text-align: left"><code>side</code></th><th style="text-align: left">Meaning</th></tr><tr><td style="text-align: left"><code>&#39;L&#39;</code></td><td style="text-align: left">The argument goes on the <em>left</em> side of a matrix-matrix operation.</td></tr><tr><td style="text-align: left"><code>&#39;R&#39;</code></td><td style="text-align: left">The argument goes on the <em>right</em> side of a matrix-matrix operation.</td></tr></table><h4 id="stdlib-blas-uplo"><a class="docs-heading-anchor" href="#stdlib-blas-uplo">Triangle referencing</a><a id="stdlib-blas-uplo-1"></a><a class="docs-heading-anchor-permalink" href="#stdlib-blas-uplo" title="Permalink"></a></h4><table><tr><th style="text-align: left"><code>uplo</code>/<code>ul</code></th><th style="text-align: left">Meaning</th></tr><tr><td style="text-align: left"><code>&#39;U&#39;</code></td><td style="text-align: left">Only the <em>upper</em> triangle of the matrix will be used.</td></tr><tr><td style="text-align: left"><code>&#39;L&#39;</code></td><td style="text-align: left">Only the <em>lower</em> triangle of the matrix will be used.</td></tr></table><h4 id="stdlib-blas-trans"><a class="docs-heading-anchor" href="#stdlib-blas-trans">Transposition operation</a><a id="stdlib-blas-trans-1"></a><a class="docs-heading-anchor-permalink" href="#stdlib-blas-trans" title="Permalink"></a></h4><table><tr><th style="text-align: left"><code>trans</code>/<code>tX</code></th><th style="text-align: left">Meaning</th></tr><tr><td style="text-align: left"><code>&#39;N&#39;</code></td><td style="text-align: left">The input matrix <code>X</code> is not transposed or conjugated.</td></tr><tr><td style="text-align: left"><code>&#39;T&#39;</code></td><td style="text-align: left">The input matrix <code>X</code> will be transposed.</td></tr><tr><td style="text-align: left"><code>&#39;C&#39;</code></td><td style="text-align: left">The input matrix <code>X</code> will be conjugated and transposed.</td></tr></table><h4 id="stdlib-blas-diag"><a class="docs-heading-anchor" href="#stdlib-blas-diag">Unit diagonal</a><a id="stdlib-blas-diag-1"></a><a class="docs-heading-anchor-permalink" href="#stdlib-blas-diag" title="Permalink"></a></h4><table><tr><th style="text-align: left"><code>diag</code>/<code>dX</code></th><th style="text-align: left">Meaning</th></tr><tr><td style="text-align: left"><code>&#39;N&#39;</code></td><td style="text-align: left">The diagonal values of the matrix <code>X</code> will be read.</td></tr><tr><td style="text-align: left"><code>&#39;U&#39;</code></td><td style="text-align: left">The diagonal of the matrix <code>X</code> is assumed to be all ones.</td></tr></table><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS" href="#LinearAlgebra.BLAS"><code>LinearAlgebra.BLAS</code></a> — <span class="docstring-category">Module</span></header><section><div><p>Interface to BLAS subroutines.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.dot" href="#LinearAlgebra.BLAS.dot"><code>LinearAlgebra.BLAS.dot</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dot(n, X, incx, Y, incy)</code></pre><p>Dot product of two vectors consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code> and <code>n</code> elements of array <code>Y</code> with stride <code>incy</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; BLAS.dot(10, fill(1.0, 10), 1, fill(1.0, 20), 2)
10.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.dotu" href="#LinearAlgebra.BLAS.dotu"><code>LinearAlgebra.BLAS.dotu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dotu(n, X, incx, Y, incy)</code></pre><p>Dot function for two complex vectors consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code> and <code>n</code> elements of array <code>Y</code> with stride <code>incy</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; BLAS.dotu(10, fill(1.0im, 10), 1, fill(1.0+im, 20), 2)
-10.0 + 10.0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.dotc" href="#LinearAlgebra.BLAS.dotc"><code>LinearAlgebra.BLAS.dotc</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dotc(n, X, incx, U, incy)</code></pre><p>Dot function for two complex vectors, consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code> and <code>n</code> elements of array <code>U</code> with stride <code>incy</code>, conjugating the first vector.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; BLAS.dotc(10, fill(1.0im, 10), 1, fill(1.0+im, 20), 2)
10.0 - 10.0im</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.blascopy!" href="#LinearAlgebra.BLAS.blascopy!"><code>LinearAlgebra.BLAS.blascopy!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">blascopy!(n, X, incx, Y, incy)</code></pre><p>Copy <code>n</code> elements of array <code>X</code> with stride <code>incx</code> to array <code>Y</code> with stride <code>incy</code>. Returns <code>Y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.nrm2" href="#LinearAlgebra.BLAS.nrm2"><code>LinearAlgebra.BLAS.nrm2</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">nrm2(n, X, incx)</code></pre><p>2-norm of a vector consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; BLAS.nrm2(4, fill(1.0, 8), 2)
2.0

julia&gt; BLAS.nrm2(1, fill(1.0, 8), 2)
1.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.asum" href="#LinearAlgebra.BLAS.asum"><code>LinearAlgebra.BLAS.asum</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">asum(n, X, incx)</code></pre><p>Sum of the magnitudes of the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p><p>For a real array, the magnitude is the absolute value. For a complex array, the magnitude is the sum of the absolute value of the real part and the absolute value of the imaginary part.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; BLAS.asum(5, fill(1.0im, 10), 2)
5.0

julia&gt; BLAS.asum(2, fill(1.0im, 10), 5)
2.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.axpy!" href="#LinearAlgebra.axpy!"><code>LinearAlgebra.axpy!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">axpy!(a, X, Y)</code></pre><p>Overwrite <code>Y</code> with <code>X*a + Y</code>, where <code>a</code> is a scalar. Return <code>Y</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; x = [1; 2; 3];

julia&gt; y = [4; 5; 6];

julia&gt; BLAS.axpy!(2, x, y)
3-element Vector{Int64}:
  6
  9
 12</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.axpby!" href="#LinearAlgebra.axpby!"><code>LinearAlgebra.axpby!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">axpby!(a, X, b, Y)</code></pre><p>Overwrite <code>Y</code> with <code>X*a + Y*b</code>, where <code>a</code> and <code>b</code> are scalars. Return <code>Y</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; x = [1., 2, 3];

julia&gt; y = [4., 5, 6];

julia&gt; BLAS.axpby!(2., x, 3., y)
3-element Vector{Float64}:
 14.0
 19.0
 24.0</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.scal!" href="#LinearAlgebra.BLAS.scal!"><code>LinearAlgebra.BLAS.scal!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scal!(n, a, X, incx)</code></pre><p>Overwrite <code>X</code> with <code>a*X</code> for the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>. Returns <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.scal" href="#LinearAlgebra.BLAS.scal"><code>LinearAlgebra.BLAS.scal</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scal(n, a, X, incx)</code></pre><p>Return <code>X</code> scaled by <code>a</code> for the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.iamax" href="#LinearAlgebra.BLAS.iamax"><code>LinearAlgebra.BLAS.iamax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">iamax(n, dx, incx)
iamax(dx)</code></pre><p>Find the index of the element of <code>dx</code> with the maximum absolute value. <code>n</code> is the length of <code>dx</code>, and <code>incx</code> is the stride. If <code>n</code> and <code>incx</code> are not provided, they assume default values of <code>n=length(dx)</code> and <code>incx=stride1(dx)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.ger!" href="#LinearAlgebra.BLAS.ger!"><code>LinearAlgebra.BLAS.ger!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ger!(alpha, x, y, A)</code></pre><p>Rank-1 update of the matrix <code>A</code> with vectors <code>x</code> and <code>y</code> as <code>alpha*x*y&#39; + A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.syr!" href="#LinearAlgebra.BLAS.syr!"><code>LinearAlgebra.BLAS.syr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syr!(uplo, alpha, x, A)</code></pre><p>Rank-1 update of the symmetric matrix <code>A</code> with vector <code>x</code> as <code>alpha*x*transpose(x) + A</code>. <a href="#stdlib-blas-uplo"><code>uplo</code></a> controls which triangle of <code>A</code> is updated. Returns <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.syrk!" href="#LinearAlgebra.BLAS.syrk!"><code>LinearAlgebra.BLAS.syrk!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syrk!(uplo, trans, alpha, A, beta, C)</code></pre><p>Rank-k update of the symmetric matrix <code>C</code> as <code>alpha*A*transpose(A) + beta*C</code> or <code>alpha*transpose(A)*A + beta*C</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>C</code> is used. Returns <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.syrk" href="#LinearAlgebra.BLAS.syrk"><code>LinearAlgebra.BLAS.syrk</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syrk(uplo, trans, alpha, A)</code></pre><p>Returns either the upper triangle or the lower triangle of <code>A</code>, according to <a href="#stdlib-blas-uplo"><code>uplo</code></a>, of <code>alpha*A*transpose(A)</code> or <code>alpha*transpose(A)*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.syr2k!" href="#LinearAlgebra.BLAS.syr2k!"><code>LinearAlgebra.BLAS.syr2k!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syr2k!(uplo, trans, alpha, A, B, beta, C)</code></pre><p>Rank-2k update of the symmetric matrix <code>C</code> as <code>alpha*A*transpose(B) + alpha*B*transpose(A) + beta*C</code> or <code>alpha*transpose(A)*B + alpha*transpose(B)*A + beta*C</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>C</code> is used. Returns <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.syr2k" href="#LinearAlgebra.BLAS.syr2k"><code>LinearAlgebra.BLAS.syr2k</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syr2k(uplo, trans, alpha, A, B)</code></pre><p>Returns the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>alpha*A*transpose(B) + alpha*B*transpose(A)</code> or <code>alpha*transpose(A)*B + alpha*transpose(B)*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section><section><div><pre><code class="language-none">syr2k(uplo, trans, A, B)</code></pre><p>Returns the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>A*transpose(B) + B*transpose(A)</code> or <code>transpose(A)*B + transpose(B)*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.her!" href="#LinearAlgebra.BLAS.her!"><code>LinearAlgebra.BLAS.her!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">her!(uplo, alpha, x, A)</code></pre><p>Methods for complex arrays only. Rank-1 update of the Hermitian matrix <code>A</code> with vector <code>x</code> as <code>alpha*x*x&#39; + A</code>. <a href="#stdlib-blas-uplo"><code>uplo</code></a> controls which triangle of <code>A</code> is updated. Returns <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.herk!" href="#LinearAlgebra.BLAS.herk!"><code>LinearAlgebra.BLAS.herk!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">herk!(uplo, trans, alpha, A, beta, C)</code></pre><p>Methods for complex arrays only. Rank-k update of the Hermitian matrix <code>C</code> as <code>alpha*A*A&#39; + beta*C</code> or <code>alpha*A&#39;*A + beta*C</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>C</code> is updated. Returns <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.herk" href="#LinearAlgebra.BLAS.herk"><code>LinearAlgebra.BLAS.herk</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">herk(uplo, trans, alpha, A)</code></pre><p>Methods for complex arrays only. Returns the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>alpha*A*A&#39;</code> or <code>alpha*A&#39;*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.her2k!" href="#LinearAlgebra.BLAS.her2k!"><code>LinearAlgebra.BLAS.her2k!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">her2k!(uplo, trans, alpha, A, B, beta, C)</code></pre><p>Rank-2k update of the Hermitian matrix <code>C</code> as <code>alpha*A*B&#39; + alpha*B*A&#39; + beta*C</code> or <code>alpha*A&#39;*B + alpha*B&#39;*A + beta*C</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. The scalar <code>beta</code> has to be real. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>C</code> is used. Returns <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.her2k" href="#LinearAlgebra.BLAS.her2k"><code>LinearAlgebra.BLAS.her2k</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">her2k(uplo, trans, alpha, A, B)</code></pre><p>Returns the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>alpha*A*B&#39; + alpha*B*A&#39;</code> or <code>alpha*A&#39;*B + alpha*B&#39;*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section><section><div><pre><code class="language-none">her2k(uplo, trans, A, B)</code></pre><p>Returns the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>A*B&#39; + B*A&#39;</code> or <code>A&#39;*B + B&#39;*A</code>, according to <a href="#stdlib-blas-trans"><code>trans</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gbmv!" href="#LinearAlgebra.BLAS.gbmv!"><code>LinearAlgebra.BLAS.gbmv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gbmv!(trans, m, kl, ku, alpha, A, x, beta, y)</code></pre><p>Update vector <code>y</code> as <code>alpha*A*x + beta*y</code> or <code>alpha*A&#39;*x + beta*y</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. The matrix <code>A</code> is a general band matrix of dimension <code>m</code> by <code>size(A,2)</code> with <code>kl</code> sub-diagonals and <code>ku</code> super-diagonals. <code>alpha</code> and <code>beta</code> are scalars. Return the updated <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gbmv" href="#LinearAlgebra.BLAS.gbmv"><code>LinearAlgebra.BLAS.gbmv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gbmv(trans, m, kl, ku, alpha, A, x)</code></pre><p>Return <code>alpha*A*x</code> or <code>alpha*A&#39;*x</code> according to <a href="#stdlib-blas-trans"><code>trans</code></a>. The matrix <code>A</code> is a general band matrix of dimension <code>m</code> by <code>size(A,2)</code> with <code>kl</code> sub-diagonals and <code>ku</code> super-diagonals, and <code>alpha</code> is a scalar.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.sbmv!" href="#LinearAlgebra.BLAS.sbmv!"><code>LinearAlgebra.BLAS.sbmv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sbmv!(uplo, k, alpha, A, x, beta, y)</code></pre><p>Update vector <code>y</code> as <code>alpha*A*x + beta*y</code> where <code>A</code> is a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>. The storage layout for <code>A</code> is described the reference BLAS module, level-2 BLAS at <a href="http://www.netlib.org/lapack/explore-html/">http://www.netlib.org/lapack/explore-html/</a>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>A</code> is used.</p><p>Return the updated <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.sbmv-NTuple{5, Any}" href="#LinearAlgebra.BLAS.sbmv-NTuple{5, Any}"><code>LinearAlgebra.BLAS.sbmv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sbmv(uplo, k, alpha, A, x)</code></pre><p>Return <code>alpha*A*x</code> where <code>A</code> is a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.sbmv-NTuple{4, Any}" href="#LinearAlgebra.BLAS.sbmv-NTuple{4, Any}"><code>LinearAlgebra.BLAS.sbmv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sbmv(uplo, k, A, x)</code></pre><p>Return <code>A*x</code> where <code>A</code> is a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>. Only the <a href="#stdlib-blas-uplo"><code>uplo</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemm!" href="#LinearAlgebra.BLAS.gemm!"><code>LinearAlgebra.BLAS.gemm!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gemm!(tA, tB, alpha, A, B, beta, C)</code></pre><p>Update <code>C</code> as <code>alpha*A*B + beta*C</code> or the other three variants according to <a href="#stdlib-blas-trans"><code>tA</code></a> and <code>tB</code>. Return the updated <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemm-NTuple{5, Any}" href="#LinearAlgebra.BLAS.gemm-NTuple{5, Any}"><code>LinearAlgebra.BLAS.gemm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gemm(tA, tB, alpha, A, B)</code></pre><p>Return <code>alpha*A*B</code> or the other three variants according to <a href="#stdlib-blas-trans"><code>tA</code></a> and <code>tB</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemm-NTuple{4, Any}" href="#LinearAlgebra.BLAS.gemm-NTuple{4, Any}"><code>LinearAlgebra.BLAS.gemm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gemm(tA, tB, A, B)</code></pre><p>Return <code>A*B</code> or the other three variants according to <a href="#stdlib-blas-trans"><code>tA</code></a> and <code>tB</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemv!" href="#LinearAlgebra.BLAS.gemv!"><code>LinearAlgebra.BLAS.gemv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gemv!(tA, alpha, A, x, beta, y)</code></pre><p>Update the vector <code>y</code> as <code>alpha*A*x + beta*y</code> or <code>alpha*A&#39;x + beta*y</code> according to <a href="#stdlib-blas-trans"><code>tA</code></a>. <code>alpha</code> and <code>beta</code> are scalars. Return the updated <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemv-NTuple{4, Any}" href="#LinearAlgebra.BLAS.gemv-NTuple{4, Any}"><code>LinearAlgebra.BLAS.gemv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gemv(tA, alpha, A, x)</code></pre><p>Return <code>alpha*A*x</code> or <code>alpha*A&#39;x</code> according to <a href="#stdlib-blas-trans"><code>tA</code></a>. <code>alpha</code> is a scalar.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.gemv-Tuple{Any, Any, Any}" href="#LinearAlgebra.BLAS.gemv-Tuple{Any, Any, Any}"><code>LinearAlgebra.BLAS.gemv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gemv(tA, A, x)</code></pre><p>Return <code>A*x</code> or <code>A&#39;x</code> according to <a href="#stdlib-blas-trans"><code>tA</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symm!" href="#LinearAlgebra.BLAS.symm!"><code>LinearAlgebra.BLAS.symm!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">symm!(side, ul, alpha, A, B, beta, C)</code></pre><p>Update <code>C</code> as <code>alpha*A*B + beta*C</code> or <code>alpha*B*A + beta*C</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. Return the updated <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symm-NTuple{5, Any}" href="#LinearAlgebra.BLAS.symm-NTuple{5, Any}"><code>LinearAlgebra.BLAS.symm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">symm(side, ul, alpha, A, B)</code></pre><p>Return <code>alpha*A*B</code> or <code>alpha*B*A</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symm-NTuple{4, Any}" href="#LinearAlgebra.BLAS.symm-NTuple{4, Any}"><code>LinearAlgebra.BLAS.symm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">symm(side, ul, A, B)</code></pre><p>Return <code>A*B</code> or <code>B*A</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symv!" href="#LinearAlgebra.BLAS.symv!"><code>LinearAlgebra.BLAS.symv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">symv!(ul, alpha, A, x, beta, y)</code></pre><p>Update the vector <code>y</code> as <code>alpha*A*x + beta*y</code>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <code>alpha</code> and <code>beta</code> are scalars. Return the updated <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symv-NTuple{4, Any}" href="#LinearAlgebra.BLAS.symv-NTuple{4, Any}"><code>LinearAlgebra.BLAS.symv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">symv(ul, alpha, A, x)</code></pre><p>Return <code>alpha*A*x</code>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <code>alpha</code> is a scalar.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.symv-Tuple{Any, Any, Any}" href="#LinearAlgebra.BLAS.symv-Tuple{Any, Any, Any}"><code>LinearAlgebra.BLAS.symv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">symv(ul, A, x)</code></pre><p>Return <code>A*x</code>. <code>A</code> is assumed to be symmetric. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemm!" href="#LinearAlgebra.BLAS.hemm!"><code>LinearAlgebra.BLAS.hemm!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hemm!(side, ul, alpha, A, B, beta, C)</code></pre><p>Update <code>C</code> as <code>alpha*A*B + beta*C</code> or <code>alpha*B*A + beta*C</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. Return the updated <code>C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemm-NTuple{5, Any}" href="#LinearAlgebra.BLAS.hemm-NTuple{5, Any}"><code>LinearAlgebra.BLAS.hemm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">hemm(side, ul, alpha, A, B)</code></pre><p>Return <code>alpha*A*B</code> or <code>alpha*B*A</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemm-NTuple{4, Any}" href="#LinearAlgebra.BLAS.hemm-NTuple{4, Any}"><code>LinearAlgebra.BLAS.hemm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">hemm(side, ul, A, B)</code></pre><p>Return <code>A*B</code> or <code>B*A</code> according to <a href="#stdlib-blas-side"><code>side</code></a>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemv!" href="#LinearAlgebra.BLAS.hemv!"><code>LinearAlgebra.BLAS.hemv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hemv!(ul, alpha, A, x, beta, y)</code></pre><p>Update the vector <code>y</code> as <code>alpha*A*x + beta*y</code>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <code>alpha</code> and <code>beta</code> are scalars. Return the updated <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemv-NTuple{4, Any}" href="#LinearAlgebra.BLAS.hemv-NTuple{4, Any}"><code>LinearAlgebra.BLAS.hemv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">hemv(ul, alpha, A, x)</code></pre><p>Return <code>alpha*A*x</code>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <code>alpha</code> is a scalar.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.hemv-Tuple{Any, Any, Any}" href="#LinearAlgebra.BLAS.hemv-Tuple{Any, Any, Any}"><code>LinearAlgebra.BLAS.hemv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">hemv(ul, A, x)</code></pre><p>Return <code>A*x</code>. <code>A</code> is assumed to be Hermitian. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trmm!" href="#LinearAlgebra.BLAS.trmm!"><code>LinearAlgebra.BLAS.trmm!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trmm!(side, ul, tA, dA, alpha, A, B)</code></pre><p>Update <code>B</code> as <code>alpha*A*B</code> or one of the other three variants determined by <a href="#stdlib-blas-side"><code>side</code></a> and <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones. Returns the updated <code>B</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trmm" href="#LinearAlgebra.BLAS.trmm"><code>LinearAlgebra.BLAS.trmm</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trmm(side, ul, tA, dA, alpha, A, B)</code></pre><p>Returns <code>alpha*A*B</code> or one of the other three variants determined by <a href="#stdlib-blas-side"><code>side</code></a> and <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trsm!" href="#LinearAlgebra.BLAS.trsm!"><code>LinearAlgebra.BLAS.trsm!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsm!(side, ul, tA, dA, alpha, A, B)</code></pre><p>Overwrite <code>B</code> with the solution to <code>A*X = alpha*B</code> or one of the other three variants determined by <a href="#stdlib-blas-side"><code>side</code></a> and <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones. Returns the updated <code>B</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trsm" href="#LinearAlgebra.BLAS.trsm"><code>LinearAlgebra.BLAS.trsm</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsm(side, ul, tA, dA, alpha, A, B)</code></pre><p>Return the solution to <code>A*X = alpha*B</code> or one of the other three variants determined by determined by <a href="#stdlib-blas-side"><code>side</code></a> and <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trmv!" href="#LinearAlgebra.BLAS.trmv!"><code>LinearAlgebra.BLAS.trmv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trmv!(ul, tA, dA, A, b)</code></pre><p>Return <code>op(A)*b</code>, where <code>op</code> is determined by <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones. The multiplication occurs in-place on <code>b</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trmv" href="#LinearAlgebra.BLAS.trmv"><code>LinearAlgebra.BLAS.trmv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trmv(ul, tA, dA, A, b)</code></pre><p>Return <code>op(A)*b</code>, where <code>op</code> is determined by <a href="#stdlib-blas-trans"><code>tA</code></a>. Only the <a href="#stdlib-blas-uplo"><code>ul</code></a> triangle of <code>A</code> is used. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trsv!" href="#LinearAlgebra.BLAS.trsv!"><code>LinearAlgebra.BLAS.trsv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsv!(ul, tA, dA, A, b)</code></pre><p>Overwrite <code>b</code> with the solution to <code>A*x = b</code> or one of the other two variants determined by <a href="#stdlib-blas-trans"><code>tA</code></a> and <a href="#stdlib-blas-uplo"><code>ul</code></a>. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones. Return the updated <code>b</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.trsv" href="#LinearAlgebra.BLAS.trsv"><code>LinearAlgebra.BLAS.trsv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsv(ul, tA, dA, A, b)</code></pre><p>Return the solution to <code>A*x = b</code> or one of the other two variants determined by <a href="#stdlib-blas-trans"><code>tA</code></a> and <a href="#stdlib-blas-uplo"><code>ul</code></a>. <a href="#stdlib-blas-diag"><code>dA</code></a> determines if the diagonal values are read or are assumed to be all ones.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.BLAS.set_num_threads" href="#LinearAlgebra.BLAS.set_num_threads"><code>LinearAlgebra.BLAS.set_num_threads</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">set_num_threads(n::Integer)
set_num_threads(::Nothing)</code></pre><p>Set the number of threads the BLAS library should use equal to <code>n::Integer</code>.</p><p>Also accepts <code>nothing</code>, in which case julia tries to guess the default number of threads. Passing <code>nothing</code> is discouraged and mainly exists for the following reason:</p><p>On exotic variants of BLAS, <code>nothing</code> may be returned by <code>get_num_threads()</code>. Thus on exotic variants of BLAS, the following pattern may fail to set the number of threads:</p><pre><code class="language-julia">old = get_num_threads()
set_num_threads(1)
@threads for i in 1:10
    # single-threaded BLAS calls
end
set_num_threads(old)</code></pre><p>Because <code>set_num_threads</code> accepts <code>nothing</code>, this code can still run on exotic variants of BLAS without error. Warnings will be raised instead.</p><div class="admonition is-compat"><header class="admonition-header">Julia 1.6</header><div class="admonition-body"><p><code>set_num_threads(::Nothing)</code> requires at least Julia 1.6.</p></div></div></div></section></article><h2 id="LAPACK-functions"><a class="docs-heading-anchor" href="#LAPACK-functions">LAPACK functions</a><a id="LAPACK-functions-1"></a><a class="docs-heading-anchor-permalink" href="#LAPACK-functions" title="Permalink"></a></h2><p><code>LinearAlgebra.LAPACK</code> provides wrappers for some of the LAPACK functions for linear algebra.  Those functions that overwrite one of the input arrays have names ending in <code>&#39;!&#39;</code>.</p><p>Usually a function has 4 methods defined, one each for <a href="../../base/numbers/#Core.Float64"><code>Float64</code></a>, <a href="../../base/numbers/#Core.Float32"><code>Float32</code></a>, <code>ComplexF64</code> and <code>ComplexF32</code> arrays.</p><p>Note that the LAPACK API provided by Julia can and will change in the future. Since this API is not user-facing, there is no commitment to support/deprecate this specific set of functions in future releases.</p><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK" href="#LinearAlgebra.LAPACK"><code>LinearAlgebra.LAPACK</code></a> — <span class="docstring-category">Module</span></header><section><div><p>Interfaces to LAPACK subroutines.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gbtrf!" href="#LinearAlgebra.LAPACK.gbtrf!"><code>LinearAlgebra.LAPACK.gbtrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gbtrf!(kl, ku, m, AB) -&gt; (AB, ipiv)</code></pre><p>Compute the LU factorization of a banded matrix <code>AB</code>. <code>kl</code> is the first subdiagonal containing a nonzero band, <code>ku</code> is the last superdiagonal containing one, and <code>m</code> is the first dimension of the matrix <code>AB</code>. Returns the LU factorization in-place and <code>ipiv</code>, the vector of pivots used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gbtrs!" href="#LinearAlgebra.LAPACK.gbtrs!"><code>LinearAlgebra.LAPACK.gbtrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gbtrs!(trans, kl, ku, m, AB, ipiv, B)</code></pre><p>Solve the equation <code>AB * X = B</code>. <code>trans</code> determines the orientation of <code>AB</code>. It may be <code>N</code> (no transpose), <code>T</code> (transpose), or <code>C</code> (conjugate transpose). <code>kl</code> is the first subdiagonal containing a nonzero band, <code>ku</code> is the last superdiagonal containing one, and <code>m</code> is the first dimension of the matrix <code>AB</code>. <code>ipiv</code> is the vector of pivots returned from <code>gbtrf!</code>. Returns the vector or matrix <code>X</code>, overwriting <code>B</code> in-place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gebal!" href="#LinearAlgebra.LAPACK.gebal!"><code>LinearAlgebra.LAPACK.gebal!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gebal!(job, A) -&gt; (ilo, ihi, scale)</code></pre><p>Balance the matrix <code>A</code> before computing its eigensystem or Schur factorization. <code>job</code> can be one of <code>N</code> (<code>A</code> will not be permuted or scaled), <code>P</code> (<code>A</code> will only be permuted), <code>S</code> (<code>A</code> will only be scaled), or <code>B</code> (<code>A</code> will be both permuted and scaled). Modifies <code>A</code> in-place and returns <code>ilo</code>, <code>ihi</code>, and <code>scale</code>. If permuting was turned on, <code>A[i,j] = 0</code> if <code>j &gt; i</code> and <code>1 &lt; j &lt; ilo</code> or <code>j &gt; ihi</code>. <code>scale</code> contains information about the scaling/permutations performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gebak!" href="#LinearAlgebra.LAPACK.gebak!"><code>LinearAlgebra.LAPACK.gebak!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gebak!(job, side, ilo, ihi, scale, V)</code></pre><p>Transform the eigenvectors <code>V</code> of a matrix balanced using <code>gebal!</code> to the unscaled/unpermuted eigenvectors of the original matrix. Modifies <code>V</code> in-place. <code>side</code> can be <code>L</code> (left eigenvectors are transformed) or <code>R</code> (right eigenvectors are transformed).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gebrd!" href="#LinearAlgebra.LAPACK.gebrd!"><code>LinearAlgebra.LAPACK.gebrd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gebrd!(A) -&gt; (A, d, e, tauq, taup)</code></pre><p>Reduce <code>A</code> in-place to bidiagonal form <code>A = QBP&#39;</code>. Returns <code>A</code>, containing the bidiagonal matrix <code>B</code>; <code>d</code>, containing the diagonal elements of <code>B</code>; <code>e</code>, containing the off-diagonal elements of <code>B</code>; <code>tauq</code>, containing the elementary reflectors representing <code>Q</code>; and <code>taup</code>, containing the elementary reflectors representing <code>P</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gelqf!" href="#LinearAlgebra.LAPACK.gelqf!"><code>LinearAlgebra.LAPACK.gelqf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gelqf!(A, tau)</code></pre><p>Compute the <code>LQ</code> factorization of <code>A</code>, <code>A = LQ</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>tau</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">gelqf!(A) -&gt; (A, tau)</code></pre><p>Compute the <code>LQ</code> factorization of <code>A</code>, <code>A = LQ</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geqlf!" href="#LinearAlgebra.LAPACK.geqlf!"><code>LinearAlgebra.LAPACK.geqlf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geqlf!(A, tau)</code></pre><p>Compute the <code>QL</code> factorization of <code>A</code>, <code>A = QL</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>tau</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">geqlf!(A) -&gt; (A, tau)</code></pre><p>Compute the <code>QL</code> factorization of <code>A</code>, <code>A = QL</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geqrf!" href="#LinearAlgebra.LAPACK.geqrf!"><code>LinearAlgebra.LAPACK.geqrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geqrf!(A, tau)</code></pre><p>Compute the <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>tau</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">geqrf!(A) -&gt; (A, tau)</code></pre><p>Compute the <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geqp3!" href="#LinearAlgebra.LAPACK.geqp3!"><code>LinearAlgebra.LAPACK.geqp3!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geqp3!(A, [jpvt, tau]) -&gt; (A, tau, jpvt)</code></pre><p>Compute the pivoted <code>QR</code> factorization of <code>A</code>, <code>AP = QR</code> using BLAS level 3. <code>P</code> is a pivoting matrix, represented by <code>jpvt</code>. <code>tau</code> stores the elementary reflectors. The arguments <code>jpvt</code> and <code>tau</code> are optional and allow for passing preallocated arrays. When passed, <code>jpvt</code> must have length greater than or equal to <code>n</code> if <code>A</code> is an <code>(m x n)</code> matrix and <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p><p><code>A</code>, <code>jpvt</code>, and <code>tau</code> are modified in-place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gerqf!" href="#LinearAlgebra.LAPACK.gerqf!"><code>LinearAlgebra.LAPACK.gerqf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gerqf!(A, tau)</code></pre><p>Compute the <code>RQ</code> factorization of <code>A</code>, <code>A = RQ</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>tau</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">gerqf!(A) -&gt; (A, tau)</code></pre><p>Compute the <code>RQ</code> factorization of <code>A</code>, <code>A = RQ</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geqrt!" href="#LinearAlgebra.LAPACK.geqrt!"><code>LinearAlgebra.LAPACK.geqrt!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geqrt!(A, T)</code></pre><p>Compute the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>T</code> contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization. The first dimension of <code>T</code> sets the block size and it must be between 1 and <code>n</code>. The second dimension of <code>T</code> must equal the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>T</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">geqrt!(A, nb) -&gt; (A, T)</code></pre><p>Compute the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>nb</code> sets the block size and it must be between 1 and <code>n</code>, the second dimension of <code>A</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>T</code>, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geqrt3!" href="#LinearAlgebra.LAPACK.geqrt3!"><code>LinearAlgebra.LAPACK.geqrt3!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geqrt3!(A, T)</code></pre><p>Recursively computes the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>T</code> contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.  The first dimension of <code>T</code> sets the block size and it must be between 1 and <code>n</code>. The second dimension of <code>T</code> must equal the smallest dimension of <code>A</code>.</p><p>Returns <code>A</code> and <code>T</code> modified in-place.</p></div></section><section><div><pre><code class="language-none">geqrt3!(A) -&gt; (A, T)</code></pre><p>Recursively computes the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>.</p><p>Returns <code>A</code>, modified in-place, and <code>T</code>, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.getrf!" href="#LinearAlgebra.LAPACK.getrf!"><code>LinearAlgebra.LAPACK.getrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">getrf!(A) -&gt; (A, ipiv, info)</code></pre><p>Compute the pivoted <code>LU</code> factorization of <code>A</code>, <code>A = LU</code>.</p><p>Returns <code>A</code>, modified in-place, <code>ipiv</code>, the pivoting information, and an <code>info</code> code which indicates success (<code>info = 0</code>), a singular value in <code>U</code> (<code>info = i</code>, in which case <code>U[i,i]</code> is singular), or an error code (<code>info &lt; 0</code>).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.tzrzf!" href="#LinearAlgebra.LAPACK.tzrzf!"><code>LinearAlgebra.LAPACK.tzrzf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tzrzf!(A) -&gt; (A, tau)</code></pre><p>Transforms the upper trapezoidal matrix <code>A</code> to upper triangular form in-place. Returns <code>A</code> and <code>tau</code>, the scalar parameters for the elementary reflectors of the transformation.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ormrz!" href="#LinearAlgebra.LAPACK.ormrz!"><code>LinearAlgebra.LAPACK.ormrz!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ormrz!(side, trans, A, tau, C)</code></pre><p>Multiplies the matrix <code>C</code> by <code>Q</code> from the transformation supplied by <code>tzrzf!</code>. Depending on <code>side</code> or <code>trans</code> the multiplication can be left-sided (<code>side = L, Q*C</code>) or right-sided (<code>side = R, C*Q</code>) and <code>Q</code> can be unmodified (<code>trans = N</code>), transposed (<code>trans = T</code>), or conjugate transposed (<code>trans = C</code>). Returns matrix <code>C</code> which is modified in-place with the result of the multiplication.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gels!" href="#LinearAlgebra.LAPACK.gels!"><code>LinearAlgebra.LAPACK.gels!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gels!(trans, A, B) -&gt; (F, B, ssr)</code></pre><p>Solves the linear equation <code>A * X = B</code>, <code>transpose(A) * X = B</code>, or <code>adjoint(A) * X = B</code> using a QR or LQ factorization. Modifies the matrix/vector <code>B</code> in place with the solution. <code>A</code> is overwritten with its <code>QR</code> or <code>LQ</code> factorization. <code>trans</code> may be one of <code>N</code> (no modification), <code>T</code> (transpose), or <code>C</code> (conjugate transpose). <code>gels!</code> searches for the minimum norm/least squares solution. <code>A</code> may be under or over determined. The solution is returned in <code>B</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gesv!" href="#LinearAlgebra.LAPACK.gesv!"><code>LinearAlgebra.LAPACK.gesv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gesv!(A, B) -&gt; (B, A, ipiv)</code></pre><p>Solves the linear equation <code>A * X = B</code> where <code>A</code> is a square matrix using the <code>LU</code> factorization of <code>A</code>. <code>A</code> is overwritten with its <code>LU</code> factorization and <code>B</code> is overwritten with the solution <code>X</code>. <code>ipiv</code> contains the pivoting information for the <code>LU</code> factorization of <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.getrs!" href="#LinearAlgebra.LAPACK.getrs!"><code>LinearAlgebra.LAPACK.getrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">getrs!(trans, A, ipiv, B)</code></pre><p>Solves the linear equation <code>A * X = B</code>, <code>transpose(A) * X = B</code>, or <code>adjoint(A) * X = B</code> for square <code>A</code>. Modifies the matrix/vector <code>B</code> in place with the solution. <code>A</code> is the <code>LU</code> factorization from <code>getrf!</code>, with <code>ipiv</code> the pivoting information. <code>trans</code> may be one of <code>N</code> (no modification), <code>T</code> (transpose), or <code>C</code> (conjugate transpose).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.getri!" href="#LinearAlgebra.LAPACK.getri!"><code>LinearAlgebra.LAPACK.getri!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">getri!(A, ipiv)</code></pre><p>Computes the inverse of <code>A</code>, using its <code>LU</code> factorization found by <code>getrf!</code>. <code>ipiv</code> is the pivot information output and <code>A</code> contains the <code>LU</code> factorization of <code>getrf!</code>. <code>A</code> is overwritten with its inverse.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gesvx!" href="#LinearAlgebra.LAPACK.gesvx!"><code>LinearAlgebra.LAPACK.gesvx!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gesvx!(fact, trans, A, AF, ipiv, equed, R, C, B) -&gt; (X, equed, R, C, B, rcond, ferr, berr, work)</code></pre><p>Solves the linear equation <code>A * X = B</code> (<code>trans = N</code>), <code>transpose(A) * X = B</code> (<code>trans = T</code>), or <code>adjoint(A) * X = B</code> (<code>trans = C</code>) using the <code>LU</code> factorization of <code>A</code>. <code>fact</code> may be <code>E</code>, in which case <code>A</code> will be equilibrated and copied to <code>AF</code>; <code>F</code>, in which case <code>AF</code> and <code>ipiv</code> from a previous <code>LU</code> factorization are inputs; or <code>N</code>, in which case <code>A</code> will be copied to <code>AF</code> and then factored. If <code>fact = F</code>, <code>equed</code> may be <code>N</code>, meaning <code>A</code> has not been equilibrated; <code>R</code>, meaning <code>A</code> was multiplied by <code>Diagonal(R)</code> from the left; <code>C</code>, meaning <code>A</code> was multiplied by <code>Diagonal(C)</code> from the right; or <code>B</code>, meaning <code>A</code> was multiplied by <code>Diagonal(R)</code> from the left and <code>Diagonal(C)</code> from the right. If <code>fact = F</code> and <code>equed = R</code> or <code>B</code> the elements of <code>R</code> must all be positive. If <code>fact = F</code> and <code>equed = C</code> or <code>B</code> the elements of <code>C</code> must all be positive.</p><p>Returns the solution <code>X</code>; <code>equed</code>, which is an output if <code>fact</code> is not <code>N</code>, and describes the equilibration that was performed; <code>R</code>, the row equilibration diagonal; <code>C</code>, the column equilibration diagonal; <code>B</code>, which may be overwritten with its equilibrated form <code>Diagonal(R)*B</code> (if <code>trans = N</code> and <code>equed = R,B</code>) or <code>Diagonal(C)*B</code> (if <code>trans = T,C</code> and <code>equed = C,B</code>); <code>rcond</code>, the reciprocal condition number of <code>A</code> after equilbrating; <code>ferr</code>, the forward error bound for each solution vector in <code>X</code>; <code>berr</code>, the forward error bound for each solution vector in <code>X</code>; and <code>work</code>, the reciprocal pivot growth factor.</p></div></section><section><div><pre><code class="language-none">gesvx!(A, B)</code></pre><p>The no-equilibration, no-transpose simplification of <code>gesvx!</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gelsd!" href="#LinearAlgebra.LAPACK.gelsd!"><code>LinearAlgebra.LAPACK.gelsd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gelsd!(A, B, rcond) -&gt; (B, rnk)</code></pre><p>Computes the least norm solution of <code>A * X = B</code> by finding the <code>SVD</code> factorization of <code>A</code>, then dividing-and-conquering the problem. <code>B</code> is overwritten with the solution <code>X</code>. Singular values below <code>rcond</code> will be treated as zero. Returns the solution in <code>B</code> and the effective rank of <code>A</code> in <code>rnk</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gelsy!" href="#LinearAlgebra.LAPACK.gelsy!"><code>LinearAlgebra.LAPACK.gelsy!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gelsy!(A, B, rcond) -&gt; (B, rnk)</code></pre><p>Computes the least norm solution of <code>A * X = B</code> by finding the full <code>QR</code> factorization of <code>A</code>, then dividing-and-conquering the problem. <code>B</code> is overwritten with the solution <code>X</code>. Singular values below <code>rcond</code> will be treated as zero. Returns the solution in <code>B</code> and the effective rank of <code>A</code> in <code>rnk</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gglse!" href="#LinearAlgebra.LAPACK.gglse!"><code>LinearAlgebra.LAPACK.gglse!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gglse!(A, c, B, d) -&gt; (X,res)</code></pre><p>Solves the equation <code>A * x = c</code> where <code>x</code> is subject to the equality constraint <code>B * x = d</code>. Uses the formula <code>||c - A*x||^2 = 0</code> to solve. Returns <code>X</code> and the residual sum-of-squares.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geev!" href="#LinearAlgebra.LAPACK.geev!"><code>LinearAlgebra.LAPACK.geev!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geev!(jobvl, jobvr, A) -&gt; (W, VL, VR)</code></pre><p>Finds the eigensystem of <code>A</code>. If <code>jobvl = N</code>, the left eigenvectors of <code>A</code> aren&#39;t computed. If <code>jobvr = N</code>, the right eigenvectors of <code>A</code> aren&#39;t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed. Returns the eigenvalues in <code>W</code>, the right eigenvectors in <code>VR</code>, and the left eigenvectors in <code>VL</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gesdd!" href="#LinearAlgebra.LAPACK.gesdd!"><code>LinearAlgebra.LAPACK.gesdd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gesdd!(job, A) -&gt; (U, S, VT)</code></pre><p>Finds the singular value decomposition of <code>A</code>, <code>A = U * S * V&#39;</code>, using a divide and conquer approach. If <code>job = A</code>, all the columns of <code>U</code> and the rows of <code>V&#39;</code> are computed. If <code>job = N</code>, no columns of <code>U</code> or rows of <code>V&#39;</code> are computed. If <code>job = O</code>, <code>A</code> is overwritten with the columns of (thin) <code>U</code> and the rows of (thin) <code>V&#39;</code>. If <code>job = S</code>, the columns of (thin) <code>U</code> and the rows of (thin) <code>V&#39;</code> are computed and returned separately.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gesvd!" href="#LinearAlgebra.LAPACK.gesvd!"><code>LinearAlgebra.LAPACK.gesvd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gesvd!(jobu, jobvt, A) -&gt; (U, S, VT)</code></pre><p>Finds the singular value decomposition of <code>A</code>, <code>A = U * S * V&#39;</code>. If <code>jobu = A</code>, all the columns of <code>U</code> are computed. If <code>jobvt = A</code> all the rows of <code>V&#39;</code> are computed. If <code>jobu = N</code>, no columns of <code>U</code> are computed. If <code>jobvt = N</code> no rows of <code>V&#39;</code> are computed. If <code>jobu = O</code>, <code>A</code> is overwritten with the columns of (thin) <code>U</code>. If <code>jobvt = O</code>, <code>A</code> is overwritten with the rows of (thin) <code>V&#39;</code>. If <code>jobu = S</code>, the columns of (thin) <code>U</code> are computed and returned separately. If <code>jobvt = S</code> the rows of (thin) <code>V&#39;</code> are computed and returned separately. <code>jobu</code> and <code>jobvt</code> can&#39;t both be <code>O</code>.</p><p>Returns <code>U</code>, <code>S</code>, and <code>Vt</code>, where <code>S</code> are the singular values of <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ggsvd!" href="#LinearAlgebra.LAPACK.ggsvd!"><code>LinearAlgebra.LAPACK.ggsvd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ggsvd!(jobu, jobv, jobq, A, B) -&gt; (U, V, Q, alpha, beta, k, l, R)</code></pre><p>Finds the generalized singular value decomposition of <code>A</code> and <code>B</code>, <code>U&#39;*A*Q = D1*R</code> and <code>V&#39;*B*Q = D2*R</code>. <code>D1</code> has <code>alpha</code> on its diagonal and <code>D2</code> has <code>beta</code> on its diagonal. If <code>jobu = U</code>, the orthogonal/unitary matrix <code>U</code> is computed. If <code>jobv = V</code> the orthogonal/unitary matrix <code>V</code> is computed. If <code>jobq = Q</code>, the orthogonal/unitary matrix <code>Q</code> is computed. If <code>jobu</code>, <code>jobv</code> or <code>jobq</code> is <code>N</code>, that matrix is not computed. This function is only available in LAPACK versions prior to 3.6.0.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ggsvd3!" href="#LinearAlgebra.LAPACK.ggsvd3!"><code>LinearAlgebra.LAPACK.ggsvd3!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ggsvd3!(jobu, jobv, jobq, A, B) -&gt; (U, V, Q, alpha, beta, k, l, R)</code></pre><p>Finds the generalized singular value decomposition of <code>A</code> and <code>B</code>, <code>U&#39;*A*Q = D1*R</code> and <code>V&#39;*B*Q = D2*R</code>. <code>D1</code> has <code>alpha</code> on its diagonal and <code>D2</code> has <code>beta</code> on its diagonal. If <code>jobu = U</code>, the orthogonal/unitary matrix <code>U</code> is computed. If <code>jobv = V</code> the orthogonal/unitary matrix <code>V</code> is computed. If <code>jobq = Q</code>, the orthogonal/unitary matrix <code>Q</code> is computed. If <code>jobu</code>, <code>jobv</code>, or <code>jobq</code> is <code>N</code>, that matrix is not computed. This function requires LAPACK 3.6.0.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.geevx!" href="#LinearAlgebra.LAPACK.geevx!"><code>LinearAlgebra.LAPACK.geevx!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">geevx!(balanc, jobvl, jobvr, sense, A) -&gt; (A, w, VL, VR, ilo, ihi, scale, abnrm, rconde, rcondv)</code></pre><p>Finds the eigensystem of <code>A</code> with matrix balancing. If <code>jobvl = N</code>, the left eigenvectors of <code>A</code> aren&#39;t computed. If <code>jobvr = N</code>, the right eigenvectors of <code>A</code> aren&#39;t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed. If <code>balanc = N</code>, no balancing is performed. If <code>balanc = P</code>, <code>A</code> is permuted but not scaled. If <code>balanc = S</code>, <code>A</code> is scaled but not permuted. If <code>balanc = B</code>, <code>A</code> is permuted and scaled. If <code>sense = N</code>, no reciprocal condition numbers are computed. If <code>sense = E</code>, reciprocal condition numbers are computed for the eigenvalues only. If <code>sense = V</code>, reciprocal condition numbers are computed for the right eigenvectors only. If <code>sense = B</code>, reciprocal condition numbers are computed for the right eigenvectors and the eigenvectors. If <code>sense = E,B</code>, the right and left eigenvectors must be computed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ggev!" href="#LinearAlgebra.LAPACK.ggev!"><code>LinearAlgebra.LAPACK.ggev!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ggev!(jobvl, jobvr, A, B) -&gt; (alpha, beta, vl, vr)</code></pre><p>Finds the generalized eigendecomposition of <code>A</code> and <code>B</code>. If <code>jobvl = N</code>, the left eigenvectors aren&#39;t computed. If <code>jobvr = N</code>, the right eigenvectors aren&#39;t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gtsv!" href="#LinearAlgebra.LAPACK.gtsv!"><code>LinearAlgebra.LAPACK.gtsv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gtsv!(dl, d, du, B)</code></pre><p>Solves the equation <code>A * X = B</code> where <code>A</code> is a tridiagonal matrix with <code>dl</code> on the subdiagonal, <code>d</code> on the diagonal, and <code>du</code> on the superdiagonal.</p><p>Overwrites <code>B</code> with the solution <code>X</code> and returns it.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gttrf!" href="#LinearAlgebra.LAPACK.gttrf!"><code>LinearAlgebra.LAPACK.gttrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gttrf!(dl, d, du) -&gt; (dl, d, du, du2, ipiv)</code></pre><p>Finds the <code>LU</code> factorization of a tridiagonal matrix with <code>dl</code> on the subdiagonal, <code>d</code> on the diagonal, and <code>du</code> on the superdiagonal.</p><p>Modifies <code>dl</code>, <code>d</code>, and <code>du</code> in-place and returns them and the second superdiagonal <code>du2</code> and the pivoting vector <code>ipiv</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gttrs!" href="#LinearAlgebra.LAPACK.gttrs!"><code>LinearAlgebra.LAPACK.gttrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gttrs!(trans, dl, d, du, du2, ipiv, B)</code></pre><p>Solves the equation <code>A * X = B</code> (<code>trans = N</code>), <code>transpose(A) * X = B</code> (<code>trans = T</code>), or <code>adjoint(A) * X = B</code> (<code>trans = C</code>) using the <code>LU</code> factorization computed by <code>gttrf!</code>. <code>B</code> is overwritten with the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.orglq!" href="#LinearAlgebra.LAPACK.orglq!"><code>LinearAlgebra.LAPACK.orglq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orglq!(A, tau, k = length(tau))</code></pre><p>Explicitly finds the matrix <code>Q</code> of a <code>LQ</code> factorization after calling <code>gelqf!</code> on <code>A</code>. Uses the output of <code>gelqf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.orgqr!" href="#LinearAlgebra.LAPACK.orgqr!"><code>LinearAlgebra.LAPACK.orgqr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orgqr!(A, tau, k = length(tau))</code></pre><p>Explicitly finds the matrix <code>Q</code> of a <code>QR</code> factorization after calling <code>geqrf!</code> on <code>A</code>. Uses the output of <code>geqrf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.orgql!" href="#LinearAlgebra.LAPACK.orgql!"><code>LinearAlgebra.LAPACK.orgql!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orgql!(A, tau, k = length(tau))</code></pre><p>Explicitly finds the matrix <code>Q</code> of a <code>QL</code> factorization after calling <code>geqlf!</code> on <code>A</code>. Uses the output of <code>geqlf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.orgrq!" href="#LinearAlgebra.LAPACK.orgrq!"><code>LinearAlgebra.LAPACK.orgrq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orgrq!(A, tau, k = length(tau))</code></pre><p>Explicitly finds the matrix <code>Q</code> of a <code>RQ</code> factorization after calling <code>gerqf!</code> on <code>A</code>. Uses the output of <code>gerqf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ormlq!" href="#LinearAlgebra.LAPACK.ormlq!"><code>LinearAlgebra.LAPACK.ormlq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ormlq!(side, trans, A, tau, C)</code></pre><p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>transpose(Q) * C</code> (<code>trans = T</code>), <code>adjoint(Q) * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>LQ</code> factorization of <code>A</code> computed using <code>gelqf!</code>. <code>C</code> is overwritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ormqr!" href="#LinearAlgebra.LAPACK.ormqr!"><code>LinearAlgebra.LAPACK.ormqr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ormqr!(side, trans, A, tau, C)</code></pre><p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>transpose(Q) * C</code> (<code>trans = T</code>), <code>adjoint(Q) * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QR</code> factorization of <code>A</code> computed using <code>geqrf!</code>. <code>C</code> is overwritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ormql!" href="#LinearAlgebra.LAPACK.ormql!"><code>LinearAlgebra.LAPACK.ormql!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ormql!(side, trans, A, tau, C)</code></pre><p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>transpose(Q) * C</code> (<code>trans = T</code>), <code>adjoint(Q) * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QL</code> factorization of <code>A</code> computed using <code>geqlf!</code>. <code>C</code> is overwritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ormrq!" href="#LinearAlgebra.LAPACK.ormrq!"><code>LinearAlgebra.LAPACK.ormrq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ormrq!(side, trans, A, tau, C)</code></pre><p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>transpose(Q) * C</code> (<code>trans = T</code>), <code>adjoint(Q) * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>RQ</code> factorization of <code>A</code> computed using <code>gerqf!</code>. <code>C</code> is overwritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gemqrt!" href="#LinearAlgebra.LAPACK.gemqrt!"><code>LinearAlgebra.LAPACK.gemqrt!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gemqrt!(side, trans, V, T, C)</code></pre><p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>transpose(Q) * C</code> (<code>trans = T</code>), <code>adjoint(Q) * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QR</code> factorization of <code>A</code> computed using <code>geqrt!</code>. <code>C</code> is overwritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.posv!" href="#LinearAlgebra.LAPACK.posv!"><code>LinearAlgebra.LAPACK.posv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">posv!(uplo, A, B) -&gt; (A, B)</code></pre><p>Finds the solution to <code>A * X = B</code> where <code>A</code> is a symmetric or Hermitian positive definite matrix. If <code>uplo = U</code> the upper Cholesky decomposition of <code>A</code> is computed. If <code>uplo = L</code> the lower Cholesky decomposition of <code>A</code> is computed. <code>A</code> is overwritten by its Cholesky decomposition. <code>B</code> is overwritten with the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.potrf!" href="#LinearAlgebra.LAPACK.potrf!"><code>LinearAlgebra.LAPACK.potrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">potrf!(uplo, A)</code></pre><p>Computes the Cholesky (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) decomposition of positive-definite matrix <code>A</code>. <code>A</code> is overwritten and returned with an info code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.potri!" href="#LinearAlgebra.LAPACK.potri!"><code>LinearAlgebra.LAPACK.potri!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">potri!(uplo, A)</code></pre><p>Computes the inverse of positive-definite matrix <code>A</code> after calling <code>potrf!</code> to find its (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) Cholesky decomposition.</p><p><code>A</code> is overwritten by its inverse and returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.potrs!" href="#LinearAlgebra.LAPACK.potrs!"><code>LinearAlgebra.LAPACK.potrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">potrs!(uplo, A, B)</code></pre><p>Finds the solution to <code>A * X = B</code> where <code>A</code> is a symmetric or Hermitian positive definite matrix whose Cholesky decomposition was computed by <code>potrf!</code>. If <code>uplo = U</code> the upper Cholesky decomposition of <code>A</code> was computed. If <code>uplo = L</code> the lower Cholesky decomposition of <code>A</code> was computed. <code>B</code> is overwritten with the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.pstrf!" href="#LinearAlgebra.LAPACK.pstrf!"><code>LinearAlgebra.LAPACK.pstrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pstrf!(uplo, A, tol) -&gt; (A, piv, rank, info)</code></pre><p>Computes the (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) pivoted Cholesky decomposition of positive-definite matrix <code>A</code> with a user-set tolerance <code>tol</code>. <code>A</code> is overwritten by its Cholesky decomposition.</p><p>Returns <code>A</code>, the pivots <code>piv</code>, the rank of <code>A</code>, and an <code>info</code> code. If <code>info = 0</code>, the factorization succeeded. If <code>info = i &gt; 0</code>, then <code>A</code> is indefinite or rank-deficient.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.ptsv!" href="#LinearAlgebra.LAPACK.ptsv!"><code>LinearAlgebra.LAPACK.ptsv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ptsv!(D, E, B)</code></pre><p>Solves <code>A * X = B</code> for positive-definite tridiagonal <code>A</code>. <code>D</code> is the diagonal of <code>A</code> and <code>E</code> is the off-diagonal. <code>B</code> is overwritten with the solution <code>X</code> and returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.pttrf!" href="#LinearAlgebra.LAPACK.pttrf!"><code>LinearAlgebra.LAPACK.pttrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pttrf!(D, E)</code></pre><p>Computes the LDLt factorization of a positive-definite tridiagonal matrix with <code>D</code> as diagonal and <code>E</code> as off-diagonal. <code>D</code> and <code>E</code> are overwritten and returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.pttrs!" href="#LinearAlgebra.LAPACK.pttrs!"><code>LinearAlgebra.LAPACK.pttrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pttrs!(D, E, B)</code></pre><p>Solves <code>A * X = B</code> for positive-definite tridiagonal <code>A</code> with diagonal <code>D</code> and off-diagonal <code>E</code> after computing <code>A</code>&#39;s LDLt factorization using <code>pttrf!</code>. <code>B</code> is overwritten with the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trtri!" href="#LinearAlgebra.LAPACK.trtri!"><code>LinearAlgebra.LAPACK.trtri!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trtri!(uplo, diag, A)</code></pre><p>Finds the inverse of (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>A</code> is overwritten with its inverse.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trtrs!" href="#LinearAlgebra.LAPACK.trtrs!"><code>LinearAlgebra.LAPACK.trtrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trtrs!(uplo, trans, diag, A, B)</code></pre><p>Solves <code>A * X = B</code> (<code>trans = N</code>), <code>transpose(A) * X = B</code> (<code>trans = T</code>), or <code>adjoint(A) * X = B</code> (<code>trans = C</code>) for (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>B</code> is overwritten with the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trcon!" href="#LinearAlgebra.LAPACK.trcon!"><code>LinearAlgebra.LAPACK.trcon!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trcon!(norm, uplo, diag, A)</code></pre><p>Finds the reciprocal condition number of (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. If <code>norm = I</code>, the condition number is found in the infinity norm. If <code>norm = O</code> or <code>1</code>, the condition number is found in the one norm.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trevc!" href="#LinearAlgebra.LAPACK.trevc!"><code>LinearAlgebra.LAPACK.trevc!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trevc!(side, howmny, select, T, VL = similar(T), VR = similar(T))</code></pre><p>Finds the eigensystem of an upper triangular matrix <code>T</code>. If <code>side = R</code>, the right eigenvectors are computed. If <code>side = L</code>, the left eigenvectors are computed. If <code>side = B</code>, both sets are computed. If <code>howmny = A</code>, all eigenvectors are found. If <code>howmny = B</code>, all eigenvectors are found and backtransformed using <code>VL</code> and <code>VR</code>. If <code>howmny = S</code>, only the eigenvectors corresponding to the values in <code>select</code> are computed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trrfs!" href="#LinearAlgebra.LAPACK.trrfs!"><code>LinearAlgebra.LAPACK.trrfs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trrfs!(uplo, trans, diag, A, B, X, Ferr, Berr) -&gt; (Ferr, Berr)</code></pre><p>Estimates the error in the solution to <code>A * X = B</code> (<code>trans = N</code>), <code>transpose(A) * X = B</code> (<code>trans = T</code>), <code>adjoint(A) * X = B</code> (<code>trans = C</code>) for <code>side = L</code>, or the equivalent equations a right-handed <code>side = R</code> <code>X * A</code> after computing <code>X</code> using <code>trtrs!</code>. If <code>uplo = U</code>, <code>A</code> is upper triangular. If <code>uplo = L</code>, <code>A</code> is lower triangular. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>Ferr</code> and <code>Berr</code> are optional inputs. <code>Ferr</code> is the forward error and <code>Berr</code> is the backward error, each component-wise.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.stev!" href="#LinearAlgebra.LAPACK.stev!"><code>LinearAlgebra.LAPACK.stev!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stev!(job, dv, ev) -&gt; (dv, Zmat)</code></pre><p>Computes the eigensystem for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>job = N</code> only the eigenvalues are found and returned in <code>dv</code>. If <code>job = V</code> then the eigenvectors are also found and returned in <code>Zmat</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.stebz!" href="#LinearAlgebra.LAPACK.stebz!"><code>LinearAlgebra.LAPACK.stebz!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stebz!(range, order, vl, vu, il, iu, abstol, dv, ev) -&gt; (dv, iblock, isplit)</code></pre><p>Computes the eigenvalues for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. If <code>order = B</code>, eigvalues are ordered within a block. If <code>order = E</code>, they are ordered across all the blocks. <code>abstol</code> can be set as a tolerance for convergence.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.stegr!" href="#LinearAlgebra.LAPACK.stegr!"><code>LinearAlgebra.LAPACK.stegr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stegr!(jobz, range, dv, ev, vl, vu, il, iu) -&gt; (w, Z)</code></pre><p>Computes the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. The eigenvalues are returned in <code>w</code> and the eigenvectors in <code>Z</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.stein!" href="#LinearAlgebra.LAPACK.stein!"><code>LinearAlgebra.LAPACK.stein!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stein!(dv, ev_in, w_in, iblock_in, isplit_in)</code></pre><p>Computes the eigenvectors for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev_in</code> as off-diagonal. <code>w_in</code> specifies the input eigenvalues for which to find corresponding eigenvectors. <code>iblock_in</code> specifies the submatrices corresponding to the eigenvalues in <code>w_in</code>. <code>isplit_in</code> specifies the splitting points between the submatrix blocks.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.syconv!" href="#LinearAlgebra.LAPACK.syconv!"><code>LinearAlgebra.LAPACK.syconv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syconv!(uplo, A, ipiv) -&gt; (A, work)</code></pre><p>Converts a symmetric matrix <code>A</code> (which has been factorized into a triangular matrix) into two matrices <code>L</code> and <code>D</code>. If <code>uplo = U</code>, <code>A</code> is upper triangular. If <code>uplo = L</code>, it is lower triangular. <code>ipiv</code> is the pivot vector from the triangular factorization. <code>A</code> is overwritten by <code>L</code> and <code>D</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.sysv!" href="#LinearAlgebra.LAPACK.sysv!"><code>LinearAlgebra.LAPACK.sysv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sysv!(uplo, A, B) -&gt; (B, A, ipiv)</code></pre><p>Finds the solution to <code>A * X = B</code> for symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>. <code>A</code> is overwritten by its Bunch-Kaufman factorization. <code>ipiv</code> contains pivoting information about the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.sytrf!" href="#LinearAlgebra.LAPACK.sytrf!"><code>LinearAlgebra.LAPACK.sytrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sytrf!(uplo, A) -&gt; (A, ipiv, info)</code></pre><p>Computes the Bunch-Kaufman factorization of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored.</p><p>Returns <code>A</code>, overwritten by the factorization, a pivot vector <code>ipiv</code>, and the error code <code>info</code> which is a non-negative integer. If <code>info</code> is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position <code>info</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.sytri!" href="#LinearAlgebra.LAPACK.sytri!"><code>LinearAlgebra.LAPACK.sytri!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sytri!(uplo, A, ipiv)</code></pre><p>Computes the inverse of a symmetric matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>A</code> is overwritten by its inverse.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.sytrs!" href="#LinearAlgebra.LAPACK.sytrs!"><code>LinearAlgebra.LAPACK.sytrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sytrs!(uplo, A, ipiv, B)</code></pre><p>Solves the equation <code>A * X = B</code> for a symmetric matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.hesv!" href="#LinearAlgebra.LAPACK.hesv!"><code>LinearAlgebra.LAPACK.hesv!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hesv!(uplo, A, B) -&gt; (B, A, ipiv)</code></pre><p>Finds the solution to <code>A * X = B</code> for Hermitian matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>. <code>A</code> is overwritten by its Bunch-Kaufman factorization. <code>ipiv</code> contains pivoting information about the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.hetrf!" href="#LinearAlgebra.LAPACK.hetrf!"><code>LinearAlgebra.LAPACK.hetrf!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hetrf!(uplo, A) -&gt; (A, ipiv, info)</code></pre><p>Computes the Bunch-Kaufman factorization of a Hermitian matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored.</p><p>Returns <code>A</code>, overwritten by the factorization, a pivot vector <code>ipiv</code>, and the error code <code>info</code> which is a non-negative integer. If <code>info</code> is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position <code>info</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.hetri!" href="#LinearAlgebra.LAPACK.hetri!"><code>LinearAlgebra.LAPACK.hetri!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hetri!(uplo, A, ipiv)</code></pre><p>Computes the inverse of a Hermitian matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>A</code> is overwritten by its inverse.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.hetrs!" href="#LinearAlgebra.LAPACK.hetrs!"><code>LinearAlgebra.LAPACK.hetrs!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hetrs!(uplo, A, ipiv, B)</code></pre><p>Solves the equation <code>A * X = B</code> for a Hermitian matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.syev!" href="#LinearAlgebra.LAPACK.syev!"><code>LinearAlgebra.LAPACK.syev!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syev!(jobz, uplo, A)</code></pre><p>Finds the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper triangle of <code>A</code> is used. If <code>uplo = L</code>, the lower triangle of <code>A</code> is used.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.syevr!" href="#LinearAlgebra.LAPACK.syevr!"><code>LinearAlgebra.LAPACK.syevr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">syevr!(jobz, range, uplo, A, vl, vu, il, iu, abstol) -&gt; (W, Z)</code></pre><p>Finds the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper triangle of <code>A</code> is used. If <code>uplo = L</code>, the lower triangle of <code>A</code> is used. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. <code>abstol</code> can be set as a tolerance for convergence.</p><p>The eigenvalues are returned in <code>W</code> and the eigenvectors in <code>Z</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.sygvd!" href="#LinearAlgebra.LAPACK.sygvd!"><code>LinearAlgebra.LAPACK.sygvd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sygvd!(itype, jobz, uplo, A, B) -&gt; (w, A, B)</code></pre><p>Finds the generalized eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code> and symmetric positive-definite matrix <code>B</code>. If <code>uplo = U</code>, the upper triangles of <code>A</code> and <code>B</code> are used. If <code>uplo = L</code>, the lower triangles of <code>A</code> and <code>B</code> are used. If <code>itype = 1</code>, the problem to solve is <code>A * x = lambda * B * x</code>. If <code>itype = 2</code>, the problem to solve is <code>A * B * x = lambda * x</code>. If <code>itype = 3</code>, the problem to solve is <code>B * A * x = lambda * x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.bdsqr!" href="#LinearAlgebra.LAPACK.bdsqr!"><code>LinearAlgebra.LAPACK.bdsqr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bdsqr!(uplo, d, e_, Vt, U, C) -&gt; (d, Vt, U, C)</code></pre><p>Computes the singular value decomposition of a bidiagonal matrix with <code>d</code> on the diagonal and <code>e_</code> on the off-diagonal. If <code>uplo = U</code>, <code>e_</code> is the superdiagonal. If <code>uplo = L</code>, <code>e_</code> is the subdiagonal. Can optionally also compute the product <code>Q&#39; * C</code>.</p><p>Returns the singular values in <code>d</code>, and the matrix <code>C</code> overwritten with <code>Q&#39; * C</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.bdsdc!" href="#LinearAlgebra.LAPACK.bdsdc!"><code>LinearAlgebra.LAPACK.bdsdc!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bdsdc!(uplo, compq, d, e_) -&gt; (d, e, u, vt, q, iq)</code></pre><p>Computes the singular value decomposition of a bidiagonal matrix with <code>d</code> on the diagonal and <code>e_</code> on the off-diagonal using a divide and conqueq method. If <code>uplo = U</code>, <code>e_</code> is the superdiagonal. If <code>uplo = L</code>, <code>e_</code> is the subdiagonal. If <code>compq = N</code>, only the singular values are found. If <code>compq = I</code>, the singular values and vectors are found. If <code>compq = P</code>, the singular values and vectors are found in compact form. Only works for real types.</p><p>Returns the singular values in <code>d</code>, and if <code>compq = P</code>, the compact singular vectors in <code>iq</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gecon!" href="#LinearAlgebra.LAPACK.gecon!"><code>LinearAlgebra.LAPACK.gecon!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gecon!(normtype, A, anorm)</code></pre><p>Finds the reciprocal condition number of matrix <code>A</code>. If <code>normtype = I</code>, the condition number is found in the infinity norm. If <code>normtype = O</code> or <code>1</code>, the condition number is found in the one norm. <code>A</code> must be the result of <code>getrf!</code> and <code>anorm</code> is the norm of <code>A</code> in the relevant norm.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gehrd!" href="#LinearAlgebra.LAPACK.gehrd!"><code>LinearAlgebra.LAPACK.gehrd!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gehrd!(ilo, ihi, A) -&gt; (A, tau)</code></pre><p>Converts a matrix <code>A</code> to Hessenberg form. If <code>A</code> is balanced with <code>gebal!</code> then <code>ilo</code> and <code>ihi</code> are the outputs of <code>gebal!</code>. Otherwise they should be <code>ilo = 1</code> and <code>ihi = size(A,2)</code>. <code>tau</code> contains the elementary reflectors of the factorization.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.orghr!" href="#LinearAlgebra.LAPACK.orghr!"><code>LinearAlgebra.LAPACK.orghr!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orghr!(ilo, ihi, A, tau)</code></pre><p>Explicitly finds <code>Q</code>, the orthogonal/unitary matrix from <code>gehrd!</code>. <code>ilo</code>, <code>ihi</code>, <code>A</code>, and <code>tau</code> must correspond to the input/output to <code>gehrd!</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gees!" href="#LinearAlgebra.LAPACK.gees!"><code>LinearAlgebra.LAPACK.gees!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gees!(jobvs, A) -&gt; (A, vs, w)</code></pre><p>Computes the eigenvalues (<code>jobvs = N</code>) or the eigenvalues and Schur vectors (<code>jobvs = V</code>) of matrix <code>A</code>. <code>A</code> is overwritten by its Schur form.</p><p>Returns <code>A</code>, <code>vs</code> containing the Schur vectors, and <code>w</code>, containing the eigenvalues.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.gges!" href="#LinearAlgebra.LAPACK.gges!"><code>LinearAlgebra.LAPACK.gges!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gges!(jobvsl, jobvsr, A, B) -&gt; (A, B, alpha, beta, vsl, vsr)</code></pre><p>Computes the generalized eigenvalues, generalized Schur form, left Schur vectors (<code>jobsvl = V</code>), or right Schur vectors (<code>jobvsr = V</code>) of <code>A</code> and <code>B</code>.</p><p>The generalized eigenvalues are returned in <code>alpha</code> and <code>beta</code>. The left Schur vectors are returned in <code>vsl</code> and the right Schur vectors are returned in <code>vsr</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trexc!" href="#LinearAlgebra.LAPACK.trexc!"><code>LinearAlgebra.LAPACK.trexc!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trexc!(compq, ifst, ilst, T, Q) -&gt; (T, Q)
trexc!(ifst, ilst, T, Q) -&gt; (T, Q)</code></pre><p>Reorder the Schur factorization <code>T</code> of a matrix, such that the diagonal block of <code>T</code> with row index <code>ifst</code> is moved to row index <code>ilst</code>. If <code>compq = V</code>, the Schur vectors <code>Q</code> are reordered. If <code>compq = N</code> they are not modified. The 4-arg method calls the 5-arg method with <code>compq = V</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trsen!" href="#LinearAlgebra.LAPACK.trsen!"><code>LinearAlgebra.LAPACK.trsen!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsen!(job, compq, select, T, Q) -&gt; (T, Q, w, s, sep)
trsen!(select, T, Q) -&gt; (T, Q, w, s, sep)</code></pre><p>Reorder the Schur factorization of a matrix and optionally finds reciprocal condition numbers. If <code>job = N</code>, no condition numbers are found. If <code>job = E</code>, only the condition number for this cluster of eigenvalues is found. If <code>job = V</code>, only the condition number for the invariant subspace is found. If <code>job = B</code> then the condition numbers for the cluster and subspace are found. If <code>compq = V</code> the Schur vectors <code>Q</code> are updated. If <code>compq = N</code> the Schur vectors are not modified. <code>select</code> determines which eigenvalues are in the cluster. The 3-arg method calls the 5-arg method with <code>job = N</code> and <code>compq = V</code>.</p><p>Returns <code>T</code>, <code>Q</code>, reordered eigenvalues in <code>w</code>, the condition number of the cluster of eigenvalues <code>s</code>, and the condition number of the invariant subspace <code>sep</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.tgsen!" href="#LinearAlgebra.LAPACK.tgsen!"><code>LinearAlgebra.LAPACK.tgsen!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tgsen!(select, S, T, Q, Z) -&gt; (S, T, alpha, beta, Q, Z)</code></pre><p>Reorders the vectors of a generalized Schur decomposition. <code>select</code> specifies the eigenvalues in each cluster.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.LAPACK.trsyl!" href="#LinearAlgebra.LAPACK.trsyl!"><code>LinearAlgebra.LAPACK.trsyl!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">trsyl!(transa, transb, A, B, C, isgn=1) -&gt; (C, scale)</code></pre><p>Solves the Sylvester matrix equation <code>A * X +/- X * B = scale*C</code> where <code>A</code> and <code>B</code> are both quasi-upper triangular. If <code>transa = N</code>, <code>A</code> is not modified. If <code>transa = T</code>, <code>A</code> is transposed. If <code>transa = C</code>, <code>A</code> is conjugate transposed. Similarly for <code>transb</code> and <code>B</code>. If <code>isgn = 1</code>, the equation <code>A * X + X * B = scale * C</code> is solved. If <code>isgn = -1</code>, the equation <code>A * X - X * B = scale * C</code> is solved.</p><p>Returns <code>X</code> (overwriting <code>C</code>) and <code>scale</code>.</p></div></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Bischof1987"><a class="tag is-link" href="#citeref-Bischof1987">Bischof1987</a>C Bischof and C Van Loan, &quot;The WY representation for products of Householder matrices&quot;, SIAM J Sci Stat Comput 8 (1987), s2-s13. <a href="https://doi.org/10.1137/0908009">doi:10.1137/0908009</a></li><li class="footnote" id="footnote-Schreiber1989"><a class="tag is-link" href="#citeref-Schreiber1989">Schreiber1989</a>R Schreiber and C Van Loan, &quot;A storage-efficient WY representation for products of Householder transformations&quot;, SIAM J Sci Stat Comput 10 (1989), 53-57. <a href="https://doi.org/10.1137/0910005">doi:10.1137/0910005</a></li><li class="footnote" id="footnote-Bunch1977"><a class="tag is-link" href="#citeref-Bunch1977">Bunch1977</a>J R Bunch and L Kaufman, Some stable methods for calculating inertia and solving symmetric linear systems, Mathematics of Computation 31:137 (1977), 163-179. <a href="http://www.ams.org/journals/mcom/1977-31-137/S0025-5718-1977-0428694-0/">url</a>.</li><li class="footnote" id="footnote-issue8859"><a class="tag is-link" href="#citeref-issue8859">issue8859</a>Issue 8859, &quot;Fix least squares&quot;, <a href="https://github.com/JuliaLang/julia/pull/8859">https://github.com/JuliaLang/julia/pull/8859</a></li><li class="footnote" id="footnote-B96"><a class="tag is-link" href="#citeref-B96">B96</a>Åke Björck, &quot;Numerical Methods for Least Squares Problems&quot;,  SIAM Press, Philadelphia, 1996, &quot;Other Titles in Applied Mathematics&quot;, Vol. 51. <a href="http://epubs.siam.org/doi/book/10.1137/1.9781611971484">doi:10.1137/1.9781611971484</a></li><li class="footnote" id="footnote-S84"><a class="tag is-link" href="#citeref-S84">S84</a>G. W. Stewart, &quot;Rank Degeneracy&quot;, SIAM Journal on Scientific and Statistical Computing, 5(2), 1984, 403-413. <a href="http://epubs.siam.org/doi/abs/10.1137/0905030">doi:10.1137/0905030</a></li><li class="footnote" id="footnote-KY88"><a class="tag is-link" href="#citeref-KY88">KY88</a>Konstantinos Konstantinides and Kung Yao, &quot;Statistical analysis of effective singular values in matrix rank determination&quot;, IEEE Transactions on Acoustics, Speech and Signal Processing, 36(5), 1988, 757-763. <a href="https://doi.org/10.1109/29.1585">doi:10.1109/29.1585</a></li><li class="footnote" id="footnote-H05"><a class="tag is-link" href="#citeref-H05">H05</a>Nicholas J. Higham, &quot;The squaring and scaling method for the matrix exponential revisited&quot;, SIAM Journal on Matrix Analysis and Applications, 26(4), 2005, 1179-1193. <a href="https://doi.org/10.1137/090768539">doi:10.1137/090768539</a></li><li class="footnote" id="footnote-AH12"><a class="tag is-link" href="#citeref-AH12">AH12</a>Awad H. Al-Mohy and Nicholas J. Higham, &quot;Improved inverse  scaling and squaring algorithms for the matrix logarithm&quot;, SIAM Journal on Scientific Computing, 34(4), 2012, C153-C169. <a href="https://doi.org/10.1137/110852553">doi:10.1137/110852553</a></li><li class="footnote" id="footnote-AHR13"><a class="tag is-link" href="#citeref-AHR13">AHR13</a>Awad H. Al-Mohy, Nicholas J. Higham and Samuel D. Relton, &quot;Computing the Fréchet derivative of the matrix logarithm and estimating the condition number&quot;, SIAM Journal on Scientific Computing, 35(4), 2013, C394-C410. <a href="https://doi.org/10.1137/120885991">doi:10.1137/120885991</a></li><li class="footnote" id="footnote-BH83"><a class="tag is-link" href="#citeref-BH83">BH83</a>Åke Björck and Sven Hammarling, &quot;A Schur method for the square root of a matrix&quot;, Linear Algebra and its Applications, 52-53, 1983, 127-140. <a href="https://doi.org/10.1016/0024-3795(83)80010-X">doi:10.1016/0024-3795(83)80010-X</a></li><li class="footnote" id="footnote-AH16_1"><a class="tag is-link" href="#citeref-AH16_1">AH16_1</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li><li class="footnote" id="footnote-AH16_2"><a class="tag is-link" href="#citeref-AH16_2">AH16_2</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li><li class="footnote" id="footnote-AH16_3"><a class="tag is-link" href="#citeref-AH16_3">AH16_3</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li><li class="footnote" id="footnote-AH16_4"><a class="tag is-link" href="#citeref-AH16_4">AH16_4</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li><li class="footnote" id="footnote-AH16_5"><a class="tag is-link" href="#citeref-AH16_5">AH16_5</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li><li class="footnote" id="footnote-AH16_6"><a class="tag is-link" href="#citeref-AH16_6">AH16_6</a>Mary Aprahamian and Nicholas J. Higham, &quot;Matrix Inverse Trigonometric and Inverse Hyperbolic Functions: Theory and Algorithms&quot;, MIMS EPrint: 2016.4. <a href="https://doi.org/10.1137/16M1057577">https://doi.org/10.1137/16M1057577</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Libdl/">« 动态链接器</a><a class="docs-footer-nextpage" href="../Logging/">日志记录 »</a><div class="flexbox-break"></div><p class="footer-message">📢📢📢Julia中文社区现已加入“开源软件供应链点亮计划”，如果你想改善Julia中文文档的翻译，那就赶快来 <a href="https://summer.iscas.ac.cn/#/org/prodetail/210370191">报名</a> 吧！</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">设置</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">选择主题</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>本文档在<span class="colophon-date" title="2021 八月 12 周四 18:36">2021 八月 12 周四</span>由<a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a>使用1.6.2版本的Julia生成。</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
